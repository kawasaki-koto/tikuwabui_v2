{
    "Loading...": "読み込んでる途中やで...",
    "Use via API": "APIを通して使うで",
    "Built with Gradio": "Gradioでビルドされたんやわ",
    "Stable Diffusion checkpoint": "Stable Diffusionはんのcheckpoint",
    "txt2img": "txt2img",
    "img2img": "img2img",
    "Extras": "その他",
    "PNG Info": "PNGん中の情報を出す",
    "Checkpoint Merger": "checkpointのマージ",
    "Train": "学習",
    "Settings": "設定",
    "Extensions": "追加しはった機能",
    "Prompt": "プロンプト",
    "Negative prompt": "ネガティブプロンプト",
    "Interrupt": "やんぴ",
    "Skip": "とばす",
    "Generate": "作るで",
    "Generate forever": "Generate forever",
    "Cancel generate forever": "Cancel generate forever",
    "Run": "やる",
    "Styles": "スタイル",
    "Label": "ラベル",
    "File": "ファイル",
    "Drop File Here": "ここにファイル投げてや",
    "- or -": "- or -",
    "Click to Upload": "クリックしてアップロード",
    "Textual Inversion": "Textual Inversion",
    "Hypernetworks": "Hypernetworks",
    "Checkpoints": "チェックポイント",
    "Lora": "LoRA",
    "Refresh": "リフレッシュ",
    "Nothing here. Add some content to the following directories:": "ここには何もないで、下のディレクトリになんか置いてや。",
    "replace preview": "プレビューを置換",
    "Textbox": "テキストボックス",
    "Save preview": "プレビューを保存",
    "Sampling method": "サンプリング方法",
    "Euler a": "Euler a",
    "Sampling steps": "サンプリングする回数",
    "Restore faces": "顔なおす",
    "Tiling": "タイリングするための画像作る",
    "Hires. fix": "でかい解像度ちゃんとする",
    "Upscaler": "アップスケーラー",
    "Latent": "Latent",
    "Latent (antialiased)": "Latent(かくかくなの直す)",
    "Latent (bicubic)": "Latent(バイキュービック)",
    "Latent (bicubic antialiased)": "Latent(バイキュービック-かくかくなの直す)",
    "Latent (nearest)": "Latent(いっちゃん近い)",
    "Latent (nearest-exact)": "Latent(いっちゃん近い-ちゃんとする)",
    "None": "なんもない",
    "Hires steps": "画像でかくするときのステップ数",
    "Denoising strength": "ノイズ消す強さ",
    "Upscale by": "こんだけ倍でかくする",
    "Resize width to": "ここまでよこでかくする",
    "Resize height to": "ここまでタッパでかくする",
    "Width": "よこ",
    "Height": "タッパ",
    "Batch count": "バッチなんぼほどするか",
    "Batch size": "バッチのでかさ",
    "CFG Scale": "どんだけ指示に従えばええんや？",
    "Seed": "シード",
    "Extra": "その他",
    "Variation seed": "バリエーションのシード",
    "Variation strength": "バリエーションどんだけ強くするか",
    "Resize seed from width": "元のよこと一緒のシードからサイズ変える",
    "Resize seed from height": "元のタッパと同じシードからサイズ変える",
    "Override settings": "設定上書き",
    "Script": "スクリプト",
    "Prompt matrix": "プロンプトマトリックス図",
    "Prompts from file or textbox": "ファイルかテキストボックスからプロンプトだす",
    "X/Y/Z plot": "X/Y/Zプロット",
    "Put variable parts at start of prompt": "プロンプト最初の｜も変数にする",
    "Use different seed for each picture": "画像でちゃうシードを使う",
    "Select prompt": "プロンプトの種類選ぶ",
    "positive": "ポジティブ",
    "negative": "ネガティブ",
    "Select joining char": "結合の区切り文字選ぶ",
    "comma": "カンマ",
    "space": "スペース",
    "Grid margins (px)": "グリッド間隔(px)",
    "Iterate seed every line": "1行ごとにシード1増やす",
    "Use same random seed for all lines": "ぜんぶの行に同じランダムシード使う",
    "List of prompt inputs": "プロンプトのリスト",
    "Upload prompt inputs": "プロンプトの入力アップロードする",
    "Nothing": "なんもない",
    "Var. seed": "変える用シード",
    "Var. strength": "変える強さ",
    "Steps": "何回やるか",
    "Prompt S/R": "Prompt S/R",
    "Prompt order": "プロンプトの並び",
    "Sampler": "サンプラー",
    "Checkpoint name": "Checkpoint名",
    "Sigma Churn": "Sigma Churn",
    "Sigma min": "Sigmaいっちゃん小さい",
    "Sigma max": "Sigmaいっちゃんでかい",
    "Sigma noise": "Sigma noise",
    "Eta": "こんぐらいかかるで",
    "Clip skip": "Clipとばす",
    "Denoising": "ノイズなくす",
    "Hires upscaler": "解像度でかくするアップスケーラー",
    "VAE": "VAE",
    "UniPC Order": "UniPC 次数",
    "Face restore": "顔なおす",
    "X type": "X軸これ",
    "X values": "X軸こんだけ",
    "Y type": "Y軸これ",
    "Y values": "Y軸こんだけ",
    "Z type": "Z軸これ",
    "Z values": "Z軸こんだけ",
    "Draw legend": "凡例描く",
    "Keep -1 for seeds": "シード値-1にしっぱなしにする",
    "Include Sub Images": "バッチで複数生成した画像グリッド出力する",
    "Include Sub Grids": "グリッドのグリッド出力する",
    "Swap X/Y axes": "X/Y軸ひっくり返す",
    "Swap Y/Z axes": "Y/Z軸ひっくり返す",
    "Swap X/Z axes": "X/Z軸ひっくり返す",
    "Save": "保存",
    "Zip": "Zip",
    "Send to img2img": "img2imgにやる",
    "Send to inpaint": "inpaintにやる",
    "Send to extras": "その他にやる",
    "Interrogate\nCLIP": "CLIPが考えてくれるで",
    "Interrogate\nDeepBooru": "DeepBooruが考えてくれるで",
    "Sketch": "スケッチ",
    "Inpaint": "inpaint",
    "Inpaint sketch": "inpaintスケッチ",
    "Inpaint upload": "inpaint上げる",
    "Batch": "バッチ",
    "Image for img2img": "img2imgで使う画像",
    "Drop Image Here": "ここに画像投げてや",
    "Copy image to:": "ここに画像コピーする:",
    "sketch": "スケッチ",
    "inpaint": "inpaint",
    "inpaint sketch": "inpaintスケッチ",
    "Image for inpainting with mask": "インペイントで使う画像とマスク",
    "Color sketch inpainting": "インペイントで使うカラースケッチ",
    "Mask": "マスク",
    "Process images in a directory on the same machine where the server is running.": "サーバーが動いてんのと同じマシンにあるディレクトリん中の画像を処理。",
    "Use an empty output directory to save pictures normally instead of writing to the output directory.": "Use an empty output directory to save pictures normally instead of writing to the output directory.",
    "Add inpaint batch mask directory to enable inpaint batch processing.": "Add inpaint batch mask directory to enable inpaint batch processing.",
    "Input directory": "Input directory",
    "Output directory": "Output directory",
    "Inpaint batch mask directory (required for inpaint batch processing only)": "Inpaint batch mask directory (required for inpaint batch processing only)",
    "Resize mode": "Resize mode",
    "Just resize": "Just resize",
    "Crop and resize": "Crop and resize",
    "Resize and fill": "Resize and fill",
    "Just resize (latent upscale)": "Just resize (latent upscale)",
    "Mask blur": "Mask blur",
    "Mask transparency": "Mask transparency",
    "Mask mode": "Mask mode",
    "Inpaint masked": "Inpaint masked",
    "Inpaint not masked": "Inpaint not masked",
    "Masked content": "Masked content",
    "fill": "fill",
    "original": "original",
    "latent noise": "latent noise",
    "latent nothing": "latent nothing",
    "Inpaint area": "Inpaint area",
    "Whole picture": "Whole picture",
    "Only masked": "Only masked",
    "Only masked padding, pixels": "Only masked padding, pixels",
    "Image CFG Scale": "Image CFG Scale",
    "img2img alternative test": "img2img alternative test",
    "Loopback": "Loopback",
    "Outpainting mk2": "Outpainting mk2",
    "Poor man's outpainting": "Poor man's outpainting",
    "SD upscale": "SD upscale",
    "should be 2 or lower.": "should be 2 or lower.",
    "Override `Sampling method` to Euler?(this method is built for it)": "Override `Sampling method` to Euler?(this method is built for it)",
    "Override `prompt` to the same value as `original prompt`?(and `negative prompt`)": "Override `prompt` to the same value as `original prompt`?(and `negative prompt`)",
    "Original prompt": "Original prompt",
    "Original negative prompt": "Original negative prompt",
    "Override `Sampling Steps` to the same value as `Decode steps`?": "Override `Sampling Steps` to the same value as `Decode steps`?",
    "Decode steps": "Decode steps",
    "Override `Denoising strength` to 1?": "Override `Denoising strength` to 1?",
    "Decode CFG scale": "Decode CFG scale",
    "Randomness": "Randomness",
    "Sigma adjustment for finding noise for image": "Sigma adjustment for finding noise for image",
    "Loops": "Loops",
    "Final denoising strength": "Final denoising strength",
    "Denoising strength curve": "Denoising strength curve",
    "Linear": "Linear",
    "Append interrogated prompt at each iteration": "Append interrogated prompt at each iteration",
    "CLIP": "CLIP",
    "DeepBooru": "DeepBooru",
    "Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8": "Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8",
    "Pixels to expand": "Pixels to expand",
    "Outpainting direction": "Outpainting direction",
    "left": "left",
    "right": "right",
    "up": "up",
    "down": "down",
    "Fall-off exponent (lower=higher detail)": "Fall-off exponent (lower=higher detail)",
    "Color variation": "Color variation",
    "Will upscale the image by the selected scale factor; use width and height sliders to set tile size": "Will upscale the image by the selected scale factor; use width and height sliders to set tile size",
    "Tile overlap": "Tile overlap",
    "Scale Factor": "Scale Factor",
    "Lanczos": "Lanczos",
    "Nearest": "一番近い",
    "ESRGAN_4x": "ESRGAN_4x",
    "LDSR": "LDSR",
    "R-ESRGAN 4x+": "R-ESRGAN 4x+",
    "R-ESRGAN 4x+ Anime6B": "R-ESRGAN 4x+ Anime6B",
    "ScuNET GAN": "ScuNET GAN",
    "ScuNET PSNR": "ScuNET PSNR",
    "SwinIR 4x": "SwinIR 4x",
    "Single Image": "Single Image",
    "Batch Process": "Batch Process",
    "Batch from Directory": "Batch from Directory",
    "Source": "Source",
    "Show result images": "Show result images",
    "Scale by": "Scale by",
    "Scale to": "Scale to",
    "Resize": "Resize",
    "Crop to fit": "Crop to fit",
    "Upscaler 1": "Upscaler 1",
    "Upscaler 2": "Upscaler 2",
    "Upscaler 2 visibility": "Upscaler 2 visibility",
    "GFPGAN visibility": "GFPGAN visibility",
    "CodeFormer visibility": "CodeFormer visibility",
    "CodeFormer weight (0 = maximum effect, 1 = minimum effect)": "CodeFormer weight (0 = maximum effect, 1 = minimum effect)",
    "Send to txt2img": "Send to txt2img",
    "A weighted sum will be used for interpolation. Requires two models; A and B. The result is calculated as A * (1 - M) + B * M": "A weighted sum will be used for interpolation. Requires two models; A and B. The result is calculated as A * (1 - M) + B * M",
    "Primary model (A)": "Primary model (A)",
    "Secondary model (B)": "Secondary model (B)",
    "Tertiary model (C)": "Tertiary model (C)",
    "Custom Name (Optional)": "Custom Name (Optional)",
    "Multiplier (M) - set to 0 to get model A": "Multiplier (M) - set to 0 to get model A",
    "Interpolation Method": "Interpolation Method",
    "No interpolation": "No interpolation",
    "Weighted sum": "Weighted sum",
    "Add difference": "Add difference",
    "Checkpoint format": "Checkpoint format",
    "ckpt": "ckpt",
    "safetensors": "safetensors",
    "Save as float16": "Save as float16",
    "Copy config from": "Copy config from",
    "A, B or C": "A, B or C",
    "B": "B",
    "C": "C",
    "Don't": "Don't",
    "Bake in VAE": "Bake in VAE",
    "Discard weights with matching name": "Discard weights with matching name",
    "Merge": "Merge",
    "See": "See",
    "wiki": "wiki",
    "for detailed explanation.": "for detailed explanation.",
    "Create embedding": "Create embedding",
    "Create hypernetwork": "Create hypernetwork",
    "Preprocess images": "Preprocess images",
    "Name": "Name",
    "Initialization text": "Initialization text",
    "Number of vectors per token": "Number of vectors per token",
    "Overwrite Old Embedding": "Overwrite Old Embedding",
    "Modules": "Modules",
    "Enter hypernetwork layer structure": "Enter hypernetwork layer structure",
    "Select activation function of hypernetwork. Recommended : Swish / Linear(none)": "Select activation function of hypernetwork. Recommended : Swish / Linear(none)",
    "linear": "linear",
    "relu": "relu",
    "leakyrelu": "leakyrelu",
    "elu": "elu",
    "swish": "swish",
    "tanh": "tanh",
    "sigmoid": "sigmoid",
    "celu": "celu",
    "gelu": "gelu",
    "glu": "glu",
    "hardshrink": "hardshrink",
    "hardsigmoid": "hardsigmoid",
    "hardtanh": "hardtanh",
    "logsigmoid": "logsigmoid",
    "logsoftmax": "logsoftmax",
    "mish": "mish",
    "prelu": "prelu",
    "rrelu": "rrelu",
    "relu6": "relu6",
    "selu": "selu",
    "silu": "silu",
    "softmax": "softmax",
    "softmax2d": "softmax2d",
    "softmin": "softmin",
    "softplus": "softplus",
    "softshrink": "softshrink",
    "softsign": "softsign",
    "tanhshrink": "tanhshrink",
    "threshold": "threshold",
    "Select Layer weights initialization. Recommended: Kaiming for relu-like, Xavier for sigmoid-like, Normal otherwise": "Select Layer weights initialization. Recommended: Kaiming for relu-like, Xavier for sigmoid-like, Normal otherwise",
    "Normal": "Normal",
    "KaimingUniform": "KaimingUniform",
    "KaimingNormal": "KaimingNormal",
    "XavierUniform": "XavierUniform",
    "XavierNormal": "XavierNormal",
    "Add layer normalization": "Add layer normalization",
    "Use dropout": "Use dropout",
    "Enter hypernetwork Dropout structure (or empty). Recommended : 0~0.35 incrementing sequence: 0, 0.05, 0.15": "Enter hypernetwork Dropout structure (or empty). Recommended : 0~0.35 incrementing sequence: 0, 0.05, 0.15",
    "Overwrite Old Hypernetwork": "Overwrite Old Hypernetwork",
    "Source directory": "Source directory",
    "Destination directory": "Destination directory",
    "Existing Caption txt Action": "Existing Caption txt Action",
    "ignore": "ignore",
    "copy": "copy",
    "prepend": "prepend",
    "append": "append",
    "Create flipped copies": "Create flipped copies",
    "Split oversized images": "Split oversized images",
    "Auto focal point crop": "Auto focal point crop",
    "Auto-sized crop": "Auto-sized crop",
    "Use BLIP for caption": "Use BLIP for caption",
    "Use deepbooru for caption": "Use deepbooru for caption",
    "Split image threshold": "Split image threshold",
    "Split image overlap ratio": "Split image overlap ratio",
    "Focal point face weight": "Focal point face weight",
    "Focal point entropy weight": "Focal point entropy weight",
    "Focal point edges weight": "Focal point edges weight",
    "Create debug image": "Create debug image",
    "Each image is center-cropped with an automatically chosen width and height.": "Each image is center-cropped with an automatically chosen width and height.",
    "Dimension lower bound": "Dimension lower bound",
    "Dimension upper bound": "Dimension upper bound",
    "Area lower bound": "Area lower bound",
    "Area upper bound": "Area upper bound",
    "Resizing objective": "Resizing objective",
    "Maximize area": "Maximize area",
    "Minimize error": "Minimize error",
    "Error threshold": "Error threshold",
    "Preprocess": "Preprocess",
    "Train an embedding or Hypernetwork; you must specify a directory with a set of 1:1 ratio images": "Train an embedding or Hypernetwork; you must specify a directory with a set of 1:1 ratio images",
    "[wiki]": "[wiki]",
    "Embedding": "Embedding",
    "Hypernetwork": "Hypernetwork",
    "Embedding Learning rate": "Embedding Learning rate",
    "Hypernetwork Learning rate": "Hypernetwork Learning rate",
    "Gradient Clipping": "Gradient Clipping",
    "disabled": "disabled",
    "value": "value",
    "norm": "norm",
    "Gradient accumulation steps": "Gradient accumulation steps",
    "Dataset directory": "Dataset directory",
    "Log directory": "Log directory",
    "Prompt template": "Prompt template",
    "Do not resize images": "Do not resize images",
    "Max steps": "Max steps",
    "Save an image to log directory every N steps, 0 to disable": "Save an image to log directory every N steps, 0 to disable",
    "Save a copy of embedding to log directory every N steps, 0 to disable": "Save a copy of embedding to log directory every N steps, 0 to disable",
    "Use PNG alpha channel as loss weight": "Use PNG alpha channel as loss weight",
    "Save images with embedding in PNG chunks": "Save images with embedding in PNG chunks",
    "Read parameters (prompt, etc...) from txt2img tab when making previews": "Read parameters (prompt, etc...) from txt2img tab when making previews",
    "Shuffle tags by ',' when creating prompts.": "Shuffle tags by ',' when creating prompts.",
    "Drop out tags when creating prompts.": "Drop out tags when creating prompts.",
    "Choose latent sampling method": "Choose latent sampling method",
    "once": "once",
    "deterministic": "deterministic",
    "random": "random",
    "Train Embedding": "Train Embedding",
    "Train Hypernetwork": "Train Hypernetwork",
    "Apply settings": "Apply settings",
    "Reload UI": "Reload UI",
    "Saving images/grids": "Saving images/grids",
    "Paths for saving": "Paths for saving",
    "Saving to a directory": "Saving to a directory",
    "Upscaling": "Upscaling",
    "Face restoration": "Face restoration",
    "System": "System",
    "Training": "Training",
    "Stable Diffusion": "Stable Diffusion",
    "Compatibility": "Compatibility",
    "Interrogate Options": "Interrogate Options",
    "Extra Networks": "Extra Networks",
    "User interface": "User interface",
    "Live previews": "Live previews",
    "Sampler parameters": "Sampler parameters",
    "Postprocessing": "Postprocessing",
    "Actions": "Actions",
    "Licenses": "Licenses",
    "Always save all generated images": "Always save all generated images",
    "File format for images": "File format for images",
    "Images filename pattern": "Images filename pattern",
    "Add number to filename when saving": "Add number to filename when saving",
    "Always save all generated image grids": "Always save all generated image grids",
    "File format for grids": "File format for grids",
    "Add extended info (seed, prompt) to filename when saving grid": "Add extended info (seed, prompt) to filename when saving grid",
    "Do not save grids consisting of one picture": "Do not save grids consisting of one picture",
    "Prevent empty spots in grid (when set to autodetect)": "Prevent empty spots in grid (when set to autodetect)",
    "Grid row count; use -1 for autodetect and 0 for it to be same as batch size": "Grid row count; use -1 for autodetect and 0 for it to be same as batch size",
    "Save text information about generation parameters as chunks to png files": "Save text information about generation parameters as chunks to png files",
    "Create a text file next to every image with generation parameters.": "Create a text file next to every image with generation parameters.",
    "Save a copy of image before doing face restoration.": "Save a copy of image before doing face restoration.",
    "Save a copy of image before applying highres fix.": "Save a copy of image before applying highres fix.",
    "Save a copy of image before applying color correction to img2img results": "Save a copy of image before applying color correction to img2img results",
    "For inpainting, save a copy of the greyscale mask": "For inpainting, save a copy of the greyscale mask",
    "For inpainting, save a masked composite": "For inpainting, save a masked composite",
    "Quality for saved jpeg images": "Quality for saved jpeg images",
    "Use lossless compression for webp images": "Use lossless compression for webp images",
    "If the saved image file size is above the limit, or its either width or height are above the limit, save a downscaled copy as JPG": "If the saved image file size is above the limit, or its either width or height are above the limit, save a downscaled copy as JPG",
    "File size limit for the above option, MB": "File size limit for the above option, MB",
    "Width/height limit for the above option, in pixels": "Width/height limit for the above option, in pixels",
    "Maximum image size, in megapixels": "Maximum image size, in megapixels",
    "Use original name for output filename during batch process in extras tab": "Use original name for output filename during batch process in extras tab",
    "Use upscaler name as filename suffix in the extras tab": "Use upscaler name as filename suffix in the extras tab",
    "When using 'Save' button, only save a single selected image": "When using 'Save' button, only save a single selected image",
    "Do not add watermark to images": "Do not add watermark to images",
    "Directory for temporary images; leave empty for default": "Directory for temporary images; leave empty for default",
    "Cleanup non-default temporary directory when starting webui": "Cleanup non-default temporary directory when starting webui",
    "Output directory for images; if empty, defaults to three directories below": "Output directory for images; if empty, defaults to three directories below",
    "Output directory for txt2img images": "Output directory for txt2img images",
    "Output directory for img2img images": "Output directory for img2img images",
    "Output directory for images from extras tab": "Output directory for images from extras tab",
    "Output directory for grids; if empty, defaults to two directories below": "Output directory for grids; if empty, defaults to two directories below",
    "Output directory for txt2img grids": "Output directory for txt2img grids",
    "Output directory for img2img grids": "Output directory for img2img grids",
    "Directory for saving images using the Save button": "Directory for saving images using the Save button",
    "Save images to a subdirectory": "Save images to a subdirectory",
    "Save grids to a subdirectory": "Save grids to a subdirectory",
    "When using \"Save\" button, save images to a subdirectory": "When using \"Save\" button, save images to a subdirectory",
    "Directory name pattern": "Directory name pattern",
    "Max prompt words for [prompt_words] pattern": "Max prompt words for [prompt_words] pattern",
    "Tile size for ESRGAN upscalers. 0 = no tiling.": "Tile size for ESRGAN upscalers. 0 = no tiling.",
    "Tile overlap, in pixels for ESRGAN upscalers. Low values = visible seam.": "Tile overlap, in pixels for ESRGAN upscalers. Low values = visible seam.",
    "Upscaler for img2img": "Upscaler for img2img",
    "LDSR processing steps. Lower = faster": "LDSR processing steps. Lower = faster",
    "Cache LDSR model in memory": "Cache LDSR model in memory",
    "Tile size for all SwinIR.": "Tile size for all SwinIR.",
    "Tile overlap, in pixels for SwinIR. Low values = visible seam.": "Tile overlap, in pixels for SwinIR. Low values = visible seam.",
    "CodeFormer weight parameter; 0 = maximum effect; 1 = minimum effect": "CodeFormer weight parameter; 0 = maximum effect; 1 = minimum effect",
    "Move face restoration model from VRAM into RAM after processing": "Move face restoration model from VRAM into RAM after processing",
    "Show warnings in console.": "Show warnings in console.",
    "VRAM usage polls per second during generation. Set to 0 to disable.": "VRAM usage polls per second during generation. Set to 0 to disable.",
    "Always print all generation info to standard output": "Always print all generation info to standard output",
    "Add a second progress bar to the console that shows progress for an entire job.": "Add a second progress bar to the console that shows progress for an entire job.",
    "Print extra hypernetwork information to console.": "Print extra hypernetwork information to console.",
    "Move VAE and CLIP to RAM when training if possible. Saves VRAM.": "Move VAE and CLIP to RAM when training if possible. Saves VRAM.",
    "Turn on pin_memory for DataLoader. Makes training slightly faster but can increase memory usage.": "Turn on pin_memory for DataLoader. Makes training slightly faster but can increase memory usage.",
    "Saves Optimizer state as separate *.optim file. Training of embedding or HN can be resumed with the matching optim file.": "Saves Optimizer state as separate *.optim file. Training of embedding or HN can be resumed with the matching optim file.",
    "Save textual inversion and hypernet settings to a text file whenever training starts.": "Save textual inversion and hypernet settings to a text file whenever training starts.",
    "Filename word regex": "Filename word regex",
    "Filename join string": "Filename join string",
    "Number of repeats for a single input image per epoch; used only for displaying epoch number": "Number of repeats for a single input image per epoch; used only for displaying epoch number",
    "Save an csv containing the loss to log directory every N steps, 0 to disable": "Save an csv containing the loss to log directory every N steps, 0 to disable",
    "Use cross attention optimizations while training": "Use cross attention optimizations while training",
    "Enable tensorboard logging.": "Enable tensorboard logging.",
    "Save generated images within tensorboard.": "Save generated images within tensorboard.",
    "How often, in seconds, to flush the pending tensorboard events and summaries to disk.": "How often, in seconds, to flush the pending tensorboard events and summaries to disk.",
    "Checkpoints to cache in RAM": "Checkpoints to cache in RAM",
    "VAE Checkpoints to cache in RAM": "VAE Checkpoints to cache in RAM",
    "SD VAE": "SD VAE",
    "Automatic": "Automatic",
    "Ignore selected VAE for stable diffusion checkpoints that have their own .vae.pt next to them": "Ignore selected VAE for stable diffusion checkpoints that have their own .vae.pt next to them",
    "Inpainting conditioning mask strength": "Inpainting conditioning mask strength",
    "Noise multiplier for img2img": "Noise multiplier for img2img",
    "Apply color correction to img2img results to match original colors.": "Apply color correction to img2img results to match original colors.",
    "With img2img, do exactly the amount of steps the slider specifies (normally you'd do less with less denoising).": "With img2img, do exactly the amount of steps the slider specifies (normally you'd do less with less denoising).",
    "With img2img, fill image's transparent parts with this color.": "With img2img, fill image's transparent parts with this color.",
    "Enable quantization in K samplers for sharper and cleaner results. This may change existing seeds. Requires restart to apply.": "Enable quantization in K samplers for sharper and cleaner results. This may change existing seeds. Requires restart to apply.",
    "Emphasis: use (text) to make model pay more attention to text and [text] to make it pay less attention": "Emphasis: use (text) to make model pay more attention to text and [text] to make it pay less attention",
    "Make K-diffusion samplers produce same images in a batch as when making a single image": "Make K-diffusion samplers produce same images in a batch as when making a single image",
    "Increase coherency by padding from the last comma within n tokens when using more than 75 tokens": "Increase coherency by padding from the last comma within n tokens when using more than 75 tokens",
    "Upcast cross attention layer to float32": "Upcast cross attention layer to float32",
    "Use old emphasis implementation. Can be useful to reproduce old seeds.": "Use old emphasis implementation. Can be useful to reproduce old seeds.",
    "Use old karras scheduler sigmas (0.1 to 10).": "Use old karras scheduler sigmas (0.1 to 10).",
    "Do not make DPM++ SDE deterministic across different batch sizes.": "Do not make DPM++ SDE deterministic across different batch sizes.",
    "For hires fix, use width/height sliders to set final resolution rather than first pass (disables Upscale by, Resize width/height to).": "For hires fix, use width/height sliders to set final resolution rather than first pass (disables Upscale by, Resize width/height to).",
    "Interrogate: keep models in VRAM": "Interrogate: keep models in VRAM",
    "Interrogate: include ranks of model tags matches in results (Has no effect on caption-based interrogators).": "Interrogate: include ranks of model tags matches in results (Has no effect on caption-based interrogators).",
    "Interrogate: num_beams for BLIP": "Interrogate: num_beams for BLIP",
    "Interrogate: minimum description length (excluding artists, etc..)": "Interrogate: minimum description length (excluding artists, etc..)",
    "Interrogate: maximum description length": "Interrogate: maximum description length",
    "CLIP: maximum number of lines in text file (0 = No limit)": "CLIP: maximum number of lines in text file (0 = No limit)",
    "CLIP: skip inquire categories": "CLIP: skip inquire categories",
    "Interrogate: deepbooru score threshold": "Interrogate: deepbooru score threshold",
    "Interrogate: deepbooru sort alphabetically": "Interrogate: deepbooru sort alphabetically",
    "use spaces for tags in deepbooru": "use spaces for tags in deepbooru",
    "escape (\\) brackets in deepbooru (so they are used as literal brackets and not for emphasis)": "escape (\\) brackets in deepbooru (so they are used as literal brackets and not for emphasis)",
    "filter out those tags from deepbooru output (separated by comma)": "filter out those tags from deepbooru output (separated by comma)",
    "Default view for Extra Networks": "Default view for Extra Networks",
    "cards": "cards",
    "Multiplier for extra networks": "Multiplier for extra networks",
    "Card width for Extra Networks (px)": "Card width for Extra Networks (px)",
    "Card height for Extra Networks (px)": "Card height for Extra Networks (px)",
    "Extra text to add before <...> when adding extra network to prompt": "Extra text to add before <...> when adding extra network to prompt",
    "Add hypernetwork to prompt": "Add hypernetwork to prompt",
    "Add Lora to prompt": "Add Lora to prompt",
    "Show grid in results for web": "Show grid in results for web",
    "For inpainting, include the greyscale mask in results for web": "For inpainting, include the greyscale mask in results for web",
    "For inpainting, include masked composite in results for web": "For inpainting, include masked composite in results for web",
    "Do not show any images in results for web": "Do not show any images in results for web",
    "Add model hash to generation information": "Add model hash to generation information",
    "Add model name to generation information": "Add model name to generation information",
    "When reading generation parameters from text into UI (from PNG info or pasted text), do not change the selected model/checkpoint.": "When reading generation parameters from text into UI (from PNG info or pasted text), do not change the selected model/checkpoint.",
    "Send seed when sending prompt or image to other interface": "Send seed when sending prompt or image to other interface",
    "Send size when sending prompt or image to another interface": "Send size when sending prompt or image to another interface",
    "Font for image grids that have text": "Font for image grids that have text",
    "Enable full page image viewer": "Enable full page image viewer",
    "Show images zoomed in by default in full page image viewer": "Show images zoomed in by default in full page image viewer",
    "Show generation progress in window title.": "Show generation progress in window title.",
    "Use dropdown for sampler selection instead of radio group": "Use dropdown for sampler selection instead of radio group",
    "Show Width/Height and Batch sliders in same row": "Show Width/Height and Batch sliders in same row",
    "Ctrl+up/down precision when editing (attention:1.1)": "Ctrl+up/down precision when editing (attention:1.1)",
    "Ctrl+up/down precision when editing <extra networks:0.9>": "Ctrl+up/down precision when editing <extra networks:0.9>",
    "Quicksettings list": "Quicksettings list",
    "Hidden UI tabs (requires restart)": "Hidden UI tabs (requires restart)",
    "txt2img/img2img UI item order": "txt2img/img2img UI item order",
    "Extra networks tab order": "Extra networks tab order",
    "Localization (requires restart)": "Localization (requires restart)",
    "Show progressbar": "Show progressbar",
    "Show live previews of the created image": "Show live previews of the created image",
    "Show previews of all images generated in a batch as a grid": "Show previews of all images generated in a batch as a grid",
    "Show new live preview image every N sampling steps. Set to -1 to show after completion of batch.": "Show new live preview image every N sampling steps. Set to -1 to show after completion of batch.",
    "Image creation progress preview mode": "Image creation progress preview mode",
    "Full": "Full",
    "Approx NN": "Approx NN",
    "Approx cheap": "Approx cheap",
    "Live preview subject": "Live preview subject",
    "Combined": "Combined",
    "Progressbar/preview update period, in milliseconds": "Progressbar/preview update period, in milliseconds",
    "Hide samplers in user interface (requires restart)": "Hide samplers in user interface (requires restart)",
    "Euler": "Euler",
    "LMS": "LMS",
    "Heun": "Heun",
    "DPM2": "DPM2",
    "DPM2 a": "DPM2 a",
    "DPM++ 2S a": "DPM++ 2S a",
    "DPM++ 2M": "DPM++ 2M",
    "DPM++ SDE": "DPM++ SDE",
    "DPM fast": "DPM fast",
    "DPM adaptive": "DPM adaptive",
    "LMS Karras": "LMS Karras",
    "DPM2 Karras": "DPM2 Karras",
    "DPM2 a Karras": "DPM2 a Karras",
    "DPM++ 2S a Karras": "DPM++ 2S a Karras",
    "DPM++ 2M Karras": "DPM++ 2M Karras",
    "DPM++ SDE Karras": "DPM++ SDE Karras",
    "DDIM": "DDIM",
    "PLMS": "PLMS",
    "UniPC": "UniPC",
    "eta (noise multiplier) for DDIM": "eta (noise multiplier) for DDIM",
    "eta (noise multiplier) for ancestral samplers": "eta (noise multiplier) for ancestral samplers",
    "img2img DDIM discretize": "img2img DDIM discretize",
    "uniform": "uniform",
    "quad": "quad",
    "sigma churn": "sigma churn",
    "sigma tmin": "sigma tmin",
    "sigma noise": "sigma noise",
    "Eta noise seed delta": "Eta noise seed delta",
    "Always discard next-to-last sigma": "Always discard next-to-last sigma",
    "UniPC variant": "UniPC variant",
    "bh1": "bh1",
    "bh2": "bh2",
    "vary_coeff": "vary_coeff",
    "UniPC skip type": "UniPC skip type",
    "time_uniform": "time_uniform",
    "time_quadratic": "time_quadratic",
    "logSNR": "logSNR",
    "UniPC order (must be < sampling steps)": "UniPC order (must be < sampling steps)",
    "UniPC lower order final": "UniPC lower order final",
    "Enable postprocessing operations in txt2img and img2img tabs": "Enable postprocessing operations in txt2img and img2img tabs",
    "Postprocessing operation order": "Postprocessing operation order",
    "Maximum number of images in upscaling cache": "Maximum number of images in upscaling cache",
    "Request browser notifications": "Request browser notifications",
    "Download localization template": "Download localization template",
    "Reload custom script bodies (No ui updates, No restart)": "Reload custom script bodies (No ui updates, No restart)",
    "Unload SD checkpoint to free VRAM": "Unload SD checkpoint to free VRAM",
    "Reload the last SD checkpoint back into VRAM": "Reload the last SD checkpoint back into VRAM",
    "Show all pages": "Show all pages",
    "Installed": "Installed",
    "Available": "Available",
    "Install from URL": "Install from URL",
    "Apply and restart UI": "Apply and restart UI",
    "Check for updates": "Check for updates",
    "Disable all extensions": "Disable all extensions",
    "none": "none",
    "extra": "extra",
    "all": "全部",
    "Extension": "Extension",
    "Use checkbox to enable the extension; it will be enabled or disabled when you click apply button": "Use checkbox to enable the extension; it will be enabled or disabled when you click apply button",
    "URL": "URL",
    "Version": "Version",
    "Extension version": "Extension version",
    "Update": "Update",
    "Use checkbox to mark the extension for update; it will be updated when you click apply button": "Use checkbox to mark the extension for update; it will be updated when you click apply button",
    "built-in": "built-in",
    "latest": "latest",
    "behind": "behind",
    "Error": "Error",
    "unknown": "unknown",
    "ScuNET": "ScuNET",
    "prompt-bracket-checker": "prompt-bracket-checker",
    "Load from:": "Load from:",
    "Extension index URL": "Extension index URL",
    "Hide extensions with tags": "Hide extensions with tags",
    "script": "script",
    "ads": "ads",
    "localization": "localization",
    "installed": "installed",
    "Description": "Description",
    "Action": "Action",
    "dropdown": "dropdown",
    "UI related": "UI related",
    "tab": "tab",
    "animation": "animation",
    "online": "online",
    "extras": "extras",
    "science": "science",
    "models": "models",
    "query": "query",
    "training": "training",
    "Fusion": "Fusion",
    "editing": "editing",
    "Waiting...": "Waiting...",
    "Time taken:": "Time taken:",
    "prompting": "prompting",
    "manipulations": "manipulations",
    "Order": "Order",
    "newest first": "newest first",
    "oldest first": "oldest first",
    "a-z": "a-z",
    "z-a": "z-a",
    "internal order": "internal order",
    "Search": "Search",
    "URL for extension's git repository": "URL for extension's git repository",
    "Local directory name": "Local directory name",
    "Install": "Install",
    "N/A": "N/A",
    "Change checkpoint": "Change checkpoint",
    "Remove All": "Remove All",
    "Prompt (press Ctrl+Enter or Alt+Enter to generate)": "Prompt (press Ctrl+Enter or Alt+Enter to generate)",
    "Negative prompt (press Ctrl+Enter or Alt+Enter to generate)": "Negative prompt (press Ctrl+Enter or Alt+Enter to generate)",
    "Stop processing images and return any results accumulated so far.": "Stop processing images and return any results accumulated so far.",
    "Stop processing current image and continue processing.": "Stop processing current image and continue processing.",
    "Read generation parameters from prompt or last generation if prompt is empty into user interface.": "Read generation parameters from prompt or last generation if prompt is empty into user interface.",
    "Clear prompt": "Clear prompt",
    "Show/hide extra networks": "Show/hide extra networks",
    "Apply selected styles to current prompt": "Apply selected styles to current prompt",
    "Save style": "Save style",
    "Search...": "Search...",
    "Which algorithm to use to produce the image": "Which algorithm to use to produce the image",
    "Euler Ancestral - very creative, each can get a completely different picture depending on step count, setting steps higher than 30-40 does not help": "Euler Ancestral - very creative, each can get a completely different picture depending on step count, setting steps higher than 30-40 does not help",
    "How many times to improve the generated image iteratively; higher values take longer; very low values can produce bad results": "How many times to improve the generated image iteratively; higher values take longer; very low values can produce bad results",
    "Produce an image that can be tiled.": "Produce an image that can be tiled.",
    "Use a two step process to partially create an image at smaller resolution, upscale, and then improve details in it without changing composition": "Use a two step process to partially create an image at smaller resolution, upscale, and then improve details in it without changing composition",
    "Number of sampling steps for upscaled picture. If 0, uses same as for original.": "Number of sampling steps for upscaled picture. If 0, uses same as for original.",
    "Determines how little respect the algorithm should have for image's content. At 0, nothing will change, and at 1 you'll get an unrelated image. With values below 1.0, processing will take less steps than the Sampling Steps slider specifies.": "Determines how little respect the algorithm should have for image's content. At 0, nothing will change, and at 1 you'll get an unrelated image. With values below 1.0, processing will take less steps than the Sampling Steps slider specifies.",
    "Adjusts the size of the image by multiplying the original width and height by the selected value. Ignored if either Resize width to or Resize height to are non-zero.": "Adjusts the size of the image by multiplying the original width and height by the selected value. Ignored if either Resize width to or Resize height to are non-zero.",
    "Resizes image to this width. If 0, width is inferred from either of two nearby sliders.": "Resizes image to this width. If 0, width is inferred from either of two nearby sliders.",
    "Resizes image to this height. If 0, height is inferred from either of two nearby sliders.": "Resizes image to this height. If 0, height is inferred from either of two nearby sliders.",
    "How many batches of images to create (has no impact on generation performance or VRAM usage)": "How many batches of images to create (has no impact on generation performance or VRAM usage)",
    "How many image to create in a single batch (increases generation performance at cost of higher VRAM usage)": "How many image to create in a single batch (increases generation performance at cost of higher VRAM usage)",
    "Classifier Free Guidance Scale - how strongly the image should conform to prompt - lower values produce more creative results": "Classifier Free Guidance Scale - how strongly the image should conform to prompt - lower values produce more creative results",
    "A value that determines the output of random number generator - if you create an image with same parameters and seed as another image, you'll get the same result": "A value that determines the output of random number generator - if you create an image with same parameters and seed as another image, you'll get the same result",
    "Set seed to -1, which will cause a new random number to be used every time": "Set seed to -1, which will cause a new random number to be used every time",
    "Reuse seed from last generation, mostly useful if it was randomed": "Reuse seed from last generation, mostly useful if it was randomed",
    "Seed of a different picture to be mixed into the generation.": "Seed of a different picture to be mixed into the generation.",
    "How strong of a variation to produce. At 0, there will be no effect. At 1, you will get the complete picture with variation seed (except for ancestral samplers, where you will just get something).": "How strong of a variation to produce. At 0, there will be no effect. At 1, you will get the complete picture with variation seed (except for ancestral samplers, where you will just get something).",
    "Make an attempt to produce a picture similar to what would have been produced with same seed at specified resolution": "Make an attempt to produce a picture similar to what would have been produced with same seed at specified resolution",
    "Do not do anything special": "Do not do anything special",
    "Separate values for X axis using commas.": "Separate values for X axis using commas.",
    "Paste available values into the field": "Paste available values into the field",
    "Separate values for Y axis using commas.": "Separate values for Y axis using commas.",
    "Open images output directory": "Open images output directory",
    "Write image to a directory (default - log/images) and generation parameters into csv file.": "Write image to a directory (default - log/images) and generation parameters into csv file.",
    "Resize image to target resolution. Unless height and width match, you will get incorrect aspect ratio.": "Resize image to target resolution. Unless height and width match, you will get incorrect aspect ratio.",
    "Resize the image so that entirety of target resolution is filled with the image. Crop parts that stick out.": "Resize the image so that entirety of target resolution is filled with the image. Crop parts that stick out.",
    "Resize the image so that entirety of image is inside target resolution. Fill empty space with image's colors.": "Resize the image so that entirety of image is inside target resolution. Fill empty space with image's colors.",
    "How much to blur the mask before processing, in pixels.": "How much to blur the mask before processing, in pixels.",
    "What to put inside the masked area before processing it with Stable Diffusion.": "What to put inside the masked area before processing it with Stable Diffusion.",
    "fill it with colors of the image": "fill it with colors of the image",
    "keep whatever was there originally": "keep whatever was there originally",
    "fill it with latent space noise": "fill it with latent space noise",
    "fill it with latent space zeroes": "fill it with latent space zeroes",
    "How many times to process an image. Each output is used as the input of the next loop. If set to 1, behavior will be as if this script were not used.": "How many times to process an image. Each output is used as the input of the next loop. If set to 1, behavior will be as if this script were not used.",
    "The denoising strength for the final loop of each image in the batch.": "The denoising strength for the final loop of each image in the batch.",
    "The denoising curve controls the rate of denoising strength change each loop. Aggressive: Most of the change will happen towards the start of the loops. Linear: Change will be constant through all loops. Lazy: Most of the change will happen towards the end of the loops.": "The denoising curve controls the rate of denoising strength change each loop. Aggressive: Most of the change will happen towards the start of the loops. Linear: Change will be constant through all loops. Lazy: Most of the change will happen towards the end of the loops.",
    "For SD upscale, how much overlap in pixels should there be between tiles. Tiles overlap so that when they are merged back into one picture, there is no clearly visible seam.": "For SD upscale, how much overlap in pixels should there be between tiles. Tiles overlap so that when they are merged back into one picture, there is no clearly visible seam.",
    "A directory on the same machine where the server is running.": "A directory on the same machine where the server is running.",
    "Leave blank to save images to the default path.": "Leave blank to save images to the default path.",
    "Result = A": "Result = A",
    "Result = A * (1 - M) + B * M": "Result = A * (1 - M) + B * M",
    "Result = A + (B - C) * M": "Result = A + (B - C) * M",
    "Regular expression; if weights's name matches it, the weights is not written to the resulting checkpoint. Use ^model_ema to discard EMA weights.": "Regular expression; if weights's name matches it, the weights is not written to the resulting checkpoint. Use ^model_ema to discard EMA weights.",
    "If the number of tokens is more than the number of vectors, some may be skipped.\nLeave the textbox empty to start with zeroed out vectors": "If the number of tokens is more than the number of vectors, some may be skipped.\nLeave the textbox empty to start with zeroed out vectors",
    "1st and last digit must be 1. ex:'1, 2, 1'": "1st and last digit must be 1. ex:'1, 2, 1'",
    "1st and last digit must be 0 and values should be between 0 and 1. ex:'0, 0.01, 0'": "1st and last digit must be 0 and values should be between 0 and 1. ex:'0, 0.01, 0'",
    "Gradient clip value": "Gradient clip value",
    "Path to directory with input images": "Path to directory with input images",
    "Path to directory where to write outputs": "Path to directory where to write outputs",
    "Use following tags to define how filenames for images are chosen: [steps], [cfg], [prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.": "Use following tags to define how filenames for images are chosen: [steps], [cfg], [prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.",
    "If this option is enabled, watermark will not be added to created images. Warning: if you do not add watermark, you may be behaving in an unethical manner.": "If this option is enabled, watermark will not be added to created images. Warning: if you do not add watermark, you may be behaving in an unethical manner.",
    "Use following tags to define how subdirectories for images and grids are chosen: [steps], [cfg],[prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.": "Use following tags to define how subdirectories for images and grids are chosen: [steps], [cfg],[prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.",
    "Restore low quality faces using GFPGAN neural network": "Restore low quality faces using GFPGAN neural network",
    "This regular expression will be used extract words from filename, and they will be joined using the option below into label text used for training. Leave empty to keep filename text as it is.": "This regular expression will be used extract words from filename, and they will be joined using the option below into label text used for training. Leave empty to keep filename text as it is.",
    "This string will be used to join split words into a single line if the option above is enabled.": "This string will be used to join split words into a single line if the option above is enabled.",
    "Only applies to inpainting models. Determines how strongly to mask off the original image for inpainting and img2img. 1.0 means fully masked, which is the default behaviour. 0.0 means a fully unmasked conditioning. Lower values will help preserve the overall composition of the image, but will struggle with large changes.": "Only applies to inpainting models. Determines how strongly to mask off the original image for inpainting and img2img. 1.0 means fully masked, which is the default behaviour. 0.0 means a fully unmasked conditioning. Lower values will help preserve the overall composition of the image, but will struggle with large changes.",
    "Early stopping parameter for CLIP model; 1 is stop at last layer as usual, 2 is stop at penultimate layer, etc.": "Early stopping parameter for CLIP model; 1 is stop at last layer as usual, 2 is stop at penultimate layer, etc.",
    "When adding extra network such as Hypernetwork or Lora to prompt, use this multiplier for it.": "When adding extra network such as Hypernetwork or Lora to prompt, use this multiplier for it.",
    "List of setting names, separated by commas, for settings that should go to the quick access bar at the top, rather than the usual setting tab. See modules/shared.py for setting names. Requires restarting to apply.": "List of setting names, separated by commas, for settings that should go to the quick access bar at the top, rather than the usual setting tab. See modules/shared.py for setting names. Requires restarting to apply.",
    "Comma-separated list of tab names; tabs listed here will appear in the extra networks UI first and in order lsited.": "Comma-separated list of tab names; tabs listed here will appear in the extra networks UI first and in order lsited.",
    "Cheap neural network approximation. Very fast compared to VAE, but produces pictures with 4 times smaller horizontal/vertical resolution and lower quality.": "Cheap neural network approximation. Very fast compared to VAE, but produces pictures with 4 times smaller horizontal/vertical resolution and lower quality.",
    "Very cheap approximation. Very fast compared to VAE, but produces pictures with 8 times smaller horizontal/vertical resolution and extremely low quality.": "Very cheap approximation. Very fast compared to VAE, but produces pictures with 8 times smaller horizontal/vertical resolution and extremely low quality.",
    "Ignores step count - uses a number of steps determined by the CFG and resolution": "Ignores step count - uses a number of steps determined by the CFG and resolution",
    "Denoising Diffusion Implicit Models - best at inpainting": "Denoising Diffusion Implicit Models - best at inpainting",
    "Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models": "Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models",
    "If this values is non-zero, it will be added to seed and used to initialize RNG for noises when using samplers with Eta. You can use this to produce even more variation of images, or you can use this to match images of other software if you know what you are doing.": "If this values is non-zero, it will be added to seed and used to initialize RNG for noises when using samplers with Eta. You can use this to produce even more variation of images, or you can use this to match images of other software if you know what you are doing.",
    "Leave empty for auto": "Leave empty for auto",
    "Aesthetic Gradients": "Aesthetic Gradients",
    "Allows training an embedding from one or few pictures, specifically meant for applying styles. Also, allows use of these specific embeddings to generated images.": "Allows training an embedding from one or few pictures, specifically meant for applying styles. Also, allows use of these specific embeddings to generated images.",
    "Dreambooth": "Dreambooth",
    "Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.": "Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.",
    "training-picker": "training-picker",
    "Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.": "Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.",
    "Dataset Tag Editor": "Dataset Tag Editor",
    "Feature-rich UI tab that allows image viewing, search-filtering and editing.": "Feature-rich UI tab that allows image viewing, search-filtering and editing.",
    "DreamArtist": "DreamArtist",
    "Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.": "Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.",
    "WD 1.4 Tagger": "WD 1.4 Tagger",
    "Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.": "Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.",
    "Hypernetwork-Monkeypatch-Extension": "Hypernetwork-Monkeypatch-Extension",
    "Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.": "Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.",
    "Custom Diffusion": "Custom Diffusion",
    "Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.": "Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.",
    "Smart Process": "Smart Process",
    "Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.": "Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.",
    "Embeddings editor": "Embeddings editor",
    "Allows you to manually edit textual inversion embeddings using sliders.": "Allows you to manually edit textual inversion embeddings using sliders.",
    "embedding-inspector": "embedding-inspector",
    "Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.": "Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.",
    "Merge Board": "Merge Board",
    "Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.": "Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.",
    "Model Converter": "Model Converter",
    "Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.": "Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.",
    "Kohya-ss Additional Networks": "Kohya-ss Additional Networks",
    "Allows the Web UI to use LoRAs (1.X and 2.X) to generate images. Also allows editing .safetensors networks prompt metadata.": "Allows the Web UI to use LoRAs (1.X and 2.X) to generate images. Also allows editing .safetensors networks prompt metadata.",
    "Merge Block Weighted": "Merge Block Weighted",
    "Merge models with separate rate for each 25 U-Net block (input, middle, output).": "Merge models with separate rate for each 25 U-Net block (input, middle, output).",
    "Embedding Merge": "Embedding Merge",
    "Merging Textual Inversion embeddings at runtime from string literals. Phrases and weight values also supported.": "Merging Textual Inversion embeddings at runtime from string literals. Phrases and weight values also supported.",
    "SuperMerger": "SuperMerger",
    "Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more.": "Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more.",
    "LoRA Block Weight": "LoRA Block Weight",
    "Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.": "Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.",
    "Image browser": "Image browser",
    "Provides an interface to browse created images in the web browser.": "Provides an interface to browse created images in the web browser.",
    "Inspiration": "Inspiration",
    "Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.": "Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.",
    "Artists to study": "Artists to study",
    "Shows a gallery of generated pictures by artists separated into categories.": "Shows a gallery of generated pictures by artists separated into categories.",
    "Prompt Gallery": "Prompt Gallery",
    "Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.": "Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.",
    "Infinity Grid Generator": "Infinity Grid Generator",
    "Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.": "Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.",
    "Config-Presets": "Config-Presets",
    "Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.": "Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.",
    "Preset Utilities": "Preset Utilities",
    "Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit)": "Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit)",
    "openOutpaint extension": "openOutpaint extension",
    "A tab with the full openOutpaint UI. Run with the --api flag.": "A tab with the full openOutpaint UI. Run with the --api flag.",
    "quick-css": "quick-css",
    "Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.": "Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.",
    "Aspect Ratio selector": "Aspect Ratio selector",
    "Adds image aspect ratio selector buttons.": "Adds image aspect ratio selector buttons.",
    "Catppuccin Theme": "Catppuccin Theme",
    "Adds various custom themes": "Adds various custom themes",
    "Kitchen Theme": "Kitchen Theme",
    "Custom Theme.": "Custom Theme.",
    "Bilingual Localization": "Bilingual Localization",
    "Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.": "Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.",
    "Dynamic Prompts": "Dynamic Prompts",
    "Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.": "Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.",
    "Unprompted": "Unprompted",
    "Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.": "Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.",
    "StylePile": "StylePile",
    "An easy way to mix and match elements to prompts that affect the style of the result.": "An easy way to mix and match elements to prompts that affect the style of the result.",
    "Booru tag autocompletion": "Booru tag autocompletion",
    "Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.": "Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.",
    "novelai-2-local-prompt": "novelai-2-local-prompt",
    "Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.": "Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.",
    "tokenizer": "tokenizer",
    "Adds a tab that lets you preview how CLIP model would tokenize your text.": "Adds a tab that lets you preview how CLIP model would tokenize your text.",
    "Randomize": "Randomize",
    "Allows for random parameters during txt2img generation. This script will function with others as well. Original author: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize": "Allows for random parameters during txt2img generation. This script will function with others as well. Original author: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize",
    "conditioning-highres-fix": "conditioning-highres-fix",
    "This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt": "This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt",
    "model-keyword": "model-keyword",
    "Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.": "Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.",
    "Prompt Generator": "Prompt Generator",
    "generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.": "generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.",
    "Promptgen": "Promptgen",
    "Use transformers models to generate prompts.": "Use transformers models to generate prompts.",
    "text2prompt": "text2prompt",
    "Generates anime tags using databases and models for tokenizing.": "Generates anime tags using databases and models for tokenizing.",
    "Prompt Translator": "Prompt Translator",
    "A integrated translator for translating prompts to English using Deepl or Baidu.": "A integrated translator for translating prompts to English using Deepl or Baidu.",
    "Deforum": "Deforum",
    "The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.": "The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.",
    "Animator": "Animator",
    "A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.": "A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.",
    "gif2gif": "gif2gif",
    "A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif": "A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif",
    "Video Loopback": "Video Loopback",
    "A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.": "A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.",
    "seed travel": "seed travel",
    "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.": "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.",
    "shift-attention": "shift-attention",
    "Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.": "Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.",
    "prompt travel": "prompt travel",
    "Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.": "Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.",
    "Steps Animation": "Steps Animation",
    "Create animation sequence from denoised intermediate steps.": "Create animation sequence from denoised intermediate steps.",
    "auto-sd-paint-ext": "auto-sd-paint-ext",
    "Krita Plugin.": "Krita Plugin.",
    "Detection Detailer": "Detection Detailer",
    "An object detection and auto-mask extension for Stable Diffusion web UI.": "An object detection and auto-mask extension for Stable Diffusion web UI.",
    "Batch Face Swap": "Batch Face Swap",
    "Automatically detects faces and replaces them.": "Automatically detects faces and replaces them.",
    "Depth Maps": "Depth Maps",
    "Depth Maps, Stereo Image, 3D Mesh and Video generator extension.": "Depth Maps, Stereo Image, 3D Mesh and Video generator extension.",
    "multi-subject-render": "multi-subject-render",
    "It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.": "It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.",
    "depthmap2mask": "depthmap2mask",
    "Create masks for img2img based on a depth estimation made by MiDaS.": "Create masks for img2img based on a depth estimation made by MiDaS.",
    "ABG_extension": "ABG_extension",
    "Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.": "Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.",
    "Pixelization": "Pixelization",
    "Using pre-trained models, produce pixel art out of images in the extras tab.": "Using pre-trained models, produce pixel art out of images in the extras tab.",
    "haku-img": "haku-img",
    "Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.": "Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.",
    "Asymmetric Tiling": "Asymmetric Tiling",
    "An always visible script extension to configure seamless image tiling independently for the X and Y axes.": "An always visible script extension to configure seamless image tiling independently for the X and Y axes.",
    "Latent Mirroring": "Latent Mirroring",
    "Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections": "Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections",
    "Sonar": "Sonar",
    "Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.": "Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.",
    "Depth Image I/O": "Depth Image I/O",
    "An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.": "An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.",
    "Ultimate SD Upscale": "Ultimate SD Upscale",
    "More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).": "More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).",
    "Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.": "Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.",
    "Dynamic Thresholding": "Dynamic Thresholding",
    "Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.": "Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.",
    "anti-burn": "anti-burn",
    "Smoothing generated images by skipping a few very last steps and averaging together some images before them.": "Smoothing generated images by skipping a few very last steps and averaging together some images before them.",
    "sd-webui-controlnet": "sd-webui-controlnet",
    "WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.": "WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.",
    "Latent Couple": "Latent Couple",
    "An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts. Note: New maintainer, uninstall prev. ext if needed.": "An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts. Note: New maintainer, uninstall prev. ext if needed.",
    "Composable LoRA": "Composable LoRA",
    "Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.": "Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.",
    "Auto TLS-HTTPS": "Auto TLS-HTTPS",
    "Allows you to easily, or even completely automatically start using HTTPS.": "Allows you to easily, or even completely automatically start using HTTPS.",
    "booru2prompt": "booru2prompt",
    "This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.": "This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.",
    "Gelbooru Prompt": "Gelbooru Prompt",
    "Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui": "Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui",
    "NSFW checker": "NSFW checker",
    "Replaces NSFW images with black.": "Replaces NSFW images with black.",
    "Diffusion Defender": "Diffusion Defender",
    "Prompt blacklist, find and replace, for semi-private and public instances.": "Prompt blacklist, find and replace, for semi-private and public instances.",
    "DH Patch": "DH Patch",
    "Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.": "Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.",
    "Riffusion": "Riffusion",
    "Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.": "Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.",
    "Save Intermediate Images": "Save Intermediate Images",
    "Save intermediate images during the sampling process. You can also make videos from the intermediate images.": "Save intermediate images during the sampling process. You can also make videos from the intermediate images.",
    "Add image number to grid": "Add image number to grid",
    "Add the image's number to its picture in the grid.": "Add the image's number to its picture in the grid.",
    "Multiple Hypernetworks": "Multiple Hypernetworks",
    "Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.": "Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.",
    "System Info": "System Info",
    "System Info tab for WebUI which shows realtime information of the server. Also supports sending crowdsourced inference data as an option.": "System Info tab for WebUI which shows realtime information of the server. Also supports sending crowdsourced inference data as an option.",
    "OpenPose Editor": "OpenPose Editor",
    "This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.": "This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.",
    "Stable Horde Worker": "Stable Horde Worker",
    "Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.": "Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.",
    "Stable Horde Client": "Stable Horde Client",
    "Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.": "Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.",
    "Discord Rich Presence": "Discord Rich Presence",
    "Provides connection to Discord RPC, showing a fancy table in the user profile.": "Provides connection to Discord RPC, showing a fancy table in the user profile.",
    "mine-diffusion": "mine-diffusion",
    "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.": "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.",
    "Aesthetic Image Scorer": "Aesthetic Image Scorer",
    "Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer": "Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer",
    "Aesthetic Scorer": "Aesthetic Scorer",
    "Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.": "Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.",
    "cafe-aesthetic": "cafe-aesthetic",
    "Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.": "Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.",
    "Clip Interrogator": "Clip Interrogator",
    "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.": "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.",
    "Visualize Cross-Attention": "Visualize Cross-Attention",
    "Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.": "Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.",
    "DAAM": "DAAM",
    "DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image.": "DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image.",
    "Dump U-Net": "Dump U-Net",
    "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547": "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547",
    "posex": "posex",
    "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.": "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.",
    "LLuL": "LLuL",
    "Local Latent Upscaler. Target an area to selectively enhance details.": "Local Latent Upscaler. Target an area to selectively enhance details.",
    "CFG-Schedule-for-Automatic1111-SD": "CFG-Schedule-for-Automatic1111-SD",
    "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.": "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.",
    "a1111-sd-webui-locon": "a1111-sd-webui-locon",
    "loading LoCon/LyCoris networks in webui. NOTE: depreciated in favor of https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris, due to error with with other lora ext.": "loading LoCon/LyCoris networks in webui. NOTE: depreciated in favor of https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris, due to error with with other lora ext.",
    "ebsynth_utility": "ebsynth_utility",
    "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.": "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.",
    "VRAM Estimator": "VRAM Estimator",
    "Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.": "Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.",
    "MultiDiffusion with Tiled VAE": "MultiDiffusion with Tiled VAE",
    "Seamless Image Fusion, along with vram efficient tiled vae script.": "Seamless Image Fusion, along with vram efficient tiled vae script.",
    "3D Model&Pose Loader": "3D Model&Pose Loader",
    "Load your 3D model/animation inside webui, or edit model pose as well, then send screenshot to txt2img or img2img to ControlNet.": "Load your 3D model/animation inside webui, or edit model pose as well, then send screenshot to txt2img or img2img to ControlNet.",
    "Corridor Crawler Outpainting": "Corridor Crawler Outpainting",
    "Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.": "Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.",
    "Panorama Viewer": "Panorama Viewer",
    "Provides a tab to display equirectangular images in interactive 3d-view.": "Provides a tab to display equirectangular images in interactive 3d-view.",
    "db-storage1111": "db-storage1111",
    "Allows to store pictures and their metadata in a database. (supports MongoDB)": "Allows to store pictures and their metadata in a database. (supports MongoDB)",
    "stable-diffusion-webui-rembg": "stable-diffusion-webui-rembg",
    "Removes backgrounds from pictures.": "Removes backgrounds from pictures.",
    "sd-webui-tunnels": "sd-webui-tunnels",
    "Add alternatives to the default tunneling methods. (including cloudflared)": "Add alternatives to the default tunneling methods. (including cloudflared)",
    "3D Openpose Editor": "3D Openpose Editor",
    "Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.": "Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.",
    "sd-webui-enable-checker": "sd-webui-enable-checker",
    "Switch background color by clicking the Enable buttons in SD Web UI": "Switch background color by clicking the Enable buttons in SD Web UI",
    "stable-diffusion-webui-state": "stable-diffusion-webui-state",
    "Preserves the UI state after reload/restart.": "Preserves the UI state after reload/restart.",
    "text2video": "text2video",
    "Implementation of text2video diffusion models, such as ModelScope or VideoCrafter, using only Auto1111 webui dependencies.": "Implementation of text2video diffusion models, such as ModelScope or VideoCrafter, using only Auto1111 webui dependencies.",
    "Aspect Ratio Helper": "Aspect Ratio Helper",
    "Easily scale dimensions while retaining the same aspect ratio.": "Easily scale dimensions while retaining the same aspect ratio.",
    "Canvas Zoom": "Canvas Zoom",
    "Added the ability to scale Inpaint, Sketch, and Inpaint Sketch. Adds useful hotkeys": "Added the ability to scale Inpaint, Sketch, and Inpaint Sketch. Adds useful hotkeys",
    "Regional Prompter": "Regional Prompter",
    "Specify different prompts for different regions; an alternative method and potential improvement to latent couple.": "Specify different prompts for different regions; an alternative method and potential improvement to latent couple.",
    "Auto Translate": "Auto Translate",
    "Language extension allows users to write prompts in their native language and automatically translate UI, without the need to manually download configuration files. New plugins can also be translated.": "Language extension allows users to write prompts in their native language and automatically translate UI, without the need to manually download configuration files. New plugins can also be translated.",
    "Allows users to generate images based on prompts written in 50 different languages. It translates the prompts to english from a selected source language before generating the image.": "Allows users to generate images based on prompts written in 50 different languages. It translates the prompts to english from a selected source language before generating the image.",
    "Abysz LAB": "Abysz LAB",
    "Temporal Coherence Tools": "Temporal Coherence Tools",
    "Negative Prompt Weight": "Negative Prompt Weight",
    "Allows users to set a global weight for the negative prompt.": "Allows users to set a global weight for the negative prompt.",
    "Discord - Dynamic Rich Presence": "Discord - Dynamic Rich Presence",
    "Will show your current sd model selected. Also showing if you are idle, or generating something - in that case, total image/s being generated.": "Will show your current sd model selected. Also showing if you are idle, or generating something - in that case, total image/s being generated.",
    "PBRemTools": "PBRemTools",
    "PBRemTools(Precise background remover tools) is a collection of tools to crop backgrounds from a single picture with high accuracy.": "PBRemTools(Precise background remover tools) is a collection of tools to crop backgrounds from a single picture with high accuracy.",
    "a1111-sd-webui-lycoris": "a1111-sd-webui-lycoris",
    "Load lycoris: non-conventional rank adapters; in separate networks gallery tab.": "Load lycoris: non-conventional rank adapters; in separate networks gallery tab.",
    "zh_CN Localization": "zh_CN Localization",
    "Simplified Chinese localization, recommend using with Bilingual Localization.": "Simplified Chinese localization, recommend using with Bilingual Localization.",
    "zh_TW Localization": "zh_TW Localization",
    "Traditional Chinese localization": "Traditional Chinese localization",
    "ko_KR Localization": "ko_KR Localization",
    "Korean localization": "Korean localization",
    "th_TH Localization": "th_TH Localization",
    "Thai localization": "Thai localization",
    "es_ES Localization": "es_ES Localization",
    "Spanish localization": "Spanish localization",
    "it_IT Localization": "it_IT Localization",
    "Italian localization": "Italian localization",
    "de_DE Localization": "de_DE Localization",
    "German localization": "German localization",
    "ja_JP Localization": "ja_JP Localization",
    "Japanese localization": "Japanese localization",
    "pt_BR Localization": "pt_BR Localization",
    "Brazillian portuguese localization": "Brazillian portuguese localization",
    "tr_TR Localization": "tr_TR Localization",
    "Turkish localization": "Turkish localization",
    "no_NO Localization": "no_NO Localization",
    "Norwegian localization": "Norwegian localization",
    "ru_RU Localization": "ru_RU Localization",
    "Russian localization": "Russian localization",
    "fi_FI Localization": "fi_FI Localization",
    "Finnish localization": "Finnish localization",
    "zh_Hans Localization": "zh_Hans Localization",
    "Simplified Chinese localization.": "Simplified Chinese localization.",
    "old localizations": "old localizations",
    "Old unmaintained localizations that used to be a part of main repository": "Old unmaintained localizations that used to be a part of main repository",
    "openOutpaint": "openOutpaint",
    "Send to openOutpaint": "Send to openOutpaint",
    "openOutpaint-webUI-extension": "openOutpaint-webUI-extension",
    "Refresh openOutpaint": "Refresh openOutpaint",
    "https://github.com/zero01101/openOutpaint-webUI-extension.git": "https://github.com/zero01101/openOutpaint-webUI-extension.git",
    "3D Model Loader": "3D Model Loader",
    "Target": "Target",
    "Light": "Light",
    "Model": "Model",
    "Position/Rotate X": "Position/Rotate X",
    "Position/Rotate Y": "Position/Rotate Y",
    "Position/Rotate Z": "Position/Rotate Z",
    "Show Ground": "Show Ground",
    "Show Grid": "Show Grid",
    "Show Axis": "Show Axis",
    "Background Color": "Background Color",
    "Ground Color": "Ground Color",
    "Light Color": "Light Color",
    "Model Scale": "Model Scale",
    "Load Model": "Load Model",
    "Reset": "Reset",
    "Send to": "Send to",
    "Play/Pause": "Play/Pause",
    "Stop": "Stop",
    "3D Model": "3D Model",
    "Canvas Background Color": "Canvas Background Color",
    "Canvas Ground Color": "Canvas Ground Color",
    "Canvas Width": "Canvas Width",
    "Canvas Height": "Canvas Height",
    "sd-3dmodel-loader": "sd-3dmodel-loader",
    "https://github.com/jtydhr88/sd-3dmodel-loader.git": "https://github.com/jtydhr88/sd-3dmodel-loader.git",
    "Conditioning Highres": "Conditioning Highres",
    "Conditioning Highres.fix strength (for sd-v1-5-inpainting)": "Conditioning Highres.fix strength (for sd-v1-5-inpainting)",
    "Cond.fix: Disabled (none)": "Cond.fix: Disabled (none)",
    "Cond.fix: Empty": "Cond.fix: Empty",
    "Cond.fix: Lowest": "Cond.fix: Lowest",
    "Cond.fix: Low": "Cond.fix: Low",
    "Cond.fix: Medium": "Cond.fix: Medium",
    "Cond.fix: High (recommended)": "Cond.fix: High (recommended)",
    "Cond.fix: Highest": "Cond.fix: Highest",
    "Cond.fix: Full": "Cond.fix: Full",
    "stable-diffusion-webui-conditioning-highres-fix": "stable-diffusion-webui-conditioning-highres-fix",
    "https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix.git": "https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix.git",
    "Info, Links and Help": "Info, Links and Help",
    "Made by": "Made by",
    "deforum.github.io": "deforum.github.io",
    ", port for AUTOMATIC1111's webui maintained by": ", port for AUTOMATIC1111's webui maintained by",
    "kabachuha": "kabachuha",
    "FOR HELP CLICK HERE": "FOR HELP CLICK HERE",
    "The code for this extension:": "The code for this extension:",
    "here": "here",
    "Join the": "Join the",
    "official Deforum Discord": "official Deforum Discord",
    "to share your creations and suggestions.": "to share your creations and suggestions.",
    "Official Deforum Wiki:": "Official Deforum Wiki:",
    "Anime-inclined great guide (by FizzleDorf) with lots of examples:": "Anime-inclined great guide (by FizzleDorf) with lots of examples:",
    "For advanced keyframing with Math functions, see": "For advanced keyframing with Math functions, see",
    "Alternatively, use": "Alternatively, use",
    "sd-parseq": "sd-parseq",
    "as a UI to define your animation schedules (see the Parseq section in the Keyframes tab).": "as a UI to define your animation schedules (see the Parseq section in the Keyframes tab).",
    "framesync.xyz": "framesync.xyz",
    "is also a good option, it makes compact math formulae for Deforum keyframes by selecting various waveforms.": "is also a good option, it makes compact math formulae for Deforum keyframes by selecting various waveforms.",
    "The other site allows for making keyframes using": "The other site allows for making keyframes using",
    "interactive splines and Bezier curves": "interactive splines and Bezier curves",
    "(select Disco output format).": "(select Disco output format).",
    "If you want to use Width/Height which are not multiples of 64, please change noise_type to 'Uniform', in Keyframes --> Noise.": "If you want to use Width/Height which are not multiples of 64, please change noise_type to 'Uniform', in Keyframes --> Noise.",
    "If you liked this extension, please": "If you liked this extension, please",
    "give it a star on GitHub": "give it a star on GitHub",
    "!": "!",
    "Keyframes": "Keyframes",
    "Prompts": "Prompts",
    "Init": "Init",
    "ControlNet": "ControlNet",
    "Hybrid Video": "Hybrid Video",
    "Output": "Output",
    "Batch name": "Batch name",
    "Restore Faces, Tiling & more": "Restore Faces, Tiling & more",
    "Restore Faces": "Restore Faces",
    "DDIM Eta": "DDIM Eta",
    "Pix2Pix img CFG schedule": "Pix2Pix img CFG schedule",
    "Resume & Run from file": "Resume & Run from file",
    "Run from Settings file": "Run from Settings file",
    "Resume Animation": "Resume Animation",
    "Custom settings file": "Custom settings file",
    "Resume from timestring": "Resume from timestring",
    "Resume timestring": "Resume timestring",
    "Animation mode": "Animation mode",
    "2D": "2D",
    "3D": "3D",
    "Interpolation": "Interpolation",
    "Video Input": "Video Input",
    "Border": "Border",
    "replicate": "replicate",
    "wrap": "wrap",
    "Cadence": "Cadence",
    "Max frames": "Max frames",
    "Guided Images": "Guided Images",
    "*READ ME before you use this mode!*": "*READ ME before you use this mode!*",
    "You can use this as a guided image tool or as a looper depending on your settings in the keyframe images field. \n                               Set the keyframes and the images that you want to show up. \n                               Note: the number of frames between each keyframe should be greater than the tweening frames.": "You can use this as a guided image tool or as a looper depending on your settings in the keyframe images field. \n                               Set the keyframes and the images that you want to show up. \n                               Note: the number of frames between each keyframe should be greater than the tweening frames.",
    "Prerequisites and Important Info:": "Prerequisites and Important Info:",
    "This mode works ONLY with 2D/3D animation modes. Interpolation and Video Input modes aren't supported.": "This mode works ONLY with 2D/3D animation modes. Interpolation and Video Input modes aren't supported.",
    "Set Init tab's strength slider greater than 0. Recommended value (.65 - .80).": "Set Init tab's strength slider greater than 0. Recommended value (.65 - .80).",
    "Set 'seed_behavior' to 'schedule' under the Seed Scheduling section below.": "Set 'seed_behavior' to 'schedule' under the Seed Scheduling section below.",
    "Looping recommendations:": "Looping recommendations:",
    "seed_schedule should start and end on the same seed.": "seed_schedule should start and end on the same seed.",
    "Example: seed_schedule could use 0:(5), 1:(-1), 219:(-1), 220:(5)": "Example: seed_schedule could use 0:(5), 1:(-1), 219:(-1), 220:(5)",
    "The 1st and last keyframe images should match.": "The 1st and last keyframe images should match.",
    "Set your total number of keyframes to be 21 more than the last inserted keyframe image.": "Set your total number of keyframes to be 21 more than the last inserted keyframe image.",
    "Example: Default args should use 221 as total keyframes.": "Example: Default args should use 221 as total keyframes.",
    "Prompts are stored in JSON format. If you've got an error, check it in validator,": "Prompts are stored in JSON format. If you've got an error, check it in validator,",
    "like here": "like here",
    "Enable guided images mode": "Enable guided images mode",
    "Images to use for keyframe guidance": "Images to use for keyframe guidance",
    "Guided images schedules": "Guided images schedules",
    "Image strength schedule": "Image strength schedule",
    "Blend factor max": "Blend factor max",
    "Blend factor slope": "Blend factor slope",
    "Tweening frames schedule": "Tweening frames schedule",
    "Color correction factor": "Color correction factor",
    "Strength": "Strength",
    "CFG": "CFG",
    "SubSeed": "SubSeed",
    "Step": "Step",
    "Checkpoint": "Checkpoint",
    "CLIP Skip": "CLIP Skip",
    "Strength schedule": "Strength schedule",
    "CFG scale schedule": "CFG scale schedule",
    "Seed behavior": "Seed behavior",
    "iter": "iter",
    "fixed": "fixed",
    "ladder": "ladder",
    "alternate": "alternate",
    "schedule": "schedule",
    "Seed iter N": "Seed iter N",
    "Seed schedule": "Seed schedule",
    "Enable Subseed scheduling": "Enable Subseed scheduling",
    "Subseed schedule": "Subseed schedule",
    "Subseed strength schedule": "Subseed strength schedule",
    "Enable steps scheduling": "Enable steps scheduling",
    "Steps schedule": "Steps schedule",
    "Enable sampler scheduling": "Enable sampler scheduling",
    "Sampler schedule": "Sampler schedule",
    "Enable checkpoint scheduling": "Enable checkpoint scheduling",
    "Checkpoint schedule": "Checkpoint schedule",
    "Enable CLIP skip scheduling": "Enable CLIP skip scheduling",
    "CLIP skip schedule": "CLIP skip schedule",
    "Motion": "Motion",
    "Noise": "Noise",
    "Coherence": "Coherence",
    "Anti Blur": "Anti Blur",
    "Angle": "Angle",
    "Zoom": "Zoom",
    "Translation X": "Translation X",
    "Translation Y": "Translation Y",
    "Translation Z": "Translation Z",
    "Rotation 3D X": "Rotation 3D X",
    "Rotation 3D Y": "Rotation 3D Y",
    "Rotation 3D Z": "Rotation 3D Z",
    "Depth Warping & FOV": "Depth Warping & FOV",
    "Depth Warping": "Depth Warping",
    "Field Of View": "Field Of View",
    "Use depth warping": "Use depth warping",
    "MiDaS weight": "MiDaS weight",
    "Padding mode": "Padding mode",
    "border": "border",
    "reflection": "reflection",
    "zeros": "zeros",
    "Sampling mode": "Sampling mode",
    "bicubic": "bicubic",
    "bilinear": "bilinear",
    "nearest": "nearest",
    "FOV schedule": "FOV schedule",
    "Near schedule": "Near schedule",
    "Far schedule": "Far schedule",
    "Perspective Flip": "Perspective Flip",
    "Enable perspective flip": "Enable perspective flip",
    "Perspective flip theta": "Perspective flip theta",
    "Perspective flip phi": "Perspective flip phi",
    "Perspective flip gamma": "Perspective flip gamma",
    "Perspective flip fv": "Perspective flip fv",
    "Noise type": "Noise type",
    "perlin": "perlin",
    "Noise schedule": "Noise schedule",
    "Perlin octaves": "Perlin octaves",
    "Perlin persistence": "Perlin persistence",
    "Color coherence": "Color coherence",
    "Match Frame 0 HSV": "Match Frame 0 HSV",
    "Match Frame 0 LAB": "Match Frame 0 LAB",
    "Match Frame 0 RGB": "Match Frame 0 RGB",
    "Color force Grayscale": "Color force Grayscale",
    "Color coherence video every N frames": "Color coherence video every N frames",
    "Contrast schedule": "Contrast schedule",
    "Reroll blank frames": "Reroll blank frames",
    "reroll": "reroll",
    "interrupt": "interrupt",
    "Kernel schedule": "Kernel schedule",
    "Sigma schedule": "Sigma schedule",
    "Amount schedule": "Amount schedule",
    "Threshold schedule": "Threshold schedule",
    "*Important* notes on Prompts": "*Important* notes on Prompts",
    "Please always keep values in math functions above 0.": "Please always keep values in math functions above 0.",
    "There is *no* Batch mode like in vanilla deforum. Please Use the txt2img tab for that.": "There is *no* Batch mode like in vanilla deforum. Please Use the txt2img tab for that.",
    "For negative prompts, please write your positive prompt, then --neg ugly, text, assymetric, or any other negative tokens of your choice. OR:": "For negative prompts, please write your positive prompt, then --neg ugly, text, assymetric, or any other negative tokens of your choice. OR:",
    "Use the negative_prompts field to automatically append all words as a negative prompt. *Don't* add --neg in the negative_prompts field!": "Use the negative_prompts field to automatically append all words as a negative prompt. *Don't* add --neg in the negative_prompts field!",
    "Prompts are stored in JSON format. If you've got an error, check it in a": "Prompts are stored in JSON format. If you've got an error, check it in a",
    "JSON Validator": "JSON Validator",
    "Prompts positive": "Prompts positive",
    "Prompts negative": "Prompts negative",
    "Composable Mask scheduling": "Composable Mask scheduling",
    "To enable, check use_mask in the Init tab": "To enable, check use_mask in the Init tab",
    "Supports boolean operations: (! - negation, & - and, | - or, ^ - xor, \\ - difference, () - nested operations)": "Supports boolean operations: (! - negation, & - and, | - or, ^ - xor, \\ - difference, () - nested operations)",
    "default variables: in \\{\\}, like \\{init_mask\\}, \\{video_mask\\}, \\{everywhere\\}": "default variables: in \\{\\}, like \\{init_mask\\}, \\{video_mask\\}, \\{everywhere\\}",
    "masks from files: in [], like [mask1.png]": "masks from files: in [], like [mask1.png]",
    "description-based:": "description-based:",
    "word masks": "word masks",
    "in <>, like <apple>, <hair>": "in <>, like <apple>, <hair>",
    "Mask schedule": "Mask schedule",
    "Use noise mask": "Use noise mask",
    "Noise mask schedule": "Noise mask schedule",
    "Image Init": "Image Init",
    "Video Init": "Video Init",
    "Mask Init": "Mask Init",
    "Use init": "Use init",
    "Strength 0 no init": "Strength 0 no init",
    "Init image": "Init image",
    "Video init path": "Video init path",
    "Extract from frame": "Extract from frame",
    "Extract to frame": "Extract to frame",
    "Extract nth frame": "Extract nth frame",
    "Overwrite extracted frames": "Overwrite extracted frames",
    "Use mask video": "Use mask video",
    "Video mask path": "Video mask path",
    "Use mask": "Use mask",
    "Use alpha as mask": "Use alpha as mask",
    "Invert mask": "Invert mask",
    "Overlay mask": "Overlay mask",
    "Mask file": "Mask file",
    "Mask overlay blur": "Mask overlay blur",
    "Mask fill": "Mask fill",
    "Full res mask": "Full res mask",
    "Full res mask padding": "Full res mask padding",
    "Parseq": "Parseq",
    "Use an": "Use an",
    "sd-parseq manifest": "sd-parseq manifest",
    "for your animation (leave blank to ignore).": "for your animation (leave blank to ignore).",
    "Note that parseq overrides:": "Note that parseq overrides:",
    "Run: seed, subseed, subseed strength.": "Run: seed, subseed, subseed strength.",
    "Keyframes: generation settings (noise, strength, contrast, scale).": "Keyframes: generation settings (noise, strength, contrast, scale).",
    "Keyframes: motion parameters for 2D and 3D (angle, zoom, translation, rotation, perspective flip).": "Keyframes: motion parameters for 2D and 3D (angle, zoom, translation, rotation, perspective flip).",
    "Parseq does": "Parseq does",
    "not": "not",
    "override:": "override:",
    "Run: Sampler, Width, Height, tiling, resize seed.": "Run: Sampler, Width, Height, tiling, resize seed.",
    "Keyframes: animation settings (animation mode, max frames, border)": "Keyframes: animation settings (animation mode, max frames, border)",
    "Keyframes: coherence (color coherence & cadence)": "Keyframes: coherence (color coherence & cadence)",
    "Keyframes: depth warping": "Keyframes: depth warping",
    "Output settings: all settings (including fps and max frames)": "Output settings: all settings (including fps and max frames)",
    "Parseq Manifest (JSON or URL)": "Parseq Manifest (JSON or URL)",
    "Use delta values for movement parameters": "Use delta values for movement parameters",
    "Requires the": "Requires the",
    "extension to be installed.": "extension to be installed.",
    "Due to ControlNet base extension's inner works it needs its models to be located at 'extensions/deforum-for-automatic1111-webui/models'. So copy, symlink or move them there until a more elegant solution is found. And, as of now, it requires use_init checked for the first run. The ControlNet extension version used in the dev process is a24089a62e70a7fae44b7bf35b51fd584dd55e25, if even with all the other options above used it still breaks, upgrade/downgrade your CN version to this one.": "Due to ControlNet base extension's inner works it needs its models to be located at 'extensions/deforum-for-automatic1111-webui/models'. So copy, symlink or move them there until a more elegant solution is found. And, as of now, it requires use_init checked for the first run. The ControlNet extension version used in the dev process is a24089a62e70a7fae44b7bf35b51fd584dd55e25, if even with all the other options above used it still breaks, upgrade/downgrade your CN version to this one.",
    "ControlNet not found. Please install it :)": "ControlNet not found. Please install it :)",
    "Please, change animation mode to 2D or 3D to enable Hybrid Mode": "Please, change animation mode to 2D or 3D to enable Hybrid Mode",
    "Info & Help": "Info & Help",
    "Hybrid Video Compositing in 2D/3D Mode": "Hybrid Video Compositing in 2D/3D Mode",
    "by": "by",
    "reallybigname": "reallybigname",
    "Composite video with previous frame init image in": "Composite video with previous frame init image in",
    "2D or 3D animation_mode": "2D or 3D animation_mode",
    "(not for Video Input mode)": "(not for Video Input mode)",
    "Uses your": "Uses your",
    "settings for": "settings for",
    "video_init_path, extract_nth_frame, overwrite_extracted_frames": "video_init_path, extract_nth_frame, overwrite_extracted_frames",
    "In Keyframes tab, you can also set": "In Keyframes tab, you can also set",
    "color_coherence": "color_coherence",
    "= '": "= '",
    "'": "'",
    "color_coherence_video_every_N_frames": "color_coherence_video_every_N_frames",
    "lets you only match every N frames": "lets you only match every N frames",
    "Color coherence may be used with hybrid composite off, to just use video color.": "Color coherence may be used with hybrid composite off, to just use video color.",
    "Hybrid motion may be used with hybrid composite off, to just use video motion.": "Hybrid motion may be used with hybrid composite off, to just use video motion.",
    "Hybrid Video Schedules": "Hybrid Video Schedules",
    "The alpha schedule controls overall alpha for video mix, whether using a composite mask or not.": "The alpha schedule controls overall alpha for video mix, whether using a composite mask or not.",
    "The": "The",
    "hybrid_comp_mask_blend_alpha_schedule": "hybrid_comp_mask_blend_alpha_schedule",
    "only affects the 'Blend'": "only affects the 'Blend'",
    "hybrid_comp_mask_type": "hybrid_comp_mask_type",
    "Mask contrast schedule is from 0-255. Normal is 1. Affects all masks.": "Mask contrast schedule is from 0-255. Normal is 1. Affects all masks.",
    "Autocontrast low/high cutoff schedules 0-100. Low 0 High 100 is full range.": "Autocontrast low/high cutoff schedules 0-100. Low 0 High 100 is full range.",
    "(": "(",
    "hybrid_comp_mask_auto_contrast": "hybrid_comp_mask_auto_contrast",
    "must be enabled": "must be enabled",
    ")": ")",
    "Click Here": "Click Here",
    "for more info/ a Guide.": "for more info/ a Guide.",
    "Hybrid Settings": "Hybrid Settings",
    "Generate inputframes": "Generate inputframes",
    "Hybrid composite": "Hybrid composite",
    "First frame as init image": "First frame as init image",
    "Motion use prev img": "Motion use prev img",
    "Hybrid motion": "Hybrid motion",
    "Optical Flow": "Optical Flow",
    "Perspective": "Perspective",
    "Affine": "Affine",
    "Flow method": "Flow method",
    "DIS Medium": "DIS Medium",
    "Farneback": "Farneback",
    "Comp mask type": "Comp mask type",
    "Depth": "Depth",
    "Video Depth": "Video Depth",
    "Blend": "Blend",
    "Difference": "Difference",
    "Comp mask equalize": "Comp mask equalize",
    "Before": "Before",
    "After": "After",
    "Both": "Both",
    "Comp mask auto contrast": "Comp mask auto contrast",
    "Comp mask inverse": "Comp mask inverse",
    "Comp save extra frames": "Comp save extra frames",
    "Hybrid Schedules": "Hybrid Schedules",
    "Comp alpha schedule": "Comp alpha schedule",
    "Comp mask blend alpha schedule": "Comp mask blend alpha schedule",
    "Comp mask contrast schedule": "Comp mask contrast schedule",
    "Comp mask auto contrast cutoff high schedule": "Comp mask auto contrast cutoff high schedule",
    "Comp mask auto contrast cutoff low schedule": "Comp mask auto contrast cutoff low schedule",
    "Humans Masking": "Humans Masking",
    "Generate human masks": "Generate human masks",
    "PNGs": "PNGs",
    "Video": "Video",
    "Video Output Settings": "Video Output Settings",
    "FPS": "FPS",
    "Output format": "Output format",
    "FFMPEG mp4": "FFMPEG mp4",
    "Add soundtrack": "Add soundtrack",
    "Init Video": "Init Video",
    "Soundtrack path": "Soundtrack path",
    "Skip video for run all": "Skip video for run all",
    "Store frames in ram": "Store frames in ram",
    "Save depth maps": "Save depth maps",
    "Make GIF": "Make GIF",
    "Upscale": "Upscale",
    "Upscale model": "Upscale model",
    "realesr-animevideov3": "realesr-animevideov3",
    "realesrgan-x4plus": "realesrgan-x4plus",
    "realesrgan-x4plus-anime": "realesrgan-x4plus-anime",
    "Upscale factor": "Upscale factor",
    "x2": "x2",
    "x3": "x3",
    "x4": "x4",
    "Keep Imgs": "Keep Imgs",
    "FFmpeg settings": "FFmpeg settings",
    "CRF": "CRF",
    "Preset": "Preset",
    "veryslow": "veryslow",
    "slower": "slower",
    "slow": "slow",
    "medium": "medium",
    "fast": "fast",
    "faster": "faster",
    "veryfast": "veryfast",
    "superfast": "superfast",
    "ultrafast": "ultrafast",
    "Location": "Location",
    "Frame Interoplation": "Frame Interoplation",
    "Video Upscaling": "Video Upscaling",
    "Frames to Video": "Frames to Video",
    "Important notes and Help": "Important notes and Help",
    "Use": "Use",
    "RIFE": "RIFE",
    "/": "/",
    "FILM": "FILM",
    "Frame Interpolation to smooth out, slow-mo (or both) any video.": "Frame Interpolation to smooth out, slow-mo (or both) any video.",
    "Supported engines:": "Supported engines:",
    "RIFE v4.6 and FILM.": "RIFE v4.6 and FILM.",
    "Important notes:": "Important notes:",
    "Frame Interpolation will *not* run if any of the following are enabled: 'Store frames in ram' / 'Skip video for run all'.": "Frame Interpolation will *not* run if any of the following are enabled: 'Store frames in ram' / 'Skip video for run all'.",
    "Audio (if provided) will *not* be transferred to the interpolated video if Slow-Mo is enabled.": "Audio (if provided) will *not* be transferred to the interpolated video if Slow-Mo is enabled.",
    "'add_soundtrack' and 'soundtrack_path' aren't being honoured in \"Interpolate an existing video\" mode. Original vid audio will be used instead with the same slow-mo rules above.": "'add_soundtrack' and 'soundtrack_path' aren't being honoured in \"Interpolate an existing video\" mode. Original vid audio will be used instead with the same slow-mo rules above.",
    "Engine": "Engine",
    "RIFE v4.6": "RIFE v4.6",
    "Slow Mo": "Slow Mo",
    "Interp X": "Interp X",
    "Slow-Mo X": "Slow-Mo X",
    "Interpolate an existing video": "Interpolate an existing video",
    "Video to Interpolate": "Video to Interpolate",
    "In Frame Count": "In Frame Count",
    "In FPS": "In FPS",
    "Interpolated Vid FPS": "Interpolated Vid FPS",
    "*Interpolate uploaded video*": "*Interpolate uploaded video*",
    "* check your CLI for outputs": "* check your CLI for outputs",
    "Video to Upscale": "Video to Upscale",
    "Upscale V2": "Upscale V2",
    "Upscale V1": "Upscale V1",
    "In Res": "In Res",
    "Out Res": "Out Res",
    "*Upscale uploaded video*": "*Upscale uploaded video*",
    "Path name modifier": "Path name modifier",
    "x0_pred": "x0_pred",
    "x": "x",
    "Important Notes:": "Important Notes:",
    "Enter relative to webui folder or Full-Absolute path, and make sure it ends with something like this: '20230124234916_%05d.png', just replace 20230124234916 with your batch ID. The %05d is important, don't forget it!": "Enter relative to webui folder or Full-Absolute path, and make sure it ends with something like this: '20230124234916_%05d.png', just replace 20230124234916 with your batch ID. The %05d is important, don't forget it!",
    "Image path": "Image path",
    "MP4 path": "MP4 path",
    "Render steps": "Render steps",
    "*Stitch frames to video*": "*Stitch frames to video*",
    "INVISIBLE": "INVISIBLE",
    "Mask contrast adjust": "Mask contrast adjust",
    "Mask brightness adjust": "Mask brightness adjust",
    "from_img2img_instead_of_link": "from_img2img_instead_of_link",
    "Perlin W": "Perlin W",
    "Perlin H": "Perlin H",
    "Filename format": "Filename format",
    "save_settings": "save_settings",
    "save_samples": "save_samples",
    "display_samples": "display_samples",
    "Subseed controls & More": "Subseed controls & More",
    "Enable subseed controls": "Enable subseed controls",
    "N Batch": "N Batch",
    "Save sample per step": "Save sample per step",
    "Show sample per step": "Show sample per step",
    "Click here after the generation to show the video": "Click here after the generation to show the video",
    "Close the video": "Close the video",
    "Deforum extension for auto1111 — version 2.2b": "Deforum extension for auto1111 — version 2.2b",
    "* Paths can be relative to webui folder OR full - absolute": "* Paths can be relative to webui folder OR full - absolute",
    "General Settings File": "General Settings File",
    "Save Settings": "Save Settings",
    "Load Settings": "Load Settings",
    "Video Settings File": "Video Settings File",
    "Save Video Settings": "Save Video Settings",
    "Load Video Settings": "Load Video Settings",
    "deforum-for-automatic1111-webui": "deforum-for-automatic1111-webui",
    "https://github.com/deforum-art/deforum-for-automatic1111-webui.git": "https://github.com/deforum-art/deforum-for-automatic1111-webui.git",
    "Enable pixelization": "Enable pixelization",
    "Keep resolution": "Keep resolution",
    "Pixel size": "Pixel size",
    "stable-diffusion-webui-pixelization": "stable-diffusion-webui-pixelization",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui-pixelization.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-pixelization.git",
    "Enable": "Enable",
    "Highres. percentage chance": "Highres. percentage chance",
    "Highres. Denoising Strength": "Highres. Denoising Strength",
    "Highres. Width": "Highres. Width",
    "Highres. Height": "Highres. Height",
    "Stop at CLIP layers": "Stop at CLIP layers",
    "stable-diffusion-webui-randomize": "stable-diffusion-webui-randomize",
    "https://github.com/innightwolfsleep/stable-diffusion-webui-randomize.git": "https://github.com/innightwolfsleep/stable-diffusion-webui-randomize.git",
    "Comma separated list OR * for all": "Comma separated list OR * for all",
    "Range of stepped values (min, max, step)": "Range of stepped values (min, max, step)",
    "Float value from 0 to 1": "Float value from 0 to 1",
    "Loads weights from checkpoint before making images. You can either use hash or a part of filename (as seen in settings) for checkpoint name. Recommended to use with Y axis for less switching.": "Loads weights from checkpoint before making images. You can either use hash or a part of filename (as seen in settings) for checkpoint name. Recommended to use with Y axis for less switching.",
    "Create aesthetic embedding": "Create aesthetic embedding",
    "Open for Clip Aesthetic!": "Open for Clip Aesthetic!",
    "Aesthetic weight": "Aesthetic weight",
    "Aesthetic steps": "Aesthetic steps",
    "Aesthetic learning rate": "Aesthetic learning rate",
    "Slerp interpolation": "Slerp interpolation",
    "Aesthetic imgs embedding": "Aesthetic imgs embedding",
    "Aesthetic text for imgs": "Aesthetic text for imgs",
    "Slerp angle": "Slerp angle",
    "Is negative text": "Is negative text",
    "Create an aesthetic embedding out of any number of images": "Create an aesthetic embedding out of any number of images",
    "Create images embedding": "Create images embedding",
    "stable-diffusion-webui-aesthetic-gradients": "stable-diffusion-webui-aesthetic-gradients",
    "This text is used to rotate the feature space of the imgs embs": "This text is used to rotate the feature space of the imgs embs",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git",
    "width": "width",
    "height": "height",
    "Add": "Add",
    "Load from JSON": "Load from JSON",
    "Detect from image": "Detect from image",
    "Add Background image": "Add Background image",
    "json": "json",
    "Save JSON": "Save JSON",
    "Save PNG": "Save PNG",
    "openpose-editor": "openpose-editor",
    "https://github.com/fkunn1326/openpose-editor.git": "https://github.com/fkunn1326/openpose-editor.git",
    "Smart Preprocess": "Smart Preprocess",
    "sd_smartprocess": "sd_smartprocess",
    "Rename images": "Rename images",
    "Directories": "Directories",
    "Cropping": "Cropping",
    "Output Size": "Output Size",
    "Pad Images": "Pad Images",
    "Crop Images": "Crop Images",
    "Captions": "Captions",
    "Generate Captions": "Generate Captions",
    "Max Caption Length (0=unlimited)": "Max Caption Length (0=unlimited)",
    "Existing Caption Action": "Existing Caption Action",
    "Add CLIP results to Caption": "Add CLIP results to Caption",
    "Number of CLIP beams": "Number of CLIP beams",
    "CLIP Minimum length": "CLIP Minimum length",
    "CLIP Maximum length": "CLIP Maximum length",
    "Use v2 CLIP Model": "Use v2 CLIP Model",
    "Append Flavor tags from CLIP": "Append Flavor tags from CLIP",
    "Max flavors to append.": "Max flavors to append.",
    "Append Medium tags from CLIP": "Append Medium tags from CLIP",
    "Append Movement tags from CLIP": "Append Movement tags from CLIP",
    "Append Artist tags from CLIP": "Append Artist tags from CLIP",
    "Append Trending tags from CLIP": "Append Trending tags from CLIP",
    "Add WD14 Tags to Caption": "Add WD14 Tags to Caption",
    "Minimum Score for WD14 Tags": "Minimum Score for WD14 Tags",
    "Minimum Score for DeepDanbooru Tags": "Minimum Score for DeepDanbooru Tags",
    "Tags To Ignore": "Tags To Ignore",
    "Replace Class with Subject in Caption": "Replace Class with Subject in Caption",
    "Subject Class": "Subject Class",
    "Subject class to crop (leave blank to auto-detect)": "Subject class to crop (leave blank to auto-detect)",
    "Subject Name": "Subject Name",
    "Subject Name to replace class with in captions": "Subject Name to replace class with in captions",
    "Post-Processing": "Post-Processing",
    "Face Restore Model": "Face Restore Model",
    "Upscale and Resize": "Upscale and Resize",
    "Cancel": "Cancel",
    "https://github.com/d8ahazard/sd_smartprocess.git": "https://github.com/d8ahazard/sd_smartprocess.git",
    "Latent Mirror mode": "Latent Mirror mode",
    "Alternate Steps": "Alternate Steps",
    "Blend Average": "Blend Average",
    "Latent Mirror style": "Latent Mirror style",
    "Vertical Mirroring": "Vertical Mirroring",
    "Horizontal Mirroring": "Horizontal Mirroring",
    "Horizontal+Vertical Mirroring": "Horizontal+Vertical Mirroring",
    "90 Degree Rotation": "90 Degree Rotation",
    "180 Degree Rotation": "180 Degree Rotation",
    "Roll Channels": "Roll Channels",
    "X panning": "X panning",
    "Y panning": "Y panning",
    "Maximum steps fraction to mirror at": "Maximum steps fraction to mirror at",
    "SD-latent-mirroring": "SD-latent-mirroring",
    "https://github.com/dfaker/SD-latent-mirroring.git": "https://github.com/dfaker/SD-latent-mirroring.git",
    "Attention Heatmap": "Attention Heatmap",
    "Attention texts for visualization. (comma separated)": "Attention texts for visualization. (comma separated)",
    "Hide heatmap images": "Hide heatmap images",
    "Do not save heatmap images": "Do not save heatmap images",
    "Hide caption": "Hide caption",
    "Use grid (output to grid dir)": "Use grid (output to grid dir)",
    "Grid layout": "Grid layout",
    "Auto": "Auto",
    "Prevent Empty Spot": "Prevent Empty Spot",
    "Batch Length As Row": "Batch Length As Row",
    "Heatmap blend alpha": "Heatmap blend alpha",
    "Heatmap image scale": "Heatmap image scale",
    "Trace each layers": "Trace each layers",
    "Use layers as row instead of Batch Length": "Use layers as row instead of Batch Length",
    "stable-diffusion-webui-daam": "stable-diffusion-webui-daam",
    "https://github.com/toriato/stable-diffusion-webui-daam.git": "https://github.com/toriato/stable-diffusion-webui-daam.git",
    "Image Browser": "Image Browser",
    "txt2img-grids": "txt2img-grids",
    "img2img-grids": "img2img-grids",
    "Favorites": "Favorites",
    "Others": "Others",
    "Favorites path from settings: log/images": "Favorites path from settings: log/images",
    "Images directory": "Images directory",
    "Sub directory depth": "Sub directory depth",
    "Add to / replace in saved directories": "Add to / replace in saved directories",
    "Saved directories": "Saved directories",
    "Remove from saved directories": "Remove from saved directories",
    "Sub directories": "Sub directories",
    "Nothing selected": "Nothing selected",
    "Get sub directories": "Get sub directories",
    "Maintenance": "Maintenance",
    "⚠ Caution: You should only use these options if you know what you are doing. ⚠": "⚠ Caution: You should only use these options if you know what you are doing. ⚠",
    "Status:": "Status:",
    "Last message": "Last message",
    "Rebuild exif cache": "Rebuild exif cache",
    "Delete 0-entries from exif cache": "Delete 0-entries from exif cache",
    "Update directory names in database": "Update directory names in database",
    "From (full path)": "From (full path)",
    "to (full path)": "to (full path)",
    "Reapply ranking after moving files": "Reapply ranking after moving files",
    "Dropdown": "Dropdown",
    "First Page": "First Page",
    "Prev Page": "Prev Page",
    "Page Index": "Page Index",
    "Next Page": "Next Page",
    "End Page": "End Page",
    "ranking": "ranking",
    "Next Image After Ranking (To be implemented)": "Next Image After Ranking (To be implemented)",
    "delete next": "delete next",
    "Delete": "Delete",
    "also delete off-screen images": "also delete off-screen images",
    "Additional Generation Info": "Additional Generation Info",
    "sort by": "sort by",
    "Sort by": "Sort by",
    "path name": "path name",
    "date": "date",
    "aesthetic_score": "aesthetic_score",
    "cfg scale": "cfg scale",
    "steps": "steps",
    "seed": "seed",
    "sampler": "sampler",
    "size": "size",
    "model": "model",
    "model hash": "model hash",
    "filename keyword": "filename keyword",
    "Filename keyword search": "Filename keyword search",
    "exif keyword": "exif keyword",
    "EXIF keyword search": "EXIF keyword search",
    "Search negative prompt": "Search negative prompt",
    "No": "No",
    "Yes": "Yes",
    "Only": "Only",
    "case sensitive": "case sensitive",
    "regex - e.g. ^(?!.*Hires).*$": "regex - e.g. ^(?!.*Hires).*$",
    "ranking filter": "ranking filter",
    "Ranking filter": "Ranking filter",
    "All": "All",
    "minimum aesthetic_score": "minimum aesthetic_score",
    "Minimum aesthetic_score": "Minimum aesthetic_score",
    "Maximum aesthetic_score": "Maximum aesthetic_score",
    "Generate Info": "Generate Info",
    "Generation Info": "Generation Info",
    "File Name": "File Name",
    "Move to favorites": "Move to favorites",
    "Send to txt2img ControlNet": "Send to txt2img ControlNet",
    "Send to img2img ControlNet": "Send to img2img ControlNet",
    "ControlNet number": "ControlNet number",
    "Directory path": "Directory path",
    "Move to directory": "Move to directory",
    "Renew Page": "Renew Page",
    "Number": "Number",
    "set_index": "set_index",
    "Image": "Image",
    "load_switch": "load_switch",
    "to_dir_load_switch": "to_dir_load_switch",
    "turn_page_switch": "turn_page_switch",
    "Checkbox": "Checkbox",
    "List of active tabs (separated by commas). Available options are txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others. Custom folders are also supported by specifying their path.": "List of active tabs (separated by commas). Available options are txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others. Custom folders are also supported by specifying their path.",
    "Select components to hide": "Select components to hide",
    "Include images in sub directories": "Include images in sub directories",
    "Preload images at startup": "Preload images at startup",
    "Move buttons copy instead of move": "Move buttons copy instead of move",
    "Print image deletion messages to the console": "Print image deletion messages to the console",
    "Move/Copy/Delete matching .txt files": "Move/Copy/Delete matching .txt files",
    "Print warning logs to the console": "Print warning logs to the console",
    "Print debug logs to the console": "Print debug logs to the console",
    "Use recycle bin when deleting images": "Use recycle bin when deleting images",
    "Scan Exif-/.txt-data (initially slower, but required for many features to work)": "Scan Exif-/.txt-data (initially slower, but required for many features to work)",
    "Scan Exif-/.txt-data (slower, but required for exif-keyword-search)": "Scan Exif-/.txt-data (slower, but required for exif-keyword-search)",
    "Change CTRL keybindings to SHIFT": "Change CTRL keybindings to SHIFT",
    "or to CTRL+SHIFT": "or to CTRL+SHIFT",
    "Enable Maintenance tab": "Enable Maintenance tab",
    "Save ranking in image's pnginfo": "Save ranking in image's pnginfo",
    "Number of columns on the page": "Number of columns on the page",
    "Number of rows on the page": "Number of rows on the page",
    "Minimum number of pages per load": "Minimum number of pages per load",
    "stable-diffusion-webui-images-browser": "stable-diffusion-webui-images-browser",
    "https://github.com/AlUlkesh/stable-diffusion-webui-images-browser.git": "https://github.com/AlUlkesh/stable-diffusion-webui-images-browser.git",
    "Input images directory": "Input images directory",
    "Enable Bilingual Localization": "Enable Bilingual Localization",
    "Localization file (Please leave `User interface` - `Localization` as None)": "Localization file (Please leave `User interface` - `Localization` as None)",
    "Translation display order": "Translation display order",
    "Translation First": "Translation First",
    "Original First": "Original First",
    "Localization dirs": "Localization dirs",
    "sd-webui-bilingual-localization": "sd-webui-bilingual-localization",
    "https://github.com/journey-ad/sd-webui-bilingual-localization.git": "https://github.com/journey-ad/sd-webui-bilingual-localization.git",
    "NAIConvert": "NAIConvert",
    "History": "History",
    "https://github.com/animerl/novelai-2-local-prompt.git": "https://github.com/animerl/novelai-2-local-prompt.git",
    "The untranslated characters will be translated automatically and will not affect the old translations. Use the function in the lower right corner to easily check and quickly modify the current translation.1,Save the setting;2,Click start button;3,Reload your browser.": "The untranslated characters will be translated automatically and will not affect the old translations. Use the function in the lower right corner to easily check and quickly modify the current translation.1,Save the setting;2,Click start button;3,Reload your browser.",
    "Translated Status": "Translated Status",
    "Start Auto Translate": "Start Auto Translate",
    "Text": "Text",
    "-->": "-->",
    "<--": "<--",
    "Translated Text": "Translated Text",
    "To Language": "To Language",
    "zh-CN": "zh-CN",
    "af": "af",
    "sq": "sq",
    "am": "am",
    "ar": "ar",
    "hy": "hy",
    "az": "az",
    "eu": "eu",
    "be": "be",
    "bn": "bn",
    "bs": "bs",
    "bg": "bg",
    "ca": "ca",
    "ceb": "ceb",
    "ny": "ny",
    "co": "co",
    "hr": "hr",
    "cs": "cs",
    "da": "da",
    "nl": "nl",
    "en": "en",
    "eo": "eo",
    "et": "et",
    "tl": "tl",
    "fi": "fi",
    "fr": "fr",
    "fy": "fy",
    "gl": "gl",
    "ka": "ka",
    "de": "de",
    "el": "el",
    "gu": "gu",
    "ht": "ht",
    "ha": "ha",
    "haw": "haw",
    "iw": "iw",
    "hi": "hi",
    "hmn": "hmn",
    "hu": "hu",
    "is": "is",
    "ig": "ig",
    "id": "id",
    "ga": "ga",
    "it": "it",
    "ja": "ja",
    "jw": "jw",
    "kn": "kn",
    "kk": "kk",
    "km": "km",
    "rw": "rw",
    "ko": "ko",
    "ku": "ku",
    "ky": "ky",
    "lo": "lo",
    "la": "la",
    "lv": "lv",
    "lt": "lt",
    "lb": "lb",
    "mk": "mk",
    "mg": "mg",
    "ms": "ms",
    "ml": "ml",
    "mt": "mt",
    "mi": "mi",
    "mr": "mr",
    "mn": "mn",
    "ne": "ne",
    "no": "no",
    "ps": "ps",
    "fa": "fa",
    "pl": "pl",
    "pt": "pt",
    "pa": "pa",
    "ro": "ro",
    "ru": "ru",
    "sm": "sm",
    "gd": "gd",
    "sr": "sr",
    "st": "st",
    "sn": "sn",
    "sd": "sd",
    "si": "si",
    "sk": "sk",
    "sl": "sl",
    "so": "so",
    "es": "es",
    "su": "su",
    "sw": "sw",
    "sv": "sv",
    "tg": "tg",
    "ta": "ta",
    "tt": "tt",
    "te": "te",
    "th": "th",
    "tr": "tr",
    "tk": "tk",
    "uk": "uk",
    "ur": "ur",
    "ug": "ug",
    "uz": "uz",
    "vi": "vi",
    "cy": "cy",
    "xh": "xh",
    "yi": "yi",
    "yo": "yo",
    "zu": "zu",
    "Select Translater": "Select Translater",
    "free_google": "free_google",
    "free_youdao_zh": "free_youdao_zh",
    "tp_alibaba": "tp_alibaba",
    "tp_argos": "tp_argos",
    "tp_baidu": "tp_baidu",
    "tp_bing": "tp_bing",
    "tp_caiyun": "tp_caiyun",
    "tp_deepl": "tp_deepl",
    "tp_google": "tp_google",
    "tp_iciba": "tp_iciba",
    "tp_iflytek": "tp_iflytek",
    "tp_iflyrec": "tp_iflyrec",
    "tp_itranslate": "tp_itranslate",
    "tp_lingvanex": "tp_lingvanex",
    "tp_mglip": "tp_mglip",
    "tp_modernMt": "tp_modernMt",
    "tp_myMemory": "tp_myMemory",
    "tp_niutrans": "tp_niutrans",
    "tp_papago": "tp_papago",
    "tp_qqFanyi": "tp_qqFanyi",
    "tp_qqTranSmart": "tp_qqTranSmart",
    "tp_reverso": "tp_reverso",
    "tp_sogou": "tp_sogou",
    "tp_translateCom": "tp_translateCom",
    "tp_utibet": "tp_utibet",
    "tp_volcEngine": "tp_volcEngine",
    "tp_yandex": "tp_yandex",
    "tp_youdao": "tp_youdao",
    "tp__alibaba": "tp__alibaba",
    "tp__argos": "tp__argos",
    "tp__baidu": "tp__baidu",
    "tp__bing": "tp__bing",
    "tp__caiyun": "tp__caiyun",
    "tp__deepl": "tp__deepl",
    "tp__google": "tp__google",
    "tp__iciba": "tp__iciba",
    "tp__iflytek": "tp__iflytek",
    "tp__iflyrec": "tp__iflyrec",
    "tp__itranslate": "tp__itranslate",
    "tp__lingvanex": "tp__lingvanex",
    "tp__mglip": "tp__mglip",
    "tp__modernMt": "tp__modernMt",
    "tp__myMemory": "tp__myMemory",
    "tp__niutrans": "tp__niutrans",
    "tp__papago": "tp__papago",
    "tp__qqFanyi": "tp__qqFanyi",
    "tp__qqTranSmart": "tp__qqTranSmart",
    "tp__reverso": "tp__reverso",
    "tp__sogou": "tp__sogou",
    "tp__translateCom": "tp__translateCom",
    "tp__utibet": "tp__utibet",
    "tp__volcEngine": "tp__volcEngine",
    "tp__yandex": "tp__yandex",
    "tp__youdao": "tp__youdao",
    "display both english and target language": "display both english and target language",
    "Save Setting": "Save Setting",
    "Remove Auto Trans": "Remove Auto Trans",
    "stable-diffusion-webui-auto-translate-language": "stable-diffusion-webui-auto-translate-language",
    "https://github.com/hyd998877/stable-diffusion-webui-auto-translate-language": "https://github.com/hyd998877/stable-diffusion-webui-auto-translate-language",
    "your select language": "your select language",
    "english": "english",
    "translate prompt.": "translate prompt.",
    "en2": "en2",
    "translate negative prompt.": "translate negative prompt.",
    "N2": "N2",
    "ui text": "ui text",
    "translated text": "translated text",
    "load": "load",
    "translate": "translate",
    "save": "save",
    "Tokenizer": "Tokenizer",
    "Before your text is sent to the neural network, it gets turned into numbers in a process called tokenization. These tokens are how the neural network reads and interprets text. Thanks to our great friends at Shousetsu愛 for inspiration for this feature.": "Before your text is sent to the neural network, it gets turned into numbers in a process called tokenization. These tokens are how the neural network reads and interprets text. Thanks to our great friends at Shousetsu愛 for inspiration for this feature.",
    "Text input": "Text input",
    "ID input": "ID input",
    "Tokenize": "Tokenize",
    "Tokens": "Tokens",
    "stable-diffusion-webui-tokenizer": "stable-diffusion-webui-tokenizer",
    "Prompt for tokenization": "Prompt for tokenization",
    "Ids for tokenization (example: 9061, 631, 736)": "Ids for tokenization (example: 9061, 631, 736)",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer.git",
    "Artists To Study": "Artists To Study",
    "dog": "dog",
    "house": "house",
    "portrait": "portrait",
    "spaceship": "spaceship",
    "anime": "anime",
    "cartoon": "cartoon",
    "digipa-high-impact": "digipa-high-impact",
    "digipa-med-impact": "digipa-med-impact",
    "digipa-low-impact": "digipa-low-impact",
    "fareast": "fareast",
    "fineart": "fineart",
    "scribbles": "scribbles",
    "special": "special",
    "ukioe": "ukioe",
    "weird": "weird",
    "black-white": "black-white",
    "nudity": "nudity",
    "c": "c",
    "n": "n",
    "Get Images": "Get Images",
    "dog-anime": "dog-anime",
    "dog-cartoon": "dog-cartoon",
    "dog-digipa-high-impact": "dog-digipa-high-impact",
    "dog-digipa-med-impact": "dog-digipa-med-impact",
    "dog-digipa-low-impact": "dog-digipa-low-impact",
    "dog-fareast": "dog-fareast",
    "dog-fineart": "dog-fineart",
    "dog-scribbles": "dog-scribbles",
    "dog-special": "dog-special",
    "dog-ukioe": "dog-ukioe",
    "dog-weird": "dog-weird",
    "dog-black-white": "dog-black-white",
    "dog-nudity": "dog-nudity",
    "dog-c": "dog-c",
    "dog-n": "dog-n",
    "house-anime": "house-anime",
    "house-cartoon": "house-cartoon",
    "house-digipa-high-impact": "house-digipa-high-impact",
    "house-digipa-med-impact": "house-digipa-med-impact",
    "house-digipa-low-impact": "house-digipa-low-impact",
    "house-fareast": "house-fareast",
    "house-fineart": "house-fineart",
    "house-scribbles": "house-scribbles",
    "house-special": "house-special",
    "house-ukioe": "house-ukioe",
    "house-weird": "house-weird",
    "house-black-white": "house-black-white",
    "house-nudity": "house-nudity",
    "house-c": "house-c",
    "house-n": "house-n",
    "portrait-anime": "portrait-anime",
    "portrait-cartoon": "portrait-cartoon",
    "portrait-digipa-high-impact": "portrait-digipa-high-impact",
    "portrait-digipa-med-impact": "portrait-digipa-med-impact",
    "portrait-digipa-low-impact": "portrait-digipa-low-impact",
    "portrait-fareast": "portrait-fareast",
    "portrait-fineart": "portrait-fineart",
    "portrait-scribbles": "portrait-scribbles",
    "portrait-special": "portrait-special",
    "portrait-ukioe": "portrait-ukioe",
    "portrait-weird": "portrait-weird",
    "portrait-black-white": "portrait-black-white",
    "portrait-nudity": "portrait-nudity",
    "portrait-c": "portrait-c",
    "portrait-n": "portrait-n",
    "spaceship-anime": "spaceship-anime",
    "spaceship-cartoon": "spaceship-cartoon",
    "spaceship-digipa-high-impact": "spaceship-digipa-high-impact",
    "spaceship-digipa-med-impact": "spaceship-digipa-med-impact",
    "spaceship-digipa-low-impact": "spaceship-digipa-low-impact",
    "spaceship-fareast": "spaceship-fareast",
    "spaceship-fineart": "spaceship-fineart",
    "spaceship-scribbles": "spaceship-scribbles",
    "spaceship-special": "spaceship-special",
    "spaceship-ukioe": "spaceship-ukioe",
    "spaceship-weird": "spaceship-weird",
    "spaceship-black-white": "spaceship-black-white",
    "spaceship-nudity": "spaceship-nudity",
    "spaceship-c": "spaceship-c",
    "spaceship-n": "spaceship-n",
    "artists to study extension by camenduru |": "artists to study extension by camenduru |",
    "github": "github",
    "|": "|",
    "twitter": "twitter",
    "youtube": "youtube",
    "hi-res images": "hi-res images",
    "All images generated with CompVis/stable-diffusion-v1-4 +": "All images generated with CompVis/stable-diffusion-v1-4 +",
    "artists.csv": "artists.csv",
    "| License: Attribution 4.0 International (CC BY 4.0)": "| License: Attribution 4.0 International (CC BY 4.0)",
    "stable-diffusion-webui-artists-to-study": "stable-diffusion-webui-artists-to-study",
    "https://github.com/camenduru/stable-diffusion-webui-artists-to-study.git": "https://github.com/camenduru/stable-diffusion-webui-artists-to-study.git",
    "MultiDiffusion": "MultiDiffusion",
    "Enable MultiDiffusion": "Enable MultiDiffusion",
    "Overwrite image size": "Overwrite image size",
    "Keep input image size": "Keep input image size",
    "Image width": "Image width",
    "Image height": "Image height",
    "Latent tile width": "Latent tile width",
    "Latent tile height": "Latent tile height",
    "Latent tile overlap": "Latent tile overlap",
    "Latent tile batch size": "Latent tile batch size",
    "Move ControlNet images to CPU (if applicable)": "Move ControlNet images to CPU (if applicable)",
    "Tiled VAE": "Tiled VAE",
    "Move VAE to GPU": "Move VAE to GPU",
    "Please use smaller tile size when see CUDA error: out of memory.": "Please use smaller tile size when see CUDA error: out of memory.",
    "Encoder Tile Size": "Encoder Tile Size",
    "Decoder Tile Size": "Decoder Tile Size",
    "Reset Tile Size": "Reset Tile Size",
    "Fast Encoder": "Fast Encoder",
    "Fast Decoder": "Fast Decoder",
    "Fast Encoder may change colors; Can fix it with more RAM and lower speed.": "Fast Encoder may change colors; Can fix it with more RAM and lower speed.",
    "Encoder Color Fix": "Encoder Color Fix",
    "multidiffusion-upscaler-for-automatic1111": "multidiffusion-upscaler-for-automatic1111",
    "https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111.git": "https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111.git",
    "Enabled": "Enabled",
    "Multiplication (2^N)": "Multiplication (2^N)",
    "Weight": "Weight",
    "Force convert half to float on interpolation (for some platforms)": "Force convert half to float on interpolation (for some platforms)",
    "I know what I am doing.": "I know what I am doing.",
    "Layers": "Layers",
    "Apply to": "Apply to",
    "Resblock": "Resblock",
    "Transformer": "Transformer",
    "S. Attn.": "S. Attn.",
    "X. Attn.": "X. Attn.",
    "OUT": "OUT",
    "Start steps": "Start steps",
    "Bilinear": "Bilinear",
    "Bicubic": "Bicubic",
    "Enable AA for Upscaling.": "Enable AA for Upscaling.",
    "Downscaling": "Downscaling",
    "Area": "Area",
    "Pooling Max": "Pooling Max",
    "Pooling Avg": "Pooling Avg",
    "Enable AA for Downscaling.": "Enable AA for Downscaling.",
    "interpolation method": "interpolation method",
    "Lerp": "Lerp",
    "SLerp": "SLerp",
    "LLuL Enabled": "LLuL Enabled",
    "LLuL Multiply": "LLuL Multiply",
    "LLuL Weight": "LLuL Weight",
    "LLuL Layers": "LLuL Layers",
    "LLuL Apply to": "LLuL Apply to",
    "LLuL Start steps": "LLuL Start steps",
    "LLuL Max steps": "LLuL Max steps",
    "LLuL Upscaler": "LLuL Upscaler",
    "LLuL Upscaler AA": "LLuL Upscaler AA",
    "LLuL Downscaler": "LLuL Downscaler",
    "LLuL Downscaler AA": "LLuL Downscaler AA",
    "LLuL Interpolation method": "LLuL Interpolation method",
    "sd-webui-llul": "sd-webui-llul",
    "https://github.com/hnmr293/sd-webui-llul.git": "https://github.com/hnmr293/sd-webui-llul.git",
    "Unprompted Seed": "Unprompted Seed",
    "Functions": "Functions",
    "Select function:": "Select function:",
    "Options": "Options",
    "Example Function": "Example Function",
    "Enter a subject 🡢 subject": "Enter a subject 🡢 subject",
    "Add fluff terms? 🡢 use_fluff": "Add fluff terms? 🡢 use_fluff",
    "Auto-include this in prompt": "Auto-include this in prompt",
    "Generate Shortcode": "Generate Shortcode",
    "img2img folder": "img2img folder",
    "Image folder 🡢 folder": "Image folder 🡢 folder",
    "String to include before the filename 🡢 pre": "String to include before the filename 🡢 pre",
    "String to include after the filename 🡢 post": "String to include after the filename 🡢 post",
    "txt2img2img": "txt2img2img",
    "Subject A 🡢 subject_a": "Subject A 🡢 subject_a",
    "Subject B 🡢 subject_b": "Subject B 🡢 subject_b",
    "Shortcodes": "Shortcodes",
    "Select shortcode:": "Select shortcode:",
    "Content": "Content",
    "##": "##",
    "##: Houses a multiline comment that will not affect the final output.": "##: Houses a multiline comment that will not affect the final output.",
    "#": "#",
    "#: Houses a comment that does not affect your final prompt.": "#: Houses a comment that does not affect your final prompt.",
    "Comment 🡢 str": "Comment 🡢 str",
    "after": "after",
    "after: Processes arbitrary text following the main output.": "after: Processes arbitrary text following the main output.",
    "Order compared to other [after] blocks 🡢 int": "Order compared to other [after] blocks 🡢 int",
    "antonyms": "antonyms",
    "antonyms: Replaces the content with one or more antonyms.": "antonyms: Replaces the content with one or more antonyms.",
    "array": "array",
    "array: Manages a group or list of values.": "array: Manages a group or list of values.",
    "Name of array variable 🡢 str": "Name of array variable 🡢 str",
    "Get or set index statements 🡢 verbatim": "Get or set index statements 🡢 verbatim",
    "Custom delimiter string 🡢 _delimiter": "Custom delimiter string 🡢 _delimiter",
    "Shuffle the array 🡢 _shuffle": "Shuffle the array 🡢 _shuffle",
    "Prepend value(s) to the array 🡢 _prepend": "Prepend value(s) to the array 🡢 _prepend",
    "Append value(s) to the array 🡢 _append": "Append value(s) to the array 🡢 _append",
    "Delete value(s) from the array by index 🡢 _del": "Delete value(s) from the array by index 🡢 _del",
    "Removed specified value(s) from the array 🡢 _remove": "Removed specified value(s) from the array 🡢 _remove",
    "Find the first index of the following value(s) 🡢 _find": "Find the first index of the following value(s) 🡢 _find",
    "article": "article",
    "article: Returns the content with prefixed with a definite or indefinite article.": "article: Returns the content with prefixed with a definite or indefinite article.",
    "autocorrect": "autocorrect",
    "autocorrect: Attempts to correct the spelling of content.": "autocorrect: Attempts to correct the spelling of content.",
    "case": "case",
    "case: Use within [switch] to run different logic blocks depending on the value of a var.": "case: Use within [switch] to run different logic blocks depending on the value of a var.",
    "Matching value 🡢 str": "Matching value 🡢 str",
    "casing": "casing",
    "casing: Converts the casing of content.": "casing: Converts the casing of content.",
    "Casing method 🡢 str": "Casing method 🡢 str",
    "camelcase": "camelcase",
    "uppercase": "uppercase",
    "lowercase": "lowercase",
    "pascalcase": "pascalcase",
    "snakecase": "snakecase",
    "constcase": "constcase",
    "kebabcase": "kebabcase",
    "upperkebabcase": "upperkebabcase",
    "separatorcase": "separatorcase",
    "sentencecase": "sentencecase",
    "titlecase": "titlecase",
    "alphanumcase": "alphanumcase",
    "chance": "chance",
    "chance: Returns the content if the number you passed is greater than or equal to a random number between 1 and 100.": "chance: Returns the content if the number you passed is greater than or equal to a random number between 1 and 100.",
    "Highest possible roll 🡢 _sides": "Highest possible roll 🡢 _sides",
    "choose": "choose",
    "choose: Returns one of multiple options, delimited by newline or vertical pipe": "choose: Returns one of multiple options, delimited by newline or vertical pipe",
    "Number of times to choose 🡢 int": "Number of times to choose 🡢 int",
    "String delimiter when returning more than one choice 🡢 _sep": "String delimiter when returning more than one choice 🡢 _sep",
    "Custom weight per option 🡢 _weighted": "Custom weight per option 🡢 _weighted",
    "Override random nature of shortcode with predetermined outcome 🡢 _case": "Override random nature of shortcode with predetermined outcome 🡢 _case",
    "config": "config",
    "config: Updates your settings with the content for the duration of a run.": "config: Updates your settings with the content for the duration of a run.",
    "conjugate": "conjugate",
    "conjugate: Converts the content verb into another conjugated form.": "conjugate: Converts the content verb into another conjugated form.",
    "do": "do",
    "do: It's a do-until loop.": "do: It's a do-until loop.",
    "Until condition 🡢 until": "Until condition 🡢 until",
    "elif": "elif",
    "elif: Shorthand 'else-if.'": "elif: Shorthand 'else-if.'",
    "else": "else",
    "else: Returns content if a previous conditional shortcode failed its check, otherwise discards content.": "else: Returns content if a previous conditional shortcode failed its check, otherwise discards content.",
    "eval": "eval",
    "eval: Parses the content using the simpleeval library, returning the result. Particularly useful for arithmetic.": "eval: Parses the content using the simpleeval library, returning the result. Particularly useful for arithmetic.",
    "file": "file",
    "file: Processes the file content of 'path.'": "file: Processes the file content of 'path.'",
    "filelist": "filelist",
    "Filepath 🡢 str": "Filepath 🡢 str",
    "Expected encoding 🡢 _encoding": "Expected encoding 🡢 _encoding",
    "filelist: Returns a list of files at a given location using glob.": "filelist: Returns a list of files at a given location using glob.",
    "Result delimiter 🡢 _delimiter": "Result delimiter 🡢 _delimiter",
    "for": "for",
    "for: It's a for loop.": "for: It's a for loop.",
    "Set a variable 🡢 my_var": "Set a variable 🡢 my_var",
    "Conditional check 🡢 str": "Conditional check 🡢 str",
    "Operation to perform at the end step 🡢 str": "Operation to perform at the end step 🡢 str",
    "get": "get",
    "get: Returns the value of a variable.": "get: Returns the value of a variable.",
    "Variable to get 🡢 str": "Variable to get 🡢 str",
    "Default value if the variable doesn't exist 🡢 _default": "Default value if the variable doesn't exist 🡢 _default",
    "Separator string when returning multiple variables 🡢 _sep": "Separator string when returning multiple variables 🡢 _sep",
    "String to prepend to the variable 🡢 _before": "String to prepend to the variable 🡢 _before",
    "String to append to the variable 🡢 _after": "String to append to the variable 🡢 _after",
    "hypernyms": "hypernyms",
    "hypernyms: Replaces the content with one or more hypernyms.": "hypernyms: Replaces the content with one or more hypernyms.",
    "hyponyms": "hyponyms",
    "hyponyms: Replaces the content with one or more synonyms.": "hyponyms: Replaces the content with one or more synonyms.",
    "if": "if",
    "if: Checks whether a variable is equal to a given value.": "if: Checks whether a variable is equal to a given value.",
    "Conditional statement 🡢 my_var": "Conditional statement 🡢 my_var",
    "Evaluation method 🡢 _is": "Evaluation method 🡢 _is",
    "Invert evaluation such that a true statement will return false 🡢 _not": "Invert evaluation such that a true statement will return false 🡢 _not",
    "Return true if any one of multiple conditions are true 🡢 _any": "Return true if any one of multiple conditions are true 🡢 _any",
    "info": "info",
    "info: Returns various types of metadata about the content.": "info: Returns various types of metadata about the content.",
    "Return the character count 🡢 character_count": "Return the character count 🡢 character_count",
    "Return the word count 🡢 word_count": "Return the word count 🡢 word_count",
    "Return the sentence count 🡢 sentence_count": "Return the sentence count 🡢 sentence_count",
    "Return the filename 🡢 filename": "Return the filename 🡢 filename",
    "Return the CLIP token count (prompt complexity) 🡢 clip_count": "Return the CLIP token count (prompt complexity) 🡢 clip_count",
    "Return the count of a custom substring 🡢 string_count": "Return the count of a custom substring 🡢 string_count",
    "length": "length",
    "length: Returns the number of items in a delimited string.": "length: Returns the number of items in a delimited string.",
    "The string to evaluate 🡢 str": "The string to evaluate 🡢 str",
    "Delimiter to check for 🡢 _delimiter": "Delimiter to check for 🡢 _delimiter",
    "Maximum number to be returned 🡢 _max": "Maximum number to be returned 🡢 _max",
    "max": "max",
    "max: Returns the maximum value among the given arguments.": "max: Returns the maximum value among the given arguments.",
    "min": "min",
    "min: Returns the minimum value among the given arguments.": "min: Returns the minimum value among the given arguments.",
    "override": "override",
    "override: Force variable(s) to hold a pre-determined value the rest of the run.": "override: Force variable(s) to hold a pre-determined value the rest of the run.",
    "Arguments in variable=value format 🡢 verbatim": "Arguments in variable=value format 🡢 verbatim",
    "pluralize": "pluralize",
    "pluralize: Converts the content into plural form.": "pluralize: Converts the content into plural form.",
    "random: Returns a random number between 0 and a given max value (inclusive)": "random: Returns a random number between 0 and a given max value (inclusive)",
    "Minimum number 🡢 _min": "Minimum number 🡢 _min",
    "Maximum number 🡢 _max": "Maximum number 🡢 _max",
    "Evaluate as floats instead of integers 🡢 _float": "Evaluate as floats instead of integers 🡢 _float",
    "repeat": "repeat",
    "repeat: Returns the content an arbitrary number of times.": "repeat: Returns the content an arbitrary number of times.",
    "Number of times to repeat the content 🡢 int": "Number of times to repeat the content 🡢 int",
    "Delimiter string between outputs 🡢 _sep": "Delimiter string between outputs 🡢 _sep",
    "replace": "replace",
    "replace: Updates a string using the arguments for replacement logic.": "replace: Updates a string using the arguments for replacement logic.",
    "Arbitrary replacement arguments in old=new format 🡢 verbatim": "Arbitrary replacement arguments in old=new format 🡢 verbatim",
    "Original value, with advanced expression support 🡢 _from": "Original value, with advanced expression support 🡢 _from",
    "New value, with advanced expression support 🡢 _to": "New value, with advanced expression support 🡢 _to",
    "Maximum number of times the replacement may occur 🡢 _count": "Maximum number of times the replacement may occur 🡢 _count",
    "set": "set",
    "set: Stores a value into a given variable.": "set: Stores a value into a given variable.",
    "Variable name 🡢 verbatim": "Variable name 🡢 verbatim",
    "Only set this variable if it doesn't already exist 🡢 _new": "Only set this variable if it doesn't already exist 🡢 _new",
    "Array of valid values (used in conjunction with _new) 🡢 _choices": "Array of valid values (used in conjunction with _new) 🡢 _choices",
    "Append the content to the variable's current value 🡢 _append": "Append the content to the variable's current value 🡢 _append",
    "Prepend the content to the variable's current value 🡢 _prepend": "Prepend the content to the variable's current value 🡢 _prepend",
    "Print the variable's value 🡢 _out": "Print the variable's value 🡢 _out",
    "sets": "sets",
    "sets: The atomic version of [set] that lets you set multiple variables at once.": "sets: The atomic version of [set] that lets you set multiple variables at once.",
    "Arbitrary arguments in variable=value format 🡢 verbatim": "Arbitrary arguments in variable=value format 🡢 verbatim",
    "singularize": "singularize",
    "singularize: Converts the content into singular form.": "singularize: Converts the content into singular form.",
    "substring: Slices up the content.": "substring: Slices up the content.",
    "Beginning index of the substring 🡢 start": "Beginning index of the substring 🡢 start",
    "Ending index of the substring 🡢 end": "Ending index of the substring 🡢 end",
    "Step size 🡢 step": "Step size 🡢 step",
    "Unit type 🡢 unit": "Unit type 🡢 unit",
    "characters": "characters",
    "words": "words",
    "switch": "switch",
    "switch: Use in conjunction with [case] to run different logic blocks depending on the value of a var.": "switch: Use in conjunction with [case] to run different logic blocks depending on the value of a var.",
    "Variable to test against 🡢 verbatim": "Variable to test against 🡢 verbatim",
    "synonyms": "synonyms",
    "synonyms: Replaces the content with one or more synonyms.": "synonyms: Replaces the content with one or more synonyms.",
    "template: This is used by the Wizard to instantiate a custom template UI. It is bypassed by the normal shortcode parser.": "template: This is used by the Wizard to instantiate a custom template UI. It is bypassed by the normal shortcode parser.",
    "unset": "unset",
    "unset: Removes one or more variables from memory. Generally not needed.": "unset: Removes one or more variables from memory. Generally not needed.",
    "Arbitrary variable names to free from memory 🡢 verbatim": "Arbitrary variable names to free from memory 🡢 verbatim",
    "while": "while",
    "while: Loops content until the condition returns false.": "while: Loops content until the condition returns false.",
    "Arbitrary conditional statement(s) to test against 🡢 verbatim": "Arbitrary conditional statement(s) to test against 🡢 verbatim",
    "Invert evaluation such that a false condition will end the loop 🡢 _not": "Invert evaluation such that a false condition will end the loop 🡢 _not",
    "controlnet": "controlnet",
    "controlnet: A neural network structure to control diffusion models by adding extra conditions. Check manual for setup info.": "controlnet: A neural network structure to control diffusion models by adding extra conditions. Check manual for setup info.",
    "Model name (do not include extension) 🡢 model": "Model name (do not include extension) 🡢 model",
    "Resolution of the detection map 🡢 detect_resolution": "Resolution of the detection map 🡢 detect_resolution",
    "Use low VRAM mode? 🡢 save_memory": "Use low VRAM mode? 🡢 save_memory",
    "DDIM ETA 🡢 eta": "DDIM ETA 🡢 eta",
    "Value Threshold 🡢 value_threhsold": "Value Threshold 🡢 value_threhsold",
    "Distance Threshold 🡢 distance_threhsold": "Distance Threshold 🡢 distance_threhsold",
    "Background Threshold 🡢 bg_threhsold": "Background Threshold 🡢 bg_threhsold",
    "Canny low threshold 🡢 low_threshold": "Canny low threshold 🡢 low_threshold",
    "Canny high threshold 🡢 high_threshold": "Canny high threshold 🡢 high_threshold",
    "Render hands with Openpose? 🡢 openpose_hands": "Render hands with Openpose? 🡢 openpose_hands",
    "enable_multi_images": "enable_multi_images",
    "enable_multi_images: Allows to use multiple init_images or multiple masks": "enable_multi_images: Allows to use multiple init_images or multiple masks",
    "file2mask": "file2mask",
    "file2mask: Modify or replace your img2img mask with arbitrary files.": "file2mask: Modify or replace your img2img mask with arbitrary files.",
    "Path to image file 🡢 str": "Path to image file 🡢 str",
    "Mask blend mode 🡢 mode": "Mask blend mode 🡢 mode",
    "add": "add",
    "subtract": "subtract",
    "discard": "discard",
    "Show mask in output 🡢 show": "Show mask in output 🡢 show",
    "img2img: Runs an img2img task inside of an [after] block.": "img2img: Runs an img2img task inside of an [after] block.",
    "img2img_autosize": "img2img_autosize",
    "img2img_autosize: Automatically adjusts the width and height parameters in img2img mode based on the proportions of the input image.": "img2img_autosize: Automatically adjusts the width and height parameters in img2img mode based on the proportions of the input image.",
    "Minimum pixels of at least one dimension 🡢 target": "Minimum pixels of at least one dimension 🡢 target",
    "Only run this shortcode if using full resolution inpainting mode 🡢 only_full_res": "Only run this shortcode if using full resolution inpainting mode 🡢 only_full_res",
    "img2pez": "img2pez",
    "img2pez: Optimize a hard prompt using the PEZ algorithm and CLIP encoders, AKA Hard Prompts Made Easy.": "img2pez: Optimize a hard prompt using the PEZ algorithm and CLIP encoders, AKA Hard Prompts Made Easy.",
    "Image path 🡢 image_path": "Image path 🡢 image_path",
    "Prompt length 🡢 prompt_length": "Prompt length 🡢 prompt_length",
    "Iterations 🡢 iterations": "Iterations 🡢 iterations",
    "Learning rate 🡢 learning_rate": "Learning rate 🡢 learning_rate",
    "Weight decay 🡢 weight_decay": "Weight decay 🡢 weight_decay",
    "Prompt bs (well, that's what they call it) 🡢 prompt_bs": "Prompt bs (well, that's what they call it) 🡢 prompt_bs",
    "CLIP model 🡢 clip_model": "CLIP model 🡢 clip_model",
    "ViT-L-14": "ViT-L-14",
    "ViT-H-14": "ViT-H-14",
    "CLIP pretrain 🡢 clip_pretrain": "CLIP pretrain 🡢 clip_pretrain",
    "openai": "openai",
    "laion2b_s32b_b79k": "laion2b_s32b_b79k",
    "Try freeing CLIP model from memory? 🡢 free_memory": "Try freeing CLIP model from memory? 🡢 free_memory",
    "init_image": "init_image",
    "init_image: Loads an image from the given path and sets it as the initial image for use with img2img.": "init_image: Loads an image from the given path and sets it as the initial image for use with img2img.",
    "instance2mask": "instance2mask",
    "instance2mask: Creates an image mask from instances of types specified by the content for use with inpainting.": "instance2mask: Creates an image mask from instances of types specified by the content for use with inpainting.",
    "refine": "refine",
    "Run inpaint per instance found 🡢 per_instance": "Run inpaint per instance found 🡢 per_instance",
    "Precision of selected area 🡢 mask_precision": "Precision of selected area 🡢 mask_precision",
    "Padding radius in pixels 🡢 padding": "Padding radius in pixels 🡢 padding",
    "Smoothing radius in pixels 🡢 smoothing": "Smoothing radius in pixels 🡢 smoothing",
    "Precision of instance selection 🡢 instance_precision": "Precision of instance selection 🡢 instance_precision",
    "Number of instance to select 🡢 select": "Number of instance to select 🡢 select",
    "Instance selection mode 🡢 select_mode": "Instance selection mode 🡢 select_mode",
    "overlap": "overlap",
    "relative overlap": "relative overlap",
    "greatest area": "greatest area",
    "invert_mask": "invert_mask",
    "invert_mask: Inverts the mask (great in combination with multiple txt2masks)": "invert_mask: Inverts the mask (great in combination with multiple txt2masks)",
    "pix2pix_zero": "pix2pix_zero",
    "pix2pix_zero: A diffusion-based image-to-image approach that allows users to specify the edit direction on-the-fly.": "pix2pix_zero: A diffusion-based image-to-image approach that allows users to specify the edit direction on-the-fly.",
    "txt2mask": "txt2mask",
    "Use legacy weights 🡢 legacy_weights": "Use legacy weights 🡢 legacy_weights",
    "Precision of selected area 🡢 precision": "Precision of selected area 🡢 precision",
    "Negative mask prompt 🡢 negative_mask": "Negative mask prompt 🡢 negative_mask",
    "Negative mask precision of selected area 🡢 neg_precision": "Negative mask precision of selected area 🡢 neg_precision",
    "Negative mask padding radius in pixels 🡢 neg_padding": "Negative mask padding radius in pixels 🡢 neg_padding",
    "Negative mask smoothing radius in pixels 🡢 neg_smoothing": "Negative mask smoothing radius in pixels 🡢 neg_smoothing",
    "Mask color, enables Inpaint Sketch mode 🡢 sketch_color": "Mask color, enables Inpaint Sketch mode 🡢 sketch_color",
    "Mask alpha, must be used in conjunction with mask color 🡢 sketch_alpha": "Mask alpha, must be used in conjunction with mask color 🡢 sketch_alpha",
    "Save the mask size to the following variable 🡢 size_var": "Save the mask size to the following variable 🡢 size_var",
    "zoom_enhance": "zoom_enhance",
    "zoom_enhance: Upscales a selected portion of the image. ENHANCE!": "zoom_enhance: Upscales a selected portion of the image. ENHANCE!",
    "Final image not showing up? Try using this workaround 🡢 use_workaround": "Final image not showing up? Try using this workaround 🡢 use_workaround",
    "Mask to find 🡢 mask": "Mask to find 🡢 mask",
    "Replacement 🡢 replacement": "Replacement 🡢 replacement",
    "Negative replacement 🡢 negative_replacement": "Negative replacement 🡢 negative_replacement",
    "Mask sorting method 🡢 mask_sort_method": "Mask sorting method 🡢 mask_sort_method",
    "left-to-right": "left-to-right",
    "right-to-left": "right-to-left",
    "top-to-bottom": "top-to-bottom",
    "bottom-to-top": "bottom-to-top",
    "big-to-small": "big-to-small",
    "small-to-big": "small-to-big",
    "unsorted": "unsorted",
    "Blur edges size 🡢 blur_size": "Blur edges size 🡢 blur_size",
    "Minimum CFG scale 🡢 cfg_scale_min": "Minimum CFG scale 🡢 cfg_scale_min",
    "Maximum denoising strength 🡢 denoising_max": "Maximum denoising strength 🡢 denoising_max",
    "Maximum mask size (if a bigger mask is found, it will bypass the shortcode) 🡢 mask_size_max": "Maximum mask size (if a bigger mask is found, it will bypass the shortcode) 🡢 mask_size_max",
    "Force denoising strength to this value 🡢 denoising_strength": "Force denoising strength to this value 🡢 denoising_strength",
    "Force CFG scale to this value 🡢 cfg_scale": "Force CFG scale to this value 🡢 cfg_scale",
    "Mask minimum number of pixels 🡢 min_area": "Mask minimum number of pixels 🡢 min_area",
    "Contour padding in pixels 🡢 contour_padding": "Contour padding in pixels 🡢 contour_padding",
    "Upscale width 🡢 upscale_width": "Upscale width 🡢 upscale_width",
    "Upscale height 🡢 upscale_height": "Upscale height 🡢 upscale_height",
    "Include original image in output window 🡢 include_original": "Include original image in output window 🡢 include_original",
    "Save debug images to WebUI folder 🡢 save": "Save debug images to WebUI folder 🡢 save",
    "Test prompt": "Test prompt",
    "Process Text": "Process Text",
    "Re-process extra networks after Unprompted is finished (WIP - this is not yet functional!)": "Re-process extra networks after Unprompted is finished (WIP - this is not yet functional!)",
    "unprompted": "unprompted",
    "https://github.com/ThereforeGames/unprompted.git": "https://github.com/ThereforeGames/unprompted.git",
    "HakuImg": "HakuImg",
    "Send to Blend": "Send to Blend",
    "Send to Layer5": "Send to Layer5",
    "Send to Layer4": "Send to Layer4",
    "Send to Layer3": "Send to Layer3",
    "Send to Layer2": "Send to Layer2",
    "Send to Layer1": "Send to Layer1",
    "Send to Effect": "Send to Effect",
    "Effect": "Effect",
    "Other": "Other",
    "Image preview height": "Image preview height",
    "Layer5": "Layer5",
    "Layer4": "Layer4",
    "Layer3": "Layer3",
    "Layer2": "Layer2",
    "Layer1": "Layer1",
    "Layer5 opacity": "Layer5 opacity",
    "Layer5 mask blur": "Layer5 mask blur",
    "Layer5 mask strength": "Layer5 mask strength",
    "Blend mode": "Blend mode",
    "normal": "normal",
    "darken": "darken",
    "multiply": "multiply",
    "color_burn": "color_burn",
    "linear_burn": "linear_burn",
    "lighten": "lighten",
    "screen": "screen",
    "color_dodge": "color_dodge",
    "linear_dodge": "linear_dodge",
    "overlay": "overlay",
    "soft_light": "soft_light",
    "hard_light": "hard_light",
    "vivid_light": "vivid_light",
    "linear_light": "linear_light",
    "pin_light": "pin_light",
    "difference": "difference",
    "exclusion": "exclusion",
    "Layer4 opacity": "Layer4 opacity",
    "Layer4 mask blur": "Layer4 mask blur",
    "Layer4 mask strength": "Layer4 mask strength",
    "Layer3 opacity": "Layer3 opacity",
    "Layer3 mask blur": "Layer3 mask blur",
    "Layer3 mask strength": "Layer3 mask strength",
    "Layer2 opacity": "Layer2 opacity",
    "Layer2 mask blur": "Layer2 mask blur",
    "Layer2 mask strength": "Layer2 mask strength",
    "Layer1 opacity": "Layer1 opacity",
    "Layer1 mask blur": "Layer1 mask blur",
    "Layer1 mask strength": "Layer1 mask strength",
    "background color": "background color",
    "refresh": "refresh",
    "img": "img",
    "Color": "Color",
    "Tone Curve": "Tone Curve",
    "Blur": "Blur",
    "Pixelize": "Pixelize",
    "Glow": "Glow",
    "temparature": "temparature",
    "hue": "hue",
    "brightness": "brightness",
    "contrast": "contrast",
    "saturation": "saturation",
    "Gamma": "Gamma",
    "reset": "reset",
    "R": "R",
    "G": "G",
    "point1 x": "point1 x",
    "point1 y": "point1 y",
    "point2 x": "point2 x",
    "point2 y": "point2 y",
    "point3 x": "point3 x",
    "point3 y": "point3 y",
    "blur": "blur",
    "kernel size": "kernel size",
    "sigma": "sigma",
    "k_sigma": "k_sigma",
    "epsilon": "epsilon",
    "phi": "phi",
    "gamma": "gamma",
    "color mode": "color mode",
    "gray": "gray",
    "rgb": "rgb",
    "use scale": "use scale",
    "colors": "colors",
    "dot size": "dot size",
    "outline inflating": "outline inflating",
    "Smoothing": "Smoothing",
    "Color reduce algo": "Color reduce algo",
    "kmeans": "kmeans",
    "dithering": "dithering",
    "kmeans with dithering": "kmeans with dithering",
    "Glow mode": "Glow mode",
    "BS": "BS",
    "BMBL": "BMBL",
    "range": "range",
    "strength": "strength",
    "InOutPaint": "InOutPaint",
    "fill up": "fill up",
    "fill down": "fill down",
    "fill left": "fill left",
    "fill right": "fill right",
    "Resolution": "Resolution",
    "haku_output": "haku_output",
    "Send to inpaint upload": "Send to inpaint upload",
    "Total num of layers (reload required)": "Total num of layers (reload required)",
    "Total num of point for curve (reload required)": "Total num of point for curve (reload required)",
    "a1111-sd-webui-haku-img": "a1111-sd-webui-haku-img",
    "https://github.com/KohakuBlueleaf/a1111-sd-webui-haku-img.git": "https://github.com/KohakuBlueleaf/a1111-sd-webui-haku-img.git",
    "State": "State",
    "Saved main elements": "Saved main elements",
    "tabs": "tabs",
    "Saved elements from txt2img": "Saved elements from txt2img",
    "prompt": "prompt",
    "negative_prompt": "negative_prompt",
    "sampling": "sampling",
    "sampling_steps": "sampling_steps",
    "batch_count": "batch_count",
    "batch_size": "batch_size",
    "cfg_scale": "cfg_scale",
    "restore_faces": "restore_faces",
    "tiling": "tiling",
    "hires_fix": "hires_fix",
    "hires_upscaler": "hires_upscaler",
    "hires_steps": "hires_steps",
    "hires_scale": "hires_scale",
    "hires_resize_x": "hires_resize_x",
    "hires_resize_y": "hires_resize_y",
    "hires_denoising_strength": "hires_denoising_strength",
    "Saved elements from img2img": "Saved elements from img2img",
    "resize_mode": "resize_mode",
    "denoising_strength": "denoising_strength",
    "https://github.com/ilian6806/stable-diffusion-webui-state.git": "https://github.com/ilian6806/stable-diffusion-webui-state.git",
    "Maximum width or height (whichever is higher)": "Maximum width or height (whichever is higher)",
    "Scale to maximum width or height": "Scale to maximum width or height",
    "-75%": "-75%",
    "-50%": "-50%",
    "-25%": "-25%",
    "+25%": "+25%",
    "+50%": "+50%",
    "+75%": "+75%",
    "+100%": "+100%",
    "Expand by default": "Expand by default",
    "Show maximum width or height button": "Show maximum width or height button",
    "Maximum width or height default": "Maximum width or height default",
    "Show predefined percentage buttons": "Show predefined percentage buttons",
    "Predefined percentage buttons, applied to dimensions (75, 125, 150)": "Predefined percentage buttons, applied to dimensions (75, 125, 150)",
    "Predefined percentage display format": "Predefined percentage display format",
    "Incremental/decremental percentage (-50%, +50%)": "Incremental/decremental percentage (-50%, +50%)",
    "Raw percentage (50%, 150%)": "Raw percentage (50%, 150%)",
    "Multiplication (x0.5, x1.5)": "Multiplication (x0.5, x1.5)",
    "sd-webui-aspect-ratio-helper": "sd-webui-aspect-ratio-helper",
    "https://github.com/thomasasfk/sd-webui-aspect-ratio-helper.git": "https://github.com/thomasasfk/sd-webui-aspect-ratio-helper.git",
    "Cafe Aesthetic": "Cafe Aesthetic",
    "Single": "Single",
    "Judge": "Judge",
    "Aesthetic": "Aesthetic",
    "Style": "Style",
    "Waifu": "Waifu",
    "Image Directory": "Image Directory",
    "Output Directory": "Output Directory",
    "Classify type": "Classify type",
    "Output style": "Output style",
    "Copy": "Copy",
    "Move": "Move",
    "Copy or move captions together": "Copy or move captions together",
    "Basis": "Basis",
    "Relative": "Relative",
    "Absolute": "Absolute",
    "Threshold (Use only when basis is absolute)": "Threshold (Use only when basis is absolute)",
    "Start": "Start",
    "Status": "Status",
    "Idle": "Idle",
    "stable-diffusion-webui-cafe-aesthetic": "stable-diffusion-webui-cafe-aesthetic",
    "https://github.com/p1atdev/stable-diffusion-webui-cafe-aesthetic": "https://github.com/p1atdev/stable-diffusion-webui-cafe-aesthetic",
    "path/to/classify": "path/to/classify",
    "path/to/output": "path/to/output",
    "BLIP2 Captioner": "BLIP2 Captioner",
    "Interrogate": "Interrogate",
    "Generated Caption": "Generated Caption",
    "Output Caption Extension": "Output Caption Extension",
    "Unload models": "Unload models",
    "Nucleus": "Nucleus",
    "Top-K": "Top-K",
    "Number of beams (0 = no beam search)": "Number of beams (0 = no beam search)",
    "Caption min length": "Caption min length",
    "Caption max length": "Caption max length",
    "Top p": "Top p",
    "stable-diffusion-webui-blip2-captioner": "stable-diffusion-webui-blip2-captioner",
    "https://github.com/p1atdev/stable-diffusion-webui-blip2-captioner": "https://github.com/p1atdev/stable-diffusion-webui-blip2-captioner",
    "Reconstruct prompt from existing image and put it into the prompt field.": "Reconstruct prompt from existing image and put it into the prompt field.",
    "path/to/caption": "path/to/caption",
    "txt": "txt",
    "Seed travel": "Seed travel",
    "Destination seed(s) (Comma separated)": "Destination seed(s) (Comma separated)",
    "Only use Random seeds (Unless comparing paths)": "Only use Random seeds (Unless comparing paths)",
    "Number of random seed(s)": "Number of random seed(s)",
    "Compare paths (Separate travels from 1st seed to each destination)": "Compare paths (Separate travels from 1st seed to each destination)",
    "Steps (Number of images between each seed)": "Steps (Number of images between each seed)",
    "Loop back to initial seed": "Loop back to initial seed",
    "Save results as video": "Save results as video",
    "Frames per second": "Frames per second",
    "Number of frames for lead in/out": "Number of frames for lead in/out",
    "Upscale ratio": "Upscale ratio",
    "Bump seed (If > 0 do a Compare Paths but only one image. No video will be generated.)": "Bump seed (If > 0 do a Compare Paths but only one image. No video will be generated.)",
    "Use cache": "Use cache",
    "Show generated images in ui": "Show generated images in ui",
    "Interpolation rate": "Interpolation rate",
    "Hug-the-middle": "Hug-the-middle",
    "Slow start": "Slow start",
    "Quick start": "Quick start",
    "Rate strength": "Rate strength",
    "Allow the default Euler a Sampling method. (Does not produce good results)": "Allow the default Euler a Sampling method. (Does not produce good results)",
    "seed_travel": "seed_travel",
    "https://github.com/yownas/seed_travel.git": "https://github.com/yownas/seed_travel.git",
    "sd-webui-regional-prompter": "sd-webui-regional-prompter",
    "https://github.com/hako-mikan/sd-webui-regional-prompter.git": "https://github.com/hako-mikan/sd-webui-regional-prompter.git",
    "Active": "Active",
    "Divide mode": "Divide mode",
    "Horizontal": "Horizontal",
    "Vertical": "Vertical",
    "Generation mode": "Generation mode",
    "Attention": "Attention",
    "Divide Ratio": "Divide Ratio",
    "Base Ratio": "Base Ratio",
    "Use base prompt": "Use base prompt",
    "Use common prompt": "Use common prompt",
    "Use common negative prompt": "Use common negative prompt",
    "visualize and make template": "visualize and make template",
    "template": "template",
    "Presets": "Presets",
    "disable convert 'AND' to 'BREAK'": "disable convert 'AND' to 'BREAK'",
    "debug": "debug",
    "Apply Presets": "Apply Presets",
    "Preset Name": "Preset Name",
    "Save to Presets": "Save to Presets",
    "Create inspiration images": "Create inspiration images",
    "Artist or styles name list. '.txt' files with one name per line": "Artist or styles name list. '.txt' files with one name per line",
    "Prompt Placeholder, which can be used at the top of prompt input": "Prompt Placeholder, which can be used at the top of prompt input",
    "To activate inspiration function, you need get \"inspiration\" images first.": "To activate inspiration function, you need get \"inspiration\" images first.",
    "You can create these images by run \"Create inspiration images\" script in txt2img page,": "You can create these images by run \"Create inspiration images\" script in txt2img page,",
    "you can get the artists or art styles list from here": "you can get the artists or art styles list from here",
    "download these files, and select these files in the \"Create inspiration images\" script UI": "download these files, and select these files in the \"Create inspiration images\" script UI",
    "There about 6000 artists and art styles in these files.": "There about 6000 artists and art styles in these files.",
    "This takes server hours depending on your GPU type and how many pictures  you generate for each artist/style": "This takes server hours depending on your GPU type and how many pictures  you generate for each artist/style",
    "I suggest at least four images for each": "I suggest at least four images for each",
    "You can also download generated pictures from here:": "You can also download generated pictures from here:",
    "unzip the file to": "unzip the file to",
    "/extections/stable-diffusion-webui-inspiration": "/extections/stable-diffusion-webui-inspiration",
    "and restart webui, and enjoy the joy of creation!": "and restart webui, and enjoy the joy of creation!",
    "Checkbox Group": "Checkbox Group",
    "artists": "artists",
    "flavors": "flavors",
    "mediums": "mediums",
    "movements": "movements",
    "Exclude abandoned": "Exclude abandoned",
    "Abandoned": "Abandoned",
    "Key word": "Key word",
    "Get inspiration": "Get inspiration",
    "to txt2img": "to txt2img",
    "to img2img": "to img2img",
    "Collect": "Collect",
    "Don't show again": "Don't show again",
    "Maximum number of samples, used to determine which folders to skip when continue running the create script": "Maximum number of samples, used to determine which folders to skip when continue running the create script",
    "stable-diffusion-webui-inspiration": "stable-diffusion-webui-inspiration",
    "https://github.com/yfszzx/stable-diffusion-webui-inspiration.git": "https://github.com/yfszzx/stable-diffusion-webui-inspiration.git",
    "Ultimate SD upscale": "Ultimate SD upscale",
    "Will upscale the image depending on the selected target size type": "Will upscale the image depending on the selected target size type",
    "Target size type": "Target size type",
    "From img2img2 settings": "From img2img2 settings",
    "Custom size": "Custom size",
    "Scale from image size": "Scale from image size",
    "Custom width": "Custom width",
    "Custom height": "Custom height",
    "Scale": "Scale",
    "Redraw options:": "Redraw options:",
    "Type": "Type",
    "Chess": "Chess",
    "Tile width": "Tile width",
    "Tile height": "Tile height",
    "Padding": "Padding",
    "Seams fix:": "Seams fix:",
    "Band pass": "Band pass",
    "Half tile offset pass": "Half tile offset pass",
    "Half tile offset pass + intersections": "Half tile offset pass + intersections",
    "Denoise": "Denoise",
    "Save options:": "Save options:",
    "Upscaled": "Upscaled",
    "Seams fix": "Seams fix",
    "ultimate-upscale-for-automatic1111": "ultimate-upscale-for-automatic1111",
    "https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git": "https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git",
    "Model Pre​views": "Model Pre​views",
    "Embeddings": "Embeddings",
    "Filter": "Filter",
    "Notes": "Notes",
    "Model Preview XD": "Model Preview XD",
    "Name matching rule for preview files": "Name matching rule for preview files",
    "Loose": "Loose",
    "Strict": "Strict",
    "Folder": "Folder",
    "Index": "Index",
    "Limit the height of preivews to the height of the browser window (.html preview files are always limited regardless of this setting)": "Limit the height of preivews to the height of the browser window (.html preview files are always limited regardless of this setting)",
    "sd-model-preview-xd": "sd-model-preview-xd",
    "No Preview Found": "No Preview Found",
    "https://github.com/CurtisDS/sd-model-preview-xd.git": "https://github.com/CurtisDS/sd-model-preview-xd.git",
    "Tag Autocomplete": "Tag Autocomplete",
    "Tag filename": "Tag filename",
    "Enable Tag Autocompletion": "Enable Tag Autocompletion",
    "Active in txt2img (Requires restart)": "Active in txt2img (Requires restart)",
    "Active in img2img (Requires restart)": "Active in img2img (Requires restart)",
    "Active in negative prompts (Requires restart)": "Active in negative prompts (Requires restart)",
    "Active in third party textboxes [Dataset Tag Editor] (Requires restart)": "Active in third party textboxes [Dataset Tag Editor] (Requires restart)",
    "List of model names (with file extension) or their hashes to use as black/whitelist, separated by commas.": "List of model names (with file extension) or their hashes to use as black/whitelist, separated by commas.",
    "Mode to use for model list": "Mode to use for model list",
    "Blacklist": "Blacklist",
    "Whitelist": "Whitelist",
    "Move completion popup together with text cursor": "Move completion popup together with text cursor",
    "Maximum results": "Maximum results",
    "Show all results": "Show all results",
    "How many results to load at once": "How many results to load at once",
    "Time in ms to wait before triggering completion again (Requires restart)": "Time in ms to wait before triggering completion again (Requires restart)",
    "Search for wildcards": "Search for wildcards",
    "Search for embeddings": "Search for embeddings",
    "Search for hypernetworks": "Search for hypernetworks",
    "Search for Loras": "Search for Loras",
    "Show '?' next to tags, linking to its Danbooru or e621 wiki page (Warning: This is an external site and very likely contains NSFW examples!)": "Show '?' next to tags, linking to its Danbooru or e621 wiki page (Warning: This is an external site and very likely contains NSFW examples!)",
    "Replace underscores with spaces on insertion": "Replace underscores with spaces on insertion",
    "Escape parentheses on insertion": "Escape parentheses on insertion",
    "Append comma on tag autocompletion": "Append comma on tag autocompletion",
    "Search by alias": "Search by alias",
    "Only show alias": "Only show alias",
    "Translation filename": "Translation filename",
    "Translation file uses old 3-column translation format instead of the new 2-column one": "Translation file uses old 3-column translation format instead of the new 2-column one",
    "Search by translation": "Search by translation",
    "Extra filename (for small sets of custom tags)": "Extra filename (for small sets of custom tags)",
    "Mode to add the extra tags to the main tag list": "Mode to add the extra tags to the main tag list",
    "Insert before": "Insert before",
    "Insert after": "Insert after",
    "a1111-sd-webui-tagcomplete": "a1111-sd-webui-tagcomplete",
    "https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git": "https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git",
    "Posex": "Posex",
    "Send this image to ControlNet.": "Send this image to ControlNet.",
    "Target ControlNet number": "Target ControlNet number",
    "https://github.com/hnmr293/posex.git": "https://github.com/hnmr293/posex.git",
    "Generate Ckpt": "Generate Ckpt",
    "Save Weights": "Save Weights",
    "Generate Samples": "Generate Samples",
    "Select or create a model to begin.": "Select or create a model to begin.",
    "Select": "Select",
    "Create": "Create",
    "Snapshot to Resume": "Snapshot to Resume",
    "Lora Model": "Lora Model",
    "Loaded Model:": "Loaded Model:",
    "Model Revision:": "Model Revision:",
    "Model Epoch:": "Model Epoch:",
    "V2 Model:": "V2 Model:",
    "Has EMA:": "Has EMA:",
    "Source Checkpoint:": "Source Checkpoint:",
    "Create Model": "Create Model",
    "Create From Hub": "Create From Hub",
    "512x Model": "512x Model",
    "Model Path": "Model Path",
    "HuggingFace Token": "HuggingFace Token",
    "Source Checkpoint": "Source Checkpoint",
    "Extract EMA Weights": "Extract EMA Weights",
    "Unfreeze Model": "Unfreeze Model",
    "Resources": "Resources",
    "Beginners guide": "Beginners guide",
    "Release notes": "Release notes",
    "Input": "Input",
    "Concepts": "Concepts",
    "Saving": "Saving",
    "Testing": "Testing",
    "Performance Wizard (WIP)": "Performance Wizard (WIP)",
    "Basic": "Basic",
    "General": "General",
    "Use LORA": "Use LORA",
    "Use Lora Extended": "Use Lora Extended",
    "Train Imagic Only": "Train Imagic Only",
    "Train Inpainting Model": "Train Inpainting Model",
    "Intervals": "Intervals",
    "Training Steps Per Image (Epochs)": "Training Steps Per Image (Epochs)",
    "Pause After N Epochs": "Pause After N Epochs",
    "Amount of time to pause between Epochs (s)": "Amount of time to pause between Epochs (s)",
    "Save Model Frequency (Epochs)": "Save Model Frequency (Epochs)",
    "Save Preview(s) Frequency (Epochs)": "Save Preview(s) Frequency (Epochs)",
    "Batching": "Batching",
    "Batch Size": "Batch Size",
    "Gradient Accumulation Steps": "Gradient Accumulation Steps",
    "Class Batch Size": "Class Batch Size",
    "Set Gradients to None When Zeroing": "Set Gradients to None When Zeroing",
    "Gradient Checkpointing": "Gradient Checkpointing",
    "Learning Rate": "Learning Rate",
    "Lora UNET Learning Rate": "Lora UNET Learning Rate",
    "Lora Text Encoder Learning Rate": "Lora Text Encoder Learning Rate",
    "Learning Rate Scheduler": "Learning Rate Scheduler",
    "linear_with_warmup": "linear_with_warmup",
    "cosine": "cosine",
    "cosine_annealing": "cosine_annealing",
    "cosine_annealing_with_restarts": "cosine_annealing_with_restarts",
    "cosine_with_restarts": "cosine_with_restarts",
    "polynomial": "polynomial",
    "constant": "constant",
    "constant_with_warmup": "constant_with_warmup",
    "Min Learning Rate": "Min Learning Rate",
    "Number of Hard Resets": "Number of Hard Resets",
    "Constant/Linear Starting Factor": "Constant/Linear Starting Factor",
    "Polynomial Power": "Polynomial Power",
    "Scale Position": "Scale Position",
    "Learning Rate Warmup Steps": "Learning Rate Warmup Steps",
    "Image Processing": "Image Processing",
    "Max Resolution": "Max Resolution",
    "Apply Horizontal Flip": "Apply Horizontal Flip",
    "Tuning": "Tuning",
    "Use EMA": "Use EMA",
    "Optimizer": "Optimizer",
    "Torch AdamW": "Torch AdamW",
    "8bit AdamW": "8bit AdamW",
    "Lion": "Lion",
    "Mixed Precision": "Mixed Precision",
    "fp16": "fp16",
    "Memory Attention": "Memory Attention",
    "default": "default",
    "Cache Latents": "Cache Latents",
    "Train UNET": "Train UNET",
    "Step Ratio of Text Encoder Training": "Step Ratio of Text Encoder Training",
    "Offset Noise": "Offset Noise",
    "Freeze CLIP Normalization Layers": "Freeze CLIP Normalization Layers",
    "Clip Skip": "Clip Skip",
    "Weight Decay": "Weight Decay",
    "Pad Tokens": "Pad Tokens",
    "Strict Tokens": "Strict Tokens",
    "Shuffle Tags": "Shuffle Tags",
    "Max Token Length": "Max Token Length",
    "Prior Loss": "Prior Loss",
    "Scale Prior Loss": "Scale Prior Loss",
    "Prior Loss Weight": "Prior Loss Weight",
    "Prior Loss Target": "Prior Loss Target",
    "Minimum Prior Loss Weight": "Minimum Prior Loss Weight",
    "Advanced": "Advanced",
    "Sanity Sample Prompt": "Sanity Sample Prompt",
    "Sanity Sample Negative Prompt": "Sanity Sample Negative Prompt",
    "Sanity Sample Seed": "Sanity Sample Seed",
    "Miscellaneous": "Miscellaneous",
    "Pretrained VAE Name or Path": "Pretrained VAE Name or Path",
    "Use Concepts List": "Use Concepts List",
    "Concepts List": "Concepts List",
    "API Key": "API Key",
    "Discord Webhook": "Discord Webhook",
    "Save and Test Webhook": "Save and Test Webhook",
    "Training Wizard (Person)": "Training Wizard (Person)",
    "Training Wizard (Object/Style)": "Training Wizard (Object/Style)",
    "Concept 1": "Concept 1",
    "Concept 2": "Concept 2",
    "Concept 3": "Concept 3",
    "Concept 4": "Concept 4",
    "Dataset Directory": "Dataset Directory",
    "Classification Dataset Directory": "Classification Dataset Directory",
    "Filewords": "Filewords",
    "Instance Token": "Instance Token",
    "Class Token": "Class Token",
    "Training Prompts": "Training Prompts",
    "Instance Prompt": "Instance Prompt",
    "Class Prompt": "Class Prompt",
    "Classification Image Negative Prompt": "Classification Image Negative Prompt",
    "Sample Prompts": "Sample Prompts",
    "Sample Image Prompt": "Sample Image Prompt",
    "Sample Negative Prompt": "Sample Negative Prompt",
    "Sample Prompt Template File": "Sample Prompt Template File",
    "Class Image Generation": "Class Image Generation",
    "Class Images Per Instance Image": "Class Images Per Instance Image",
    "Classification CFG Scale": "Classification CFG Scale",
    "Classification Steps": "Classification Steps",
    "Sample Image Generation": "Sample Image Generation",
    "Number of Samples to Generate": "Number of Samples to Generate",
    "Sample Seed": "Sample Seed",
    "Sample CFG Scale": "Sample CFG Scale",
    "Sample Steps": "Sample Steps",
    "Custom Model Name": "Custom Model Name",
    "Save in .safetensors format": "Save in .safetensors format",
    "Save EMA Weights to Generated Models": "Save EMA Weights to Generated Models",
    "Use EMA Weights for Inference": "Use EMA Weights for Inference",
    "Half Model": "Half Model",
    "Save Checkpoint to Subdirectory": "Save Checkpoint to Subdirectory",
    "Generate a .ckpt file when saving during training.": "Generate a .ckpt file when saving during training.",
    "Generate a .ckpt file when training completes.": "Generate a .ckpt file when training completes.",
    "Generate a .ckpt file when training is canceled.": "Generate a .ckpt file when training is canceled.",
    "Lora UNET Rank": "Lora UNET Rank",
    "Lora Text Encoder Rank": "Lora Text Encoder Rank",
    "Lora Weight": "Lora Weight",
    "Lora Text Weight": "Lora Text Weight",
    "Generate lora weights when saving during training.": "Generate lora weights when saving during training.",
    "Generate lora weights when training completes.": "Generate lora weights when training completes.",
    "Generate lora weights when training is canceled.": "Generate lora weights when training is canceled.",
    "Generate lora weights for extra networks.": "Generate lora weights for extra networks.",
    "Diffusion Weights (training snapshots)": "Diffusion Weights (training snapshots)",
    "Save separate diffusers snapshots when saving during training.": "Save separate diffusers snapshots when saving during training.",
    "Save separate diffusers snapshots when training completes.": "Save separate diffusers snapshots when training completes.",
    "Save separate diffusers snapshots when training is canceled.": "Save separate diffusers snapshots when training is canceled.",
    "Class Generation Schedulers": "Class Generation Schedulers",
    "Image Generation Library": "Image Generation Library",
    "A1111 txt2img (Euler a)": "A1111 txt2img (Euler a)",
    "Native Diffusers": "Native Diffusers",
    "Image Generation Scheduler": "Image Generation Scheduler",
    "DDPM": "DDPM",
    "PNDM": "PNDM",
    "LMSDiscrete": "LMSDiscrete",
    "EulerDiscrete": "EulerDiscrete",
    "HeunDiscrete": "HeunDiscrete",
    "EulerAncestralDiscrete": "EulerAncestralDiscrete",
    "DPMSolverMultistep": "DPMSolverMultistep",
    "DPMSolverSinglestep": "DPMSolverSinglestep",
    "KDPM2Discrete": "KDPM2Discrete",
    "KDPM2AncestralDiscrete": "KDPM2AncestralDiscrete",
    "DEISMultistep": "DEISMultistep",
    "UniPCMultistep": "UniPCMultistep",
    "Manual Class Generation": "Manual Class Generation",
    "Generate Class Images": "Generate Class Images",
    "Generate Graph": "Generate Graph",
    "Graph Smoothing Steps": "Graph Smoothing Steps",
    "Debug Buckets": "Debug Buckets",
    "Epochs to Simulate": "Epochs to Simulate",
    "Batch Size to Simulate": "Batch Size to Simulate",
    "Generate Sample Images": "Generate Sample Images",
    "Sample Prompt": "Sample Prompt",
    "Sample Prompt File": "Sample Prompt File",
    "Sample Width": "Sample Width",
    "Sample Height": "Sample Height",
    "Sample Batch Size": "Sample Batch Size",
    "Swap Sample Faces": "Swap Sample Faces",
    "Swap Prompt": "Swap Prompt",
    "Swap Negative Prompt": "Swap Negative Prompt",
    "Swap Steps": "Swap Steps",
    "Swap Batch": "Swap Batch",
    "Use txt2img": "Use txt2img",
    "Experimental Settings": "Experimental Settings",
    "Deterministic": "Deterministic",
    "Use EMA for prediction": "Use EMA for prediction",
    "Calculate Split Loss": "Calculate Split Loss",
    "Use TensorFloat 32": "Use TensorFloat 32",
    "Noise scheduler": "Noise scheduler",
    "DEIS": "DEIS",
    "Update Extension and Restart": "Update Extension and Restart",
    "Bucket Cropping": "Bucket Cropping",
    "Source Path": "Source Path",
    "Dest Path": "Dest Path",
    "Max Res": "Max Res",
    "Bucket Steps": "Bucket Steps",
    "Dry Run": "Dry Run",
    "Start Cropping": "Start Cropping",
    "Check Progress": "Check Progress",
    "Update Parameters": "Update Parameters",
    "Changelog": "Changelog",
    "X": "X",
    "sd_dreambooth_extension": "sd_dreambooth_extension",
    "https://github.com/d8ahazard/sd_dreambooth_extension.git": "https://github.com/d8ahazard/sd_dreambooth_extension.git",
    "runwayml/stable-diffusion-v1-5": "runwayml/stable-diffusion-v1-5",
    "A generic prompt used to generate a sample image to verify model fidelity.": "A generic prompt used to generate a sample image to verify model fidelity.",
    "A negative prompt for the generic sample image.": "A negative prompt for the generic sample image.",
    "Leave blank to use base model VAE.": "Leave blank to use base model VAE.",
    "Path to JSON file with concepts to train.": "Path to JSON file with concepts to train.",
    "https://discord.com/api/webhooks/XXX/XXXX": "https://discord.com/api/webhooks/XXX/XXXX",
    "(Optional) Path to directory with classification/regularization images": "(Optional) Path to directory with classification/regularization images",
    "When using [filewords], this is the subject to use when building prompts.": "When using [filewords], this is the subject to use when building prompts.",
    "When using [filewords], this is the class to use when building prompts.": "When using [filewords], this is the class to use when building prompts.",
    "Optionally use [filewords] to read image captions from files.": "Optionally use [filewords] to read image captions from files.",
    "Leave blank to use instance prompt. Optionally use [filewords] to base sample captions on instance images.": "Leave blank to use instance prompt. Optionally use [filewords] to base sample captions on instance images.",
    "Enter the path to a txt file containing sample prompts.": "Enter the path to a txt file containing sample prompts.",
    "Enter a model name for saving checkpoints and lora models.": "Enter a model name for saving checkpoints and lora models.",
    "Tagger": "Tagger",
    "Single process": "Single process",
    "Batch from directory": "Batch from directory",
    "Use recursive with glob pattern": "Use recursive with glob pattern",
    "Output filename format": "Output filename format",
    "Output filename formats": "Output filename formats",
    "Related to original file": "Related to original file",
    "[name]": "[name]",
    ": Original filename without extension": ": Original filename without extension",
    "[extension]": "[extension]",
    ": Original extension": ": Original extension",
    "[hash:<algorithms>]": "[hash:<algorithms>]",
    ": Original extension\nAvailable algorithms:": ": Original extension\nAvailable algorithms:",
    "sha1, blake2s, shake_256, sha256, md5-sha1, sha512_256, shake_128, mdc2, ripemd160, whirlpool, md5, sha3_384, sha512, sha3_512, blake2b, sha224, sm3, sha512_224, sha3_224, sha384, md4, sha3_256": "sha1, blake2s, shake_256, sha256, md5-sha1, sha512_256, shake_128, mdc2, ripemd160, whirlpool, md5, sha3_384, sha512, sha3_512, blake2b, sha224, sm3, sha512_224, sha3_224, sha384, md4, sha3_256",
    "Related to output file": "Related to output file",
    "[output_extension]": "[output_extension]",
    ": Output extension (has no dot)": ": Output extension (has no dot)",
    "Examples": "Examples",
    "Original filename without extension": "Original filename without extension",
    "[name].[output_extension]": "[name].[output_extension]",
    "Original file's hash (good for deleting duplication)": "Original file's hash (good for deleting duplication)",
    "[hash:sha1].[output_extension]": "[hash:sha1].[output_extension]",
    "Action on existing caption": "Action on existing caption",
    "Remove duplicated tag": "Remove duplicated tag",
    "Save with JSON": "Save with JSON",
    "default.json": "default.json",
    "Interrogator": "Interrogator",
    "wd14-convnext": "wd14-convnext",
    "wd14-convnext-v2": "wd14-convnext-v2",
    "wd14-convnext-v2-git": "wd14-convnext-v2-git",
    "wd14-swinv2-v2": "wd14-swinv2-v2",
    "wd14-swinv2-v2-git": "wd14-swinv2-v2-git",
    "wd14-vit": "wd14-vit",
    "wd14-vit-v2": "wd14-vit-v2",
    "wd14-vit-v2-git": "wd14-vit-v2-git",
    "Unload all interrogate models": "Unload all interrogate models",
    "Threshold": "Threshold",
    "Additional tags (split by comma)": "Additional tags (split by comma)",
    "Exclude tags (split by comma)": "Exclude tags (split by comma)",
    "Sort by alphabetical order": "Sort by alphabetical order",
    "Include confident of tags matches in results": "Include confident of tags matches in results",
    "Use spaces instead of underscore": "Use spaces instead of underscore",
    "Excudes (split by comma)": "Excudes (split by comma)",
    "Escape brackets": "Escape brackets",
    "Unload model after running": "Unload model after running",
    "Tags": "Tags",
    "Rating confidents": "Rating confidents",
    "Tag confidents": "Tag confidents",
    "stable-diffusion-webui-wd14-tagger": "stable-diffusion-webui-wd14-tagger",
    "https://github.com/toriato/stable-diffusion-webui-wd14-tagger.git": "https://github.com/toriato/stable-diffusion-webui-wd14-tagger.git",
    "/path/to/images or /path/to/images/**/*": "/path/to/images or /path/to/images/**/*",
    "Leave blank to save images to the same path.": "Leave blank to save images to the same path.",
    "Leave blank to use same filename as original.": "Leave blank to use same filename as original.",
    "Found tags": "Found tags",
    "auto-sd-paint-ext Guide/Panel": "auto-sd-paint-ext Guide/Panel",
    "Generate Krita Plugin Symlink Command": "Generate Krita Plugin Symlink Command",
    "Launch Krita.": "Launch Krita.",
    "On the menubar, go to": "On the menubar, go to",
    "Settings > Manage Resources...": "Settings > Manage Resources...",
    "In the window that appears, click": "In the window that appears, click",
    "Open Resource Folder": "Open Resource Folder",
    "In the file explorer that appears, look for a folder called": "In the file explorer that appears, look for a folder called",
    "pykrita": "pykrita",
    "or create it.": "or create it.",
    "Enter the": "Enter the",
    "folder and copy the folder location from the address bar.": "folder and copy the folder location from the address bar.",
    "Paste the folder location below.": "Paste the folder location below.",
    "Pykrita Folder Location": "Pykrita Folder Location",
    "Search for \"Command Prompt\" in the Start Menu, right-click and click \"Run as Administrator...\", paste the follow commands and hit Enter:": "Search for \"Command Prompt\" in the Start Menu, right-click and click \"Run as Administrator...\", paste the follow commands and hit Enter:",
    "mklink /j \"<path_to_pykrita>\\krita_diff\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\"\nmklink \"<path_to_pykrita>\\krita_diff.desktop\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\"": "mklink /j \"<path_to_pykrita>\\krita_diff\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\"\nmklink \"<path_to_pykrita>\\krita_diff.desktop\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\"",
    "Linux command:": "Linux command:",
    "ln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\" \"<path_to_pykrita>/krita_diff\"\nln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\" \"<path_to_pykrita>/krita_diff.desktop\"": "ln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\" \"<path_to_pykrita>/krita_diff\"\nln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\" \"<path_to_pykrita>/krita_diff.desktop\"",
    "NOTE": "NOTE",
    ": Symlinks will break if you move or rename the repository or any\nof its parent folders or otherwise change the path such that the symlink\nbecomes invalid. In which case, repeat the above steps with the new": ": Symlinks will break if you move or rename the repository or any\nof its parent folders or otherwise change the path such that the symlink\nbecomes invalid. In which case, repeat the above steps with the new",
    "folder location and (auto-detected) repository location.": "folder location and (auto-detected) repository location.",
    ": Ensure": ": Ensure",
    "webui-user.bat": "webui-user.bat",
    "webui-user.sh": "webui-user.sh",
    "contains": "contains",
    "--api": "--api",
    "in": "in",
    "COMMANDLINE_ARGS": "COMMANDLINE_ARGS",
    "Enabling the Krita Plugin": "Enabling the Krita Plugin",
    "Restart Krita.": "Restart Krita.",
    "Settings > Configure Krita...": "Settings > Configure Krita...",
    "On the left sidebar, go to": "On the left sidebar, go to",
    "Python Plugin Manager": "Python Plugin Manager",
    "Look for": "Look for",
    "Stable Diffusion Plugin": "Stable Diffusion Plugin",
    "and tick the checkbox.": "and tick the checkbox.",
    "Restart Krita again for changes to take effect.": "Restart Krita again for changes to take effect.",
    "SD Plugin": "SD Plugin",
    "docked window should appear on the left of the Krita window. If it does not, look on the menubar under": "docked window should appear on the left of the Krita window. If it does not, look on the menubar under",
    "Settings > Dockers": "Settings > Dockers",
    "Next Steps": "Next Steps",
    "Troubleshooting": "Troubleshooting",
    "Update Guide": "Update Guide",
    "Usage Guide": "Usage Guide",
    "TODO: Control/status panel": "TODO: Control/status panel",
    "https://github.com/Interpause/auto-sd-paint-ext.git": "https://github.com/Interpause/auto-sd-paint-ext.git",
    "DreamArtist Create embedding": "DreamArtist Create embedding",
    "DreamArtist Train": "DreamArtist Train",
    "Process Att-Map": "Process Att-Map",
    "Initialization text (negative)": "Initialization text (negative)",
    "Number of negative vectors per token": "Number of negative vectors per token",
    "Unet Learning rate": "Unet Learning rate",
    "Train with DreamArtist": "Train with DreamArtist",
    "Train with reconstruction": "Train with reconstruction",
    "Attention Map": "Attention Map",
    "Train U-Net": "Train U-Net",
    "CFG scale (dynamic cfg: low,high:type e.g. 1.0-3.5:cos)": "CFG scale (dynamic cfg: low,high:type e.g. 1.0-3.5:cos)",
    "Reconstruction loss weight": "Reconstruction loss weight",
    "Negative lr weight": "Negative lr weight",
    "Classifier path": "Classifier path",
    "Accumulation steps": "Accumulation steps",
    "Prompt template file": "Prompt template file",
    "Positive \"filewords\" only": "Positive \"filewords\" only",
    "Experimental features (May be solve the problem of erratic training and difficult to reproduce [set EMA to 0.97])": "Experimental features (May be solve the problem of erratic training and difficult to reproduce [set EMA to 0.97])",
    "EMA (positive)": "EMA (positive)",
    "EMA replace steps (positive)": "EMA replace steps (positive)",
    "EMA (nagetive)": "EMA (nagetive)",
    "EMA replace steps (nagative)": "EMA replace steps (nagative)",
    "beta1": "beta1",
    "beta2": "beta2",
    "Since there is a self-attention operation in VAE, it may change the distribution of features. This processing will superimpose the attention map of self-attention on the original Att-Map.": "Since there is a self-attention operation in VAE, it may change the distribution of features. This processing will superimpose the attention map of self-attention on the original Att-Map.",
    "Data directory": "Data directory",
    "Process": "Process",
    "DreamArtist-sd-webui-extension": "DreamArtist-sd-webui-extension",
    "Path to classifier ckpt, can be empty": "Path to classifier ckpt, can be empty",
    "https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git": "https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git",
    "Additional Networks": "Additional Networks",
    "Separate UNet/Text Encoder weights": "Separate UNet/Text Encoder weights",
    "Network module 1": "Network module 1",
    "LoRA": "LoRA",
    "Model 1": "Model 1",
    "Weight 1": "Weight 1",
    "UNet Weight 1": "UNet Weight 1",
    "TEnc Weight 1": "TEnc Weight 1",
    "Network module 2": "Network module 2",
    "Model 2": "Model 2",
    "Weight 2": "Weight 2",
    "UNet Weight 2": "UNet Weight 2",
    "TEnc Weight 2": "TEnc Weight 2",
    "Network module 3": "Network module 3",
    "Model 3": "Model 3",
    "Weight 3": "Weight 3",
    "UNet Weight 3": "UNet Weight 3",
    "TEnc Weight 3": "TEnc Weight 3",
    "Network module 4": "Network module 4",
    "Model 4": "Model 4",
    "Weight 4": "Weight 4",
    "UNet Weight 4": "UNet Weight 4",
    "TEnc Weight 4": "TEnc Weight 4",
    "Network module 5": "Network module 5",
    "Model 5": "Model 5",
    "Weight 5": "Weight 5",
    "UNet Weight 5": "UNet Weight 5",
    "TEnc Weight 5": "TEnc Weight 5",
    "Extra args": "Extra args",
    "mask image:": "mask image:",
    "Refresh models": "Refresh models",
    "AddNet Model 1": "AddNet Model 1",
    "AddNet Weight 1": "AddNet Weight 1",
    "AddNet UNet Weight 1": "AddNet UNet Weight 1",
    "AddNet TEnc Weight 1": "AddNet TEnc Weight 1",
    "AddNet Model 2": "AddNet Model 2",
    "AddNet Weight 2": "AddNet Weight 2",
    "AddNet UNet Weight 2": "AddNet UNet Weight 2",
    "AddNet TEnc Weight 2": "AddNet TEnc Weight 2",
    "AddNet Model 3": "AddNet Model 3",
    "AddNet Weight 3": "AddNet Weight 3",
    "AddNet UNet Weight 3": "AddNet UNet Weight 3",
    "AddNet TEnc Weight 3": "AddNet TEnc Weight 3",
    "AddNet Model 4": "AddNet Model 4",
    "AddNet Weight 4": "AddNet Weight 4",
    "AddNet UNet Weight 4": "AddNet UNet Weight 4",
    "AddNet TEnc Weight 4": "AddNet TEnc Weight 4",
    "AddNet Model 5": "AddNet Model 5",
    "AddNet Weight 5": "AddNet Weight 5",
    "AddNet UNet Weight 5": "AddNet UNet Weight 5",
    "AddNet TEnc Weight 5": "AddNet TEnc Weight 5",
    "Model path filter": "Model path filter",
    "Filter models by path name": "Filter models by path name",
    "Network module": "Network module",
    "Model hash": "Model hash",
    "Legacy hash": "Legacy hash",
    "Model path": "Model path",
    "Send to txt2img:": "Send to txt2img:",
    "Send to img2img:": "Send to img2img:",
    "Copy metadata to other models in directory": "Copy metadata to other models in directory",
    "Containing directory": "Containing directory",
    "All models in this directory will receive the selected model's metadata": "All models in this directory will receive the selected model's metadata",
    "Only copy to models with same session ID": "Only copy to models with same session ID",
    "Only copy to models with no metadata": "Only copy to models with no metadata",
    "Copy Metadata": "Copy Metadata",
    "Display name for this model": "Display name for this model",
    "Author": "Author",
    "Author of this model": "Author of this model",
    "Keywords": "Keywords",
    "Activation keywords, comma-separated": "Activation keywords, comma-separated",
    "Model description/readme/notes/instructions": "Model description/readme/notes/instructions",
    "Source URL where this model could be found": "Source URL where this model could be found",
    "Rating": "Rating",
    "Comma-separated list of tags (\"artist, style, character, 2d, 3d...\")": "Comma-separated list of tags (\"artist, style, character, 2d, 3d...\")",
    "Editing Enabled": "Editing Enabled",
    "Save Metadata": "Save Metadata",
    "Cover image": "Cover image",
    "Image Parameters": "Image Parameters",
    "Training info": "Training info",
    "Most frequent tags in captions": "Most frequent tags in captions",
    "Dataset folder structure": "Dataset folder structure",
    "Image Count": "Image Count",
    "Repeats": "Repeats",
    "Total Images": "Total Images",
    "Training parameters": "Training parameters",
    "copy to clipboard": "copy to clipboard",
    "Extra paths to scan for LoRA models, comma-separated. Paths containing commas must be enclosed in double quotes. In the path, \" (one quote) must be replaced by \"\" (two quotes).": "Extra paths to scan for LoRA models, comma-separated. Paths containing commas must be enclosed in double quotes. In the path, \" (one quote) must be replaced by \"\" (two quotes).",
    "Sort LoRA models by": "Sort LoRA models by",
    "name": "name",
    "rating": "rating",
    "has user metadata": "has user metadata",
    "Reverse model sort order": "Reverse model sort order",
    "LoRA model name filter": "LoRA model name filter",
    "Metadata to show in XY-Grid label for Model axes, comma-separated (example: \"ss_learning_rate, ss_num_epochs\")": "Metadata to show in XY-Grid label for Model axes, comma-separated (example: \"ss_learning_rate, ss_num_epochs\")",
    "# of threads to use for hash calculation (increase if using an SSD)": "# of threads to use for hash calculation (increase if using an SSD)",
    "Make a backup copy of the model being edited when saving its metadata.": "Make a backup copy of the model being edited when saving its metadata.",
    "Only show .safetensors format models": "Only show .safetensors format models",
    "Only show models that have/don't have user-added metadata": "Only show models that have/don't have user-added metadata",
    "has metadata": "has metadata",
    "missing metadata": "missing metadata",
    "Max number of top tags to show": "Max number of top tags to show",
    "Max number of dataset folders to show": "Max number of dataset folders to show",
    "sd-webui-additional-networks": "sd-webui-additional-networks",
    "https://github.com/kohya-ss/sd-webui-additional-networks.git": "https://github.com/kohya-ss/sd-webui-additional-networks.git",
    "This extension works well with text captions in comma-separated style (such as the tags generated by DeepBooru interrogator).": "This extension works well with text captions in comma-separated style (such as the tags generated by DeepBooru interrogator).",
    "Save all changes": "Save all changes",
    "Backup original text file (original file will be renamed like filename.000, .001, .002, ...)": "Backup original text file (original file will be renamed like filename.000, .001, .002, ...)",
    "Note:": "Note:",
    "New text file will be created if you are using filename as captions.": "New text file will be created if you are using filename as captions.",
    "Use kohya-ss's finetuning metadata json": "Use kohya-ss's finetuning metadata json",
    "json path": "json path",
    "json input path (Optional, only for append results)": "json input path (Optional, only for append results)",
    "Overwrite if output file exists": "Overwrite if output file exists",
    "Save metadata as caption": "Save metadata as caption",
    "Save metadata image key as fullpath": "Save metadata image key as fullpath",
    "Results": "Results",
    "Reload/Save Settings (config.json)": "Reload/Save Settings (config.json)",
    "Reload settings": "Reload settings",
    "Save current settings": "Save current settings",
    "Restore settings to default": "Restore settings to default",
    "Caption File Ext": "Caption File Ext",
    "Load": "Load",
    "Unload": "Unload",
    "Dataset Load Settings": "Dataset Load Settings",
    "Load from subdirectories": "Load from subdirectories",
    "Load caption from filename if no text file exists": "Load caption from filename if no text file exists",
    "Replace new-line character with comma": "Replace new-line character with comma",
    "Use Interrogator Caption": "Use Interrogator Caption",
    "If Empty": "If Empty",
    "Overwrite": "Overwrite",
    "Prepend": "Prepend",
    "Append": "Append",
    "Interrogators": "Interrogators",
    "Interrogator Settings": "Interrogator Settings",
    "Use Custom Threshold (Booru)": "Use Custom Threshold (Booru)",
    "Booru Score Threshold": "Booru Score Threshold",
    "Use Custom Threshold (WDv1.4 Tagger)": "Use Custom Threshold (WDv1.4 Tagger)",
    "WDv1.4 Tagger Score Threshold": "WDv1.4 Tagger Score Threshold",
    "Dataset Filter": "Dataset Filter",
    "Filter Apply": "Filter Apply",
    "hidden_idx_next": "hidden_idx_next",
    "hidden_idx_prev": "hidden_idx_prev",
    "Dataset Images": "Dataset Images",
    "Filter by Tags": "Filter by Tags",
    "Filter by Selection": "Filter by Selection",
    "Batch Edit Captions": "Batch Edit Captions",
    "Edit Caption of Selected Image": "Edit Caption of Selected Image",
    "Move or Delete Files": "Move or Delete Files",
    "Clear tag filters": "Clear tag filters",
    "Clear ALL filters": "Clear ALL filters",
    "Positive Filter": "Positive Filter",
    "Negative Filter": "Negative Filter",
    "Search tags / Filter images by tags": "Search tags / Filter images by tags",
    "(INCLUSIVE)": "(INCLUSIVE)",
    "Search Tags": "Search Tags",
    "Prefix": "Prefix",
    "Suffix": "Suffix",
    "Use regex": "Use regex",
    "Alphabetical Order": "Alphabetical Order",
    "Frequency": "Frequency",
    "Length": "Length",
    "Token Length": "Token Length",
    "Sort Order": "Sort Order",
    "Ascending": "Ascending",
    "Descending": "Descending",
    "Filter Logic": "Filter Logic",
    "AND": "AND",
    "OR": "OR",
    "NONE": "NONE",
    "Filter Images by Tags": "Filter Images by Tags",
    "(EXCLUSIVE)": "(EXCLUSIVE)",
    "Select images from the left gallery.": "Select images from the left gallery.",
    "Add selection [Enter]": "Add selection [Enter]",
    "Add ALL Displayed": "Add ALL Displayed",
    "Filter Images": "Filter Images",
    "Selected Image :": "Selected Image :",
    "Remove selection [Delete]": "Remove selection [Delete]",
    "Invert selection": "Invert selection",
    "Clear selection": "Clear selection",
    "Apply selection filter": "Apply selection filter",
    "Search and Replace": "Search and Replace",
    "Remove": "Remove",
    "Edit common tags.": "Edit common tags.",
    "Show only the tags selected in the Positive Filter": "Show only the tags selected in the Positive Filter",
    "Common Tags": "Common Tags",
    "Edit Tags": "Edit Tags",
    "Prepend additional tags": "Prepend additional tags",
    "Apply changes to filtered images": "Apply changes to filtered images",
    "Show description of how to edit tags": "Show description of how to edit tags",
    "1. The tags common to all displayed images are shown in comma separated style.": "1. The tags common to all displayed images are shown in comma separated style.",
    "2. When changes are applied, all tags in each displayed images are replaced.": "2. When changes are applied, all tags in each displayed images are replaced.",
    "3. If you change some tags into blank, they will be erased.": "3. If you change some tags into blank, they will be erased.",
    "4. If you add some tags to the end, they will be added to the end/beginning of the text file.": "4. If you add some tags to the end, they will be added to the end/beginning of the text file.",
    "5. Changes are not applied to the text files until the \"Save all changes\" button is pressed.": "5. Changes are not applied to the text files until the \"Save all changes\" button is pressed.",
    "ex A.": "ex A.",
    "Original Text = \"A, A, B, C\" Common Tags = \"B, A\" Edit Tags = \"X, Y\"": "Original Text = \"A, A, B, C\" Common Tags = \"B, A\" Edit Tags = \"X, Y\"",
    "Result = \"Y, Y, X, C\" (B->X, A->Y)": "Result = \"Y, Y, X, C\" (B->X, A->Y)",
    "ex B.": "ex B.",
    "Original Text = \"A, B, C\" Common Tags = \"(nothing)\" Edit Tags = \"X, Y\"": "Original Text = \"A, B, C\" Common Tags = \"(nothing)\" Edit Tags = \"X, Y\"",
    "Result = \"A, B, C, X, Y\" (add X and Y to the end (default))": "Result = \"A, B, C, X, Y\" (add X and Y to the end (default))",
    "Result = \"X, Y, A, B, C\" (add X and Y to the beginning (\"Prepend additional tags\" checked))": "Result = \"X, Y, A, B, C\" (add X and Y to the beginning (\"Prepend additional tags\" checked))",
    "ex C.": "ex C.",
    "Original Text = \"A, B, C, D, E\" Common Tags = \"A, B, D\" Edit Tags = \", X, \"": "Original Text = \"A, B, C, D, E\" Common Tags = \"A, B, D\" Edit Tags = \", X, \"",
    "Result = \"X, C, E\" (A->\"\", B->X, D->\"\")": "Result = \"X, C, E\" (A->\"\", B->X, D->\"\")",
    "Search and Replace for all images displayed.": "Search and Replace for all images displayed.",
    "Search Text": "Search Text",
    "Replace Text": "Replace Text",
    "Search and Replace in": "Search and Replace in",
    "Only Selected Tags": "Only Selected Tags",
    "Each Tags": "Each Tags",
    "Entire Caption": "Entire Caption",
    "Selected Tags": "Selected Tags",
    "duplicate": "duplicate",
    "tags from the images displayed.": "tags from the images displayed.",
    "Remove duplicate tags": "Remove duplicate tags",
    "selected": "selected",
    "Remove selected tags": "Remove selected tags",
    "Select visible tags": "Select visible tags",
    "Deselect visible tags": "Deselect visible tags",
    "Select Tags": "Select Tags",
    "Sort tags in the images displayed.": "Sort tags in the images displayed.",
    "Sort tags": "Sort tags",
    "Truncate tags by token count.": "Truncate tags by token count.",
    "Truncate tags by token count": "Truncate tags by token count",
    "hidden_s_or_n": "hidden_s_or_n",
    "Read Caption from Selected Image": "Read Caption from Selected Image",
    "Interrogate Selected Image": "Interrogate Selected Image",
    "Caption of Selected Image": "Caption of Selected Image",
    "Copy and Overwrite": "Copy and Overwrite",
    "BLIP": "BLIP",
    "DeepDanbooru": "DeepDanbooru",
    "wd-v1-4-vit-tagger": "wd-v1-4-vit-tagger",
    "wd-v1-4-convnext-tagger": "wd-v1-4-convnext-tagger",
    "wd-v1-4-vit-tagger-v2": "wd-v1-4-vit-tagger-v2",
    "wd-v1-4-convnext-tagger-v2": "wd-v1-4-convnext-tagger-v2",
    "wd-v1-4-swinv2-tagger-v2": "wd-v1-4-swinv2-tagger-v2",
    "Interrogate Result": "Interrogate Result",
    "Copy caption from selected images automatically": "Copy caption from selected images automatically",
    "Sort caption on save": "Sort caption on save",
    "Warn if changes in caption is not saved": "Warn if changes in caption is not saved",
    "Edit Caption": "Edit Caption",
    "Apply changes to selected image": "Apply changes to selected image",
    "Apply changes to ALL displayed images": "Apply changes to ALL displayed images",
    "Changes are not applied to the text files until the \"Save all changes\" button is pressed.": "Changes are not applied to the text files until the \"Save all changes\" button is pressed.",
    "Moved or deleted images will be unloaded.": "Moved or deleted images will be unloaded.",
    "Move or Delete": "Move or Delete",
    "Selected One": "Selected One",
    "All Displayed Ones": "All Displayed Ones",
    "Image File": "Image File",
    "Caption Text File": "Caption Text File",
    "Caption Backup File": "Caption Backup File",
    "Target dataset num: 0": "Target dataset num: 0",
    "Destination Directory": "Destination Directory",
    "Move File(s)": "Move File(s)",
    "DELETE cannot be undone. The files will be deleted completely.": "DELETE cannot be undone. The files will be deleted completely.",
    "DELETE File(s)": "DELETE File(s)",
    "Number of columns on image gallery": "Number of columns on image gallery",
    "Force image gallery to use temporary files": "Force image gallery to use temporary files",
    "Use raw CLIP token to calculate token count (without emphasis or embeddings)": "Use raw CLIP token to calculate token count (without emphasis or embeddings)",
    "stable-diffusion-webui-dataset-tag-editor": "stable-diffusion-webui-dataset-tag-editor",
    "https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor": "https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor",
    "C:\\path\\to\\metadata.json": "C:\\path\\to\\metadata.json",
    "C:\\directory\\of\\datasets": "C:\\directory\\of\\datasets",
    ".txt (on Load and Save)": ".txt (on Load and Save)",
    "https://github.com/Bing-su/sd-webui-tunnels.git": "https://github.com/Bing-su/sd-webui-tunnels.git",
    "ControlNet-M2M": "ControlNet-M2M",
    "Config file for Control Net models": "Config file for Control Net models",
    "Config file for Adapter models": "Config file for Adapter models",
    "Directory for detected maps auto saving": "Directory for detected maps auto saving",
    "Extra path to scan for ControlNet models (e.g. training output directory)": "Extra path to scan for ControlNet models (e.g. training output directory)",
    "Multi ControlNet: Max models amount (requires restart)": "Multi ControlNet: Max models amount (requires restart)",
    "Model cache size (requires restart)": "Model cache size (requires restart)",
    "Apply transfer control when loading models": "Apply transfer control when loading models",
    "Do not append detectmap to output": "Do not append detectmap to output",
    "Allow detectmap auto saving": "Allow detectmap auto saving",
    "Use mid-control on highres pass (second pass)": "Use mid-control on highres pass (second pass)",
    "Allow other script to control this extension": "Allow other script to control this extension",
    "Skip img2img processing when using img2img initial image": "Skip img2img processing when using img2img initial image",
    "Enable optimized monocular depth estimation": "Enable optimized monocular depth estimation",
    "Only use mid-control when inference": "Only use mid-control when inference",
    "Enable CFG-Based guidance": "Enable CFG-Based guidance",
    "Passing ControlNet parameters with \"Send to img2img\"": "Passing ControlNet parameters with \"Send to img2img\"",
    "https://github.com/Mikubill/sd-webui-controlnet.git": "https://github.com/Mikubill/sd-webui-controlnet.git",
    "Annotator result": "Annotator result",
    "Invert colors if your image has white background.": "Invert colors if your image has white background.",
    "Change your brush width to make it thinner if you want to draw something.": "Change your brush width to make it thinner if you want to draw something.",
    "Invert Input Color": "Invert Input Color",
    "RGB to BGR": "RGB to BGR",
    "Low VRAM": "Low VRAM",
    "Guess Mode": "Guess Mode",
    "Preprocessor": "Preprocessor",
    "Guidance Start (T)": "Guidance Start (T)",
    "Guidance End (T)": "Guidance End (T)",
    "Annotator resolution": "Annotator resolution",
    "Threshold A": "Threshold A",
    "Threshold B": "Threshold B",
    "Resize Mode": "Resize Mode",
    "Just Resize": "Just Resize",
    "Scale to Fit (Inner Fit)": "Scale to Fit (Inner Fit)",
    "Envelope (Outer Fit)": "Envelope (Outer Fit)",
    "Create blank canvas": "Create blank canvas",
    "Preview annotator result": "Preview annotator result",
    "Hide annotator result": "Hide annotator result",
    "canny": "canny",
    "depth": "depth",
    "depth_leres": "depth_leres",
    "hed": "hed",
    "mlsd": "mlsd",
    "normal_map": "normal_map",
    "openpose": "openpose",
    "openpose_hand": "openpose_hand",
    "clip_vision": "clip_vision",
    "color": "color",
    "pidinet": "pidinet",
    "scribble": "scribble",
    "fake_scribble": "fake_scribble",
    "segmentation": "segmentation",
    "binary": "binary",
    "[ControlNet] Enabled": "[ControlNet] Enabled",
    "[ControlNet] Model": "[ControlNet] Model",
    "[ControlNet] Weight": "[ControlNet] Weight",
    "[ControlNet] Guidance Start": "[ControlNet] Guidance Start",
    "[ControlNet] Guidance End": "[ControlNet] Guidance End",
    "[ControlNet] Resize Mode": "[ControlNet] Resize Mode",
    "[ControlNet] Preprocessor": "[ControlNet] Preprocessor",
    "[ControlNet] Pre Resolution": "[ControlNet] Pre Resolution",
    "[ControlNet] Pre Threshold A": "[ControlNet] Pre Threshold A",
    "[ControlNet] Pre Threshold B": "[ControlNet] Pre Threshold B",
    "Main": "Main",
    "LAB Tools": "LAB Tools",
    "Guide": "Guide",
    "Abysz LAB 0.1.9 Temporal coherence tools": "Abysz LAB 0.1.9 Temporal coherence tools",
    "DFI Render": "DFI Render",
    "Original frames folder": "Original frames folder",
    "Generated frames folder": "Generated frames folder",
    "Output folder": "Output folder",
    "Info": "Info",
    "The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.": "The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.",
    "Source denoise:": "Source denoise:",
    "A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.": "A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.",
    "(This is a demanding algorithm)": "(This is a demanding algorithm)",
    "DFI Tolerance:": "DFI Tolerance:",
    "Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.": "Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.",
    "This parameter commands the new dynamic algorithm.": "This parameter commands the new dynamic algorithm.",
    "DFI Expand:": "DFI Expand:",
    "DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.": "DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.",
    "Source Denoise": "Source Denoise",
    "DFI Tolerance": "DFI Tolerance",
    "DFI Expand": "DFI Expand",
    "Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.": "Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.",
    "The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).": "The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).",
    "Preview DFI Map": "Preview DFI Map",
    "Preview amount. 0 = Quick shoot": "Preview amount. 0 = Quick shoot",
    "Inter Denoise:": "Inter Denoise:",
    "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.": "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.",
    "Inter Blur:": "Inter Blur:",
    "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.": "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.",
    "Corruption Refresh:": "Corruption Refresh:",
    "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.": "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.",
    "Corruption Preserve:": "Corruption Preserve:",
    "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.": "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.",
    "Smooth:": "Smooth:",
    "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.": "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.",
    "Inter Denoise": "Inter Denoise",
    "Inter Denoise Size": "Inter Denoise Size",
    "Inter Denoise FPD": "Inter Denoise FPD",
    "Inter Blur": "Inter Blur",
    "The new dynamic algorithm will handle these parameters. Activate them only for manual control.": "The new dynamic algorithm will handle these parameters. Activate them only for manual control.",
    "Corruption Refresh (Lower = Faster)": "Corruption Refresh (Lower = Faster)",
    "Corruption Preserve": "Corruption Preserve",
    "Smooth": "Smooth",
    "Frames to render. 0=ALL": "Frames to render. 0=ALL",
    "Run DFI": "Run DFI",
    "Show output folder video": "Show output folder video",
    "Deflickers Playground": "Deflickers Playground",
    "Frames folder": "Frames folder",
    "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.": "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.",
    "Blend:": "Blend:",
    "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.": "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.",
    "Overlay:": "Overlay:",
    "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.": "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.",
    "Normalize:": "Normalize:",
    "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.": "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.",
    "BLEND (0=Off)": "BLEND (0=Off)",
    "OVERLAY (0=Off)": "OVERLAY (0=Off)",
    "NORMALIZE (0=Off))": "NORMALIZE (0=Off))",
    "Deflickers": "Deflickers",
    "Style Fuse": "Style Fuse",
    "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.": "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.",
    "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.": "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.",
    "Style frames": "Style frames",
    "Video frames": "Video frames",
    "Fuse Strength": "Fuse Strength",
    "Fuse": "Fuse",
    "Video extract": "Video extract",
    "Video path": "Video path",
    "Fps. 0=Original": "Fps. 0=Original",
    "Extract": "Extract",
    "What DFI does?": "What DFI does?",
    "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext": "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext",
    "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.": "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.",
    "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.": "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.",
    "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.": "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.",
    "Usage strategies": "Usage strategies",
    "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.": "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.",
    "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.": "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.",
    "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.": "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.",
    "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.": "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.",
    "Abysz-LAB-Ext": "Abysz-LAB-Ext",
    "https://github.com/AbyszOne/Abysz-LAB-Ext": "https://github.com/AbyszOne/Abysz-LAB-Ext",
    "The RAW frames you have used as base for IA generation.": "The RAW frames you have used as base for IA generation.",
    "The frames of AI generated video": "The frames of AI generated video",
    "Remember that each generation overwrites previous frames in the same folder.": "Remember that each generation overwrites previous frames in the same folder.",
    "STAND BY...": "STAND BY...",
    "Frames to process": "Frames to process",
    "Processed frames": "Processed frames",
    "Style to fuse": "Style to fuse",
    "Remember to use same fps as generated video for DFI": "Remember to use same fps as generated video for DFI",
    "Cutoff": "Cutoff",
    "Target tokens (comma separated)": "Target tokens (comma separated)",
    "Details": "Details",
    "Disable for Negative prompt.": "Disable for Negative prompt.",
    "Cutoff strongly.": "Cutoff strongly.",
    "Padding token (ID or single token)": "Padding token (ID or single token)",
    "Interpolation method": "Interpolation method",
    "Debug log": "Debug log",
    "Cutoff Enabled": "Cutoff Enabled",
    "Cutoff Targets": "Cutoff Targets",
    "Cutoff Weight": "Cutoff Weight",
    "Cutoff Disable for Negative Prompt": "Cutoff Disable for Negative Prompt",
    "Cutoff Strong": "Cutoff Strong",
    "Cutoff Padding": "Cutoff Padding",
    "Cutoff Interpolation": "Cutoff Interpolation",
    "sd-webui-cutoff": "sd-webui-cutoff",
    "https://github.com/hnmr293/sd-webui-cutoff.git": "https://github.com/hnmr293/sd-webui-cutoff.git",
    "red, blue": "red, blue",
    "stable-diffusion-webui-two-shot": "stable-diffusion-webui-two-shot",
    "Divisions": "Divisions",
    "Positions": "Positions",
    "Weights": "Weights",
    "end at this step": "end at this step",
    "Visualize": "Visualize",
    "Regions": "Regions",
    "Extra generation params": "Extra generation params",
    "Apply": "Apply",
    "https://github.com/opparco/stable-diffusion-webui-two-shot.git": "https://github.com/opparco/stable-diffusion-webui-two-shot.git",
    "sd-webui-depth-lib": "sd-webui-depth-lib",
    "Depth Library": "Depth Library",
    "Pages:": "Pages:",
    "Selected": "Selected",
    "Send to ControlNet": "Send to ControlNet",
    "https://github.com/jexom/sd-webui-depth-lib.git": "https://github.com/jexom/sd-webui-depth-lib.git",
    "CLIP_test": "CLIP_test",
    "Create Beta hypernetwork": "Create Beta hypernetwork",
    "Train_Gamma": "Train_Gamma",
    "Train_Tuning": "Train_Tuning",
    "Show advanced options": "Show advanced options",
    "Weight initialization seed, set -1 for default": "Weight initialization seed, set -1 for default",
    "Standard Deviation for Normal weight initialization": "Standard Deviation for Normal weight initialization",
    "Use dropout. Might improve training when dataset is small / limited.": "Use dropout. Might improve training when dataset is small / limited.",
    "Use skip-connection. Won't work without extension!": "Use skip-connection. Won't work without extension!",
    "Optional information about Hypernetwork": "Optional information about Hypernetwork",
    "Setting file name": "Setting file name",
    "Save hypernetwork setting to file": "Save hypernetwork setting to file",
    "Train an embedding or Hypernetwork; you must specify a directory": "Train an embedding or Hypernetwork; you must specify a directory",
    "Show advanced learn rate scheduler options": "Show advanced learn rate scheduler options",
    "Show advanced adamW parameter options)": "Show advanced adamW parameter options)",
    "Show Gradient Clipping Options(for both)": "Show Gradient Clipping Options(for both)",
    "Show Noise Scheduler Options(for both)": "Show Noise Scheduler Options(for both)",
    "Uses D-Adaptation(LR Free) AdamW. Recommended LR is 1.0 at base": "Uses D-Adaptation(LR Free) AdamW. Recommended LR is 1.0 at base",
    "AdamW weight decay parameter": "AdamW weight decay parameter",
    "AdamW beta1 parameter": "AdamW beta1 parameter",
    "AdamW beta2 parameter": "AdamW beta2 parameter",
    "AdamW epsilon parameter": "AdamW epsilon parameter",
    "Growth factor limiting, use value like 1.02 or leave it as -1": "Growth factor limiting, use value like 1.02 or leave it as -1",
    "Use CosineAnnealingWarmupRestarts Scheduler": "Use CosineAnnealingWarmupRestarts Scheduler",
    "Steps for cycle": "Steps for cycle",
    "Step multiplier per cycle": "Step multiplier per cycle",
    "Warmup step per cycle": "Warmup step per cycle",
    "Minimum learning rate": "Minimum learning rate",
    "Decays learning rate every cycle": "Decays learning rate every cycle",
    "Saves when every cycle finishes": "Saves when every cycle finishes",
    "Generates image when every cycle finishes": "Generates image when every cycle finishes",
    "Gradient Clipping Options": "Gradient Clipping Options",
    "limit": "limit",
    "Limiting value": "Limiting value",
    "Norm type": "Norm type",
    "Use Noise training scheduler(test)": "Use Noise training scheduler(test)",
    "Restarts noise scheduler, or linear": "Restarts noise scheduler, or linear",
    "Restarts noise scheduler every nth epoch": "Restarts noise scheduler every nth epoch",
    "Unload Optimizer when generating preview(hypernetwork)": "Unload Optimizer when generating preview(hypernetwork)",
    "Standard deviation for sampling": "Standard deviation for sampling",
    "loss type": "loss type",
    "loss": "loss",
    "loss_simple": "loss_simple",
    "loss_vlb": "loss_vlb",
    "Save training setting": "Save training setting",
    "File name to save setting as": "File name to save setting as",
    "Load training option from saved json file. This will override settings above": "Load training option from saved json file. This will override settings above",
    "Train Hypernetwork; you must specify a directory": "Train Hypernetwork; you must specify a directory",
    "Hypernetwork name to create, leave it empty to use selected": "Hypernetwork name to create, leave it empty to use selected",
    "Load Hypernetwork creation option from saved json file": "Load Hypernetwork creation option from saved json file",
    "Load training option(s) from saved json file": "Load training option(s) from saved json file",
    "Save a copy of model to log directory every N steps, 0 to disable": "Save a copy of model to log directory every N steps, 0 to disable",
    "Manual dataset seed": "Manual dataset seed",
    "CLIP-test": "CLIP-test",
    "CLIP Text models. Set to empty to not change.": "CLIP Text models. Set to empty to not change.",
    "Enable clip model change. This will be triggered from next model changes.": "Enable clip model change. This will be triggered from next model changes.",
    "Detach grad from conditioning models": "Detach grad from conditioning models",
    "Hypernetwork-MonkeyPatch-Extension": "Hypernetwork-MonkeyPatch-Extension",
    "must be positive float": "must be positive float",
    "Training information, dateset, etc": "Training information, dateset, etc",
    "default = 0.01": "default = 0.01",
    "default = 0.9": "default = 0.9",
    "default = 0.99": "default = 0.99",
    "default = 1e-8": "default = 1e-8",
    "Cycles every nth Step": "Cycles every nth Step",
    "Step length multiplier every cycle": "Step length multiplier every cycle",
    "CosineAnnealing lr increase step": "CosineAnnealing lr increase step",
    "restricts decay value, but does not restrict gamma rate decay": "restricts decay value, but does not restrict gamma rate decay",
    "Value should be in (0-1]": "Value should be in (0-1]",
    ". filename cannot have ',' inside, and files should be splitted by ','.": ". filename cannot have ',' inside, and files should be splitted by ','.",
    "https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension.git": "https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension.git",
    "Remove background": "Remove background",
    "u2net": "u2net",
    "u2netp": "u2netp",
    "u2net_human_seg": "u2net_human_seg",
    "u2net_cloth_seg": "u2net_cloth_seg",
    "silueta": "silueta",
    "Return mask": "Return mask",
    "Alpha matting": "Alpha matting",
    "Erode size": "Erode size",
    "Foreground threshold": "Foreground threshold",
    "Background threshold": "Background threshold",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg.git",
    "stable-diffusion-webui-depthmap-script": "stable-diffusion-webui-depthmap-script",
    "Compute on": "Compute on",
    "GPU": "GPU",
    "CPU": "CPU",
    "Match input size (size is ignored when using boost)": "Match input size (size is ignored when using boost)",
    "BOOST (multi-resolution merging)": "BOOST (multi-resolution merging)",
    "Invert DepthMap (black=near, white=far)": "Invert DepthMap (black=near, white=far)",
    "Clip and renormalize": "Clip and renormalize",
    "Far clip": "Far clip",
    "Near clip": "Near clip",
    "Combine into one image.": "Combine into one image.",
    "Combine axis": "Combine axis",
    "Save DepthMap": "Save DepthMap",
    "Show DepthMap": "Show DepthMap",
    "Show HeatMap": "Show HeatMap",
    "Generate Stereo side-by-side image": "Generate Stereo side-by-side image",
    "Generate Stereo anaglyph image (red/cyan)": "Generate Stereo anaglyph image (red/cyan)",
    "Divergence (3D effect)": "Divergence (3D effect)",
    "Gap fill technique": "Gap fill technique",
    "Balance between eyes": "Balance between eyes",
    "Generate 3D inpainted mesh. (Sloooow)": "Generate 3D inpainted mesh. (Sloooow)",
    "Generate 4 demo videos with 3D inpainted mesh.": "Generate 4 demo videos with 3D inpainted mesh.",
    "Save the foreground masks": "Save the foreground masks",
    "pre-depth background removal": "pre-depth background removal",
    "Rembg Model": "Rembg Model",
    "Information, comment and share @": "Information, comment and share @",
    "Input Mesh (.ply)": "Input Mesh (.ply)",
    "Generate video from inpainted mesh.": "Generate video from inpainted mesh.",
    "A file on the same machine where the server is running.": "A file on the same machine where the server is running.",
    "Number of frames": "Number of frames",
    "Framerate": "Framerate",
    "Format": "Format",
    "Trajectory": "Trajectory",
    "Translate: x, y, z": "Translate: x, y, z",
    "Crop: top, left, bottom, right": "Crop: top, left, bottom, right",
    "Dolly": "Dolly",
    "Generate Video": "Generate Video",
    "https://github.com/thygate/stable-diffusion-webui-depthmap-script.git": "https://github.com/thygate/stable-diffusion-webui-depthmap-script.git",
    "Plot": "Plot",
    "Max Image Size": "Max Image Size",
    "Max Batch Count": "Max Batch Count",
    "Run benchmark": "Run benchmark",
    "Load results": "Load results",
    "a1111-stable-diffusion-webui-vram-estimator": "a1111-stable-diffusion-webui-vram-estimator",
    "https://github.com/space-nuko/a1111-stable-diffusion-webui-vram-estimator.git": "https://github.com/space-nuko/a1111-stable-diffusion-webui-vram-estimator.git",
    "Training Picker": "Training Picker",
    "Video to extract frames from:": "Video to extract frames from:",
    "Only extract keyframes (recommended)": "Only extract keyframes (recommended)",
    "Extract every nth frame": "Extract every nth frame",
    "Extract Frames": "Extract Frames",
    "Extracted Frame Set": "Extracted Frame Set",
    "Resize crops to 512x512": "Resize crops to 512x512",
    "Outfill method:": "Outfill method:",
    "Don't outfill": "Don't outfill",
    "Stretch image": "Stretch image",
    "Transparent": "Transparent",
    "Solid color": "Solid color",
    "Average image color": "Average image color",
    "Dominant image color": "Dominant image color",
    "Stretch pixels at border": "Stretch pixels at border",
    "Reflect image around border": "Reflect image around border",
    "Blurred & stretched overlay": "Blurred & stretched overlay",
    "Reuse original image": "Reuse original image",
    "Reset Aspect Ratio": "Reset Aspect Ratio",
    "Image border outfill method:": "Image border outfill method:",
    "Black outfill": "Black outfill",
    "Outfill border color:": "Outfill border color:",
    "Blur amount:": "Blur amount:",
    "Number of clusters:": "Number of clusters:",
    "Save crops to:": "Save crops to:",
    "Fixed size to resize images to": "Fixed size to resize images to",
    "Path to read videos from": "Path to read videos from",
    "Path to store extracted frame sets in": "Path to store extracted frame sets in",
    "Default cropped image output directory": "Default cropped image output directory",
    "https://github.com/Maurdekye/training-picker.git": "https://github.com/Maurdekye/training-picker.git",
    "✕": "✕",
    "[NPW] Weight": "[NPW] Weight",
    "stable-diffusion-NPW": "stable-diffusion-NPW",
    "https://github.com/muerrilla/stable-diffusion-NPW": "https://github.com/muerrilla/stable-diffusion-NPW",
    "Wildcards Manager": "Wildcards Manager",
    "Dynamic Prompts enabled": "Dynamic Prompts enabled",
    "Combinatorial generation": "Combinatorial generation",
    "Max generations (0 = all combinations - the batch count value is ignored)": "Max generations (0 = all combinations - the batch count value is ignored)",
    "Combinatorial batches": "Combinatorial batches",
    "Prompt Magic": "Prompt Magic",
    "Magic prompt": "Magic prompt",
    "Max magic prompt length": "Max magic prompt length",
    "Magic prompt creativity": "Magic prompt creativity",
    "Magic prompt model": "Magic prompt model",
    "Gustavosta/MagicPrompt-Stable-Diffusion": "Gustavosta/MagicPrompt-Stable-Diffusion",
    "daspartho/prompt-extend": "daspartho/prompt-extend",
    "succinctly/text2image-prompt-generator": "succinctly/text2image-prompt-generator",
    "microsoft/Promptist": "microsoft/Promptist",
    "AUTOMATIC/promptgen-lexart": "AUTOMATIC/promptgen-lexart",
    "AUTOMATIC/promptgen-majinai-safe": "AUTOMATIC/promptgen-majinai-safe",
    "AUTOMATIC/promptgen-majinai-unsafe": "AUTOMATIC/promptgen-majinai-unsafe",
    "kmewhort/stable-diffusion-prompt-bolster": "kmewhort/stable-diffusion-prompt-bolster",
    "Gustavosta/MagicPrompt-Dalle": "Gustavosta/MagicPrompt-Dalle",
    "Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator": "Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator",
    "Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator": "Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator",
    "crumb/bloom-560m-RLHF-SD2-prompter-aesthetic": "crumb/bloom-560m-RLHF-SD2-prompter-aesthetic",
    "Meli/GPT2-Prompt": "Meli/GPT2-Prompt",
    "DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M": "DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M",
    "Magic prompt blocklist regex": "Magic prompt blocklist regex",
    "Magic Prompt batch size": "Magic Prompt batch size",
    "I'm feeling lucky": "I'm feeling lucky",
    "Attention grabber": "Attention grabber",
    "Minimum attention": "Minimum attention",
    "Maximum attention": "Maximum attention",
    "Don't apply to negative prompts": "Don't apply to negative prompts",
    "Need help?": "Need help?",
    "Syntax cheatsheet": "Syntax cheatsheet",
    "Tutorial": "Tutorial",
    "Discussions": "Discussions",
    "Report a bug": "Report a bug",
    "Combinations": "Combinations",
    "Choose a number of terms from a list, in this case we choose two artists:": "Choose a number of terms from a list, in this case we choose two artists:",
    "{2$$artist1|artist2|artist3}": "{2$$artist1|artist2|artist3}",
    "If $$ is not provided, then 1$$ is assumed.": "If $$ is not provided, then 1$$ is assumed.",
    "If the chosen number of terms is greater than the available terms, then some terms will be duplicated, otherwise chosen terms will be unique. This is useful in the case of wildcards, e.g.": "If the chosen number of terms is greater than the available terms, then some terms will be duplicated, otherwise chosen terms will be unique. This is useful in the case of wildcards, e.g.",
    "{2$$__artist__}": "{2$$__artist__}",
    "is equivalent to": "is equivalent to",
    "{2$$__artist__|__artist__}": "{2$$__artist__|__artist__}",
    "A range can be provided:": "A range can be provided:",
    "{1-3$$artist1|artist2|artist3}": "{1-3$$artist1|artist2|artist3}",
    "In this case, a random number of artists between 1 and 3 is chosen.": "In this case, a random number of artists between 1 and 3 is chosen.",
    "Options can be given weights:": "Options can be given weights:",
    "{2::artist1|artist2}": "{2::artist1|artist2}",
    "In this case, artist1 will be chosen twice as often as artist2.": "In this case, artist1 will be chosen twice as often as artist2.",
    "Wildcards can be used and the joiner can also be specified:": "Wildcards can be used and the joiner can also be specified:",
    "{{1-$$and$$__adjective__}}": "{{1-$$and$$__adjective__}}",
    "Here, a random number between 1 and 3 words from adjective.txt will be chosen and joined together with the word 'and' instead of the default comma.": "Here, a random number between 1 and 3 words from adjective.txt will be chosen and joined together with the word 'and' instead of the default comma.",
    "Wildcards": "Wildcards",
    "Find and manage wildcards in the Wildcards Manager tab.": "Find and manage wildcards in the Wildcards Manager tab.",
    "__<folder>/mywildcards__": "__<folder>/mywildcards__",
    "will then become available.": "will then become available.",
    "Find more settings on the": "Find more settings on the",
    "Jinja2 templates": "Jinja2 templates",
    "Enable Jinja2 templates": "Enable Jinja2 templates",
    "Help for Jinja2 templates": "Help for Jinja2 templates",
    "Jinja2 templates is an experimental feature for advanced template generation. It is not recommended for general use unless you are comfortable with writing scripts.": "Jinja2 templates is an experimental feature for advanced template generation. It is not recommended for general use unless you are comfortable with writing scripts.",
    "Literals": "Literals",
    "I love red roses": "I love red roses",
    "Random choices": "Random choices",
    "I love {{ choice('red', 'blue', 'green') }} roses": "I love {{ choice('red', 'blue', 'green') }} roses",
    "This will randomly choose one of the three colors.": "This will randomly choose one of the three colors.",
    "Iterations": "Iterations",
    "{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}": "{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}",
    "This will produce three prompts, one for each color. The prompt tag is used to mark the text that will be used as the prompt. If no prompt tag is present then only one prompt is assumed": "This will produce three prompts, one for each color. The prompt tag is used to mark the text that will be used as the prompt. If no prompt tag is present then only one prompt is assumed",
    "{% for colour in wildcard(\"__colours__\") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}": "{% for colour in wildcard(\"__colours__\") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}",
    "This will produce one prompt for each colour in the wildcard.txt file.": "This will produce one prompt for each colour in the wildcard.txt file.",
    "Conditionals": "Conditionals",
    "{% for colour in [\"red\", \"blue\", \"green\"] %}\n        {% if colour == \"red\"}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}": "{% for colour in [\"red\", \"blue\", \"green\"] %}\n        {% if colour == \"red\"}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}",
    "This will produce the following prompts:": "This will produce the following prompts:",
    "I hate blue roses": "I hate blue roses",
    "I hate green roses": "I hate green roses",
    "Jinja2 templates are based on the Jinja2 template engine. For more information see the": "Jinja2 templates are based on the Jinja2 template engine. For more information see the",
    "Jinja2 documentation.": "Jinja2 documentation.",
    "If you are using these templates, please let me know if they are useful.": "If you are using these templates, please let me know if they are useful.",
    "Advanced options": "Advanced options",
    "Some settings have been moved to the settings tab. Find them in the Dynamic Prompts section.": "Some settings have been moved to the settings tab. Find them in the Dynamic Prompts section.",
    "Unlink seed from prompt": "Unlink seed from prompt",
    "Fixed seed": "Fixed seed",
    "Write raw prompt to image": "Write raw prompt to image",
    "Don't generate images": "Don't generate images",
    "Write prompts to file": "Write prompts to file",
    "Manage wildcards for Dynamic Prompts": "Manage wildcards for Dynamic Prompts",
    "1. Create your wildcard library by copying a collection using the dropdown below.": "1. Create your wildcard library by copying a collection using the dropdown below.",
    "2. Click on any of the files that appear in the tree to edit them.": "2. Click on any of the files that appear in the tree to edit them.",
    "3. Use the wildcard in your script by typing the name of the file or copying the text from the Wildcards file text box": "3. Use the wildcard in your script by typing the name of the file or copying the text from the Wildcards file text box",
    "Select a collection": "Select a collection",
    "devilkkw": "devilkkw",
    "jumbo": "jumbo",
    "nai": "nai",
    "nsp": "nsp",
    "parrotzone": "parrotzone",
    "Copy collection": "Copy collection",
    "Overwrite existing": "Overwrite existing",
    "Refresh wildcards": "Refresh wildcards",
    "Delete all wildcards": "Delete all wildcards",
    "Wildcards file": "Wildcards file",
    "File editor": "File editor",
    "Save wildcards": "Save wildcards",
    "Ignore whitespace in prompts: All newlines, tabs, and multiple spaces are replaced by a single space": "Ignore whitespace in prompts: All newlines, tabs, and multiple spaces are replaced by a single space",
    "Save template to metadata: Write prompt template into the PNG metadata": "Save template to metadata: Write prompt template into the PNG metadata",
    "Write prompts to file: Create a new .txt file for every batch containing the prompt template as well as the generated prompts.": "Write prompts to file: Create a new .txt file for every batch containing the prompt template as well as the generated prompts.",
    "String to use as left bracket for parser variants, .e.g {variant1|variant2|variant3}": "String to use as left bracket for parser variants, .e.g {variant1|variant2|variant3}",
    "String to use as right bracket for parser variants, .e.g {variant1|variant2|variant3}": "String to use as right bracket for parser variants, .e.g {variant1|variant2|variant3}",
    "String to use as wrap for parser wildcard, .e.g __wildcard__": "String to use as wrap for parser wildcard, .e.g __wildcard__",
    "Limit Jinja prompts: Limit the number of prompts to batch_count * batch_size. The default is to generate batch_count * barch_size * number of prompts generated by Jinja": "Limit Jinja prompts: Limit the number of prompts to batch_count * batch_size. The default is to generate batch_count * barch_size * number of prompts generated by Jinja",
    "sd-dynamic-prompts": "sd-dynamic-prompts",
    "https://github.com/adieyal/sd-dynamic-prompts.git": "https://github.com/adieyal/sd-dynamic-prompts.git",
    "Disable dynamic prompts by unchecking this box.": "Disable dynamic prompts by unchecking this box.",
    "Instead of generating random prompts from a template, combinatorial generation produces every possible prompt from the given string.\nThe prompt 'I {love|hate} {New York|Chicago} in {June|July|August}' will produce 12 variants in total.\n\nThe value of the 'Seed' field is only used for the first image. To change this, look for 'Fixed seed' in the 'Advanced options' section.": "Instead of generating random prompts from a template, combinatorial generation produces every possible prompt from the given string.\nThe prompt 'I {love|hate} {New York|Chicago} in {June|July|August}' will produce 12 variants in total.\n\nThe value of the 'Seed' field is only used for the first image. To change this, look for 'Fixed seed' in the 'Advanced options' section.",
    "Limit the maximum number of prompts generated. 0 (default) will generate all images. Useful to prevent an unexpected combinatorial explosion.": "Limit the maximum number of prompts generated. 0 (default) will generate all images. Useful to prevent an unexpected combinatorial explosion.",
    "Re-run your combinatorial batch this many times with a different seed each time.": "Re-run your combinatorial batch this many times with a different seed each time.",
    "Magic Prompt adds interesting modifiers to your prompt for a little bit of extra spice.\nThe first time you use it, the MagicPrompt model is downloaded so be patient.\nIf you're running low on VRAM, you might get a CUDA error.": "Magic Prompt adds interesting modifiers to your prompt for a little bit of extra spice.\nThe first time you use it, the MagicPrompt model is downloaded so be patient.\nIf you're running low on VRAM, you might get a CUDA error.",
    "Controls the maximum length in tokens of the generated prompt.": "Controls the maximum length in tokens of the generated prompt.",
    "Adjusts the generated prompt. You will need to experiment with this setting.": "Adjusts the generated prompt. You will need to experiment with this setting.",
    "Regular expression pattern for blocking terms out of the generated prompt. Applied case-insensitively. For instance, to block both \"purple\" and \"interdimensional\", you could use the pattern \"purple|interdimensional\".": "Regular expression pattern for blocking terms out of the generated prompt. Applied case-insensitively. For instance, to block both \"purple\" and \"interdimensional\", you could use the pattern \"purple|interdimensional\".",
    "The number of prompts to generate per batch. Increasing this can speed up prompt generation at the expense of slightly increased VRAM usage.": "The number of prompts to generate per batch. Increasing this can speed up prompt generation at the expense of slightly increased VRAM usage.",
    "Uses the lexica.art API to create random prompts.\nThe prompt in the main prompt box is used as a search string.\nLeaving the prompt box blank returns a list of completely randomly chosen prompts.\nTry it out, it can be quite fun.": "Uses the lexica.art API to create random prompts.\nThe prompt in the main prompt box is used as a search string.\nLeaving the prompt box blank returns a list of completely randomly chosen prompts.\nTry it out, it can be quite fun.",
    "Randomly selects a keyword from the prompt and adds emphasis to it. Try this with Fixed Seed enabled.": "Randomly selects a keyword from the prompt and adds emphasis to it. Try this with Fixed Seed enabled.",
    "Don't use prompt magic on negative prompts.": "Don't use prompt magic on negative prompts.",
    "Jinja2 templates are an expressive alternative to the standard syntax. See the Help section below for instructions.": "Jinja2 templates are an expressive alternative to the standard syntax. See the Help section below for instructions.",
    "Check this if you want to generate random prompts, even if your seed is fixed": "Check this if you want to generate random prompts, even if your seed is fixed",
    "Select this if you want to use the same seed for every generated image.\nThis is useful if you want to test prompt variations while using the same seed.\nIf there are no wildcards then all the images will be identical.": "Select this if you want to use the same seed for every generated image.\nThis is useful if you want to test prompt variations while using the same seed.\nIf there are no wildcards then all the images will be identical.",
    "Write the prompt template into the image metadata": "Write the prompt template into the image metadata",
    "Be sure to check the 'Write prompts to file' checkbox if you don't want to lose the generated prompts. Note, one image is still generated.": "Be sure to check the 'Write prompts to file' checkbox if you don't want to lose the generated prompts. Note, one image is still generated.",
    "The generated file is a slugified version of the prompt and can be found in the same directory as the generated images.\nE.g. in ./outputs/txt2img-images/.": "The generated file is a slugified version of the prompt and can be found in the same directory as the generated images.\nE.g. in ./outputs/txt2img-images/.",
    "Complete documentation is available at https://github.com/adieyal/sd-dynamic-prompts. Please report any issues on GitHub.": "Complete documentation is available at https://github.com/adieyal/sd-dynamic-prompts. Please report any issues on GitHub.",
    "Generate all possible prompt combinations.": "Generate all possible prompt combinations.",
    "Automatically update your prompt with interesting modifiers. (Runs slowly the first time)": "Automatically update your prompt with interesting modifiers. (Runs slowly the first time)",
    "Generate random prompts from lexica.art (your prompt is used as a search query).": "Generate random prompts from lexica.art (your prompt is used as a search query).",
    "Use the same seed for all prompts in this batch": "Use the same seed for all prompts in this batch",
    "Write all generated prompts to a file": "Write all generated prompts to a file",
    "If this is set, then random prompts are generated, even if the seed is the same.": "If this is set, then random prompts are generated, even if the seed is the same.",
    "Disable image generation. Useful if you only want to generate text prompts. (1 image will still be generated to keep Auto1111 happy.).": "Disable image generation. Useful if you only want to generate text prompts. (1 image will still be generated to keep Auto1111 happy.).",
    "Add emphasis to a randomly selected keyword in the prompt.": "Add emphasis to a randomly selected keyword in the prompt.",
    "Write template into image metadata.": "Write template into image metadata.",
    "Note: Each model will download between 300mb and 1.4gb of data on first use.": "Note: Each model will download between 300mb and 1.4gb of data on first use.",
    "Text2Prompt": "Text2Prompt",
    "Input Theme": "Input Theme",
    "Input Negative Theme": "Input Negative Theme",
    "Negative strength": "Negative strength",
    "Replace underscore in tag with whitespace": "Replace underscore in tag with whitespace",
    "Escape brackets in tag": "Escape brackets in tag",
    "Generation Settings": "Generation Settings",
    "Database": "Database",
    "Tag count filter": "Tag count filter",
    "Tag range:": "Tag range:",
    "≥ 0 tagged": "≥ 0 tagged",
    "(14589 tags total)": "(14589 tags total)",
    "Method to convert similarity into probability": "Method to convert similarity into probability",
    "Cutoff and Power": "Cutoff and Power",
    "Softmax": "Softmax",
    "Power": "Power",
    "Top-k": "Top-k",
    "Top-p (Nucleus)": "Top-p (Nucleus)",
    "Max number of tags": "Max number of tags",
    "k value": "k value",
    "p value": "p value",
    "Use weighted choice": "Use weighted choice",
    "stable-diffusion-webui-text2prompt": "stable-diffusion-webui-text2prompt",
    "https://github.com/toshiaki1729/stable-diffusion-webui-text2prompt.git": "https://github.com/toshiaki1729/stable-diffusion-webui-text2prompt.git",
    "Embedding Editor": "Embedding Editor",
    "Vector": "Vector",
    "Refresh Embeddings": "Refresh Embeddings",
    "Save Embedding": "Save Embedding",
    "Enter words and color hexes to mark weights on the sliders for guidance. Hint: Use the txt2img prompt token counter or": "Enter words and color hexes to mark weights on the sliders for guidance. Hint: Use the txt2img prompt token counter or",
    "webui-tokenizer": "webui-tokenizer",
    "to see which words are constructed using multiple sub-words, e.g. 'computer' doesn't exist in stable diffusion's CLIP dictionary and instead 'compu' and 'ter' are used (1 word but 2 embedding vectors). Currently buggy and needs a moment to process before pressing the button. If it doesn't work after a moment, try adding a random space to refresh it.": "to see which words are constructed using multiple sub-words, e.g. 'computer' doesn't exist in stable diffusion's CLIP dictionary and instead 'compu' and 'ter' are used (1 word but 2 embedding vectors). Currently buggy and needs a moment to process before pressing the button. If it doesn't work after a moment, try adding a random space to refresh it.",
    "Sampling Steps": "Sampling Steps",
    "Generate Preview": "Generate Preview",
    "stable-diffusion-webui-embedding-editor": "stable-diffusion-webui-embedding-editor",
    "https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor.git": "https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor.git",
    "symbol:color-hex, symbol:color-hex, ...": "symbol:color-hex, symbol:color-hex, ...",
    "e.g. A portrait photo of embedding_name": "e.g. A portrait photo of embedding_name",
    "Shift attention": "Shift attention",
    "https://github.com/yownas/shift-attention.git": "https://github.com/yownas/shift-attention.git",
    "Save score as EXIF or PNG Info Chunk": "Save score as EXIF or PNG Info Chunk",
    "sd_model_hash": "sd_model_hash",
    "hash": "hash",
    "Save tags (Windows only)": "Save tags (Windows only)",
    "Save category (Windows only)": "Save category (Windows only)",
    "Save generation params text": "Save generation params text",
    "Force CPU (Requires Custom Script Reload)": "Force CPU (Requires Custom Script Reload)",
    "stable-diffusion-webui-aesthetic-image-scorer": "stable-diffusion-webui-aesthetic-image-scorer",
    "https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer.git": "https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer.git"
}